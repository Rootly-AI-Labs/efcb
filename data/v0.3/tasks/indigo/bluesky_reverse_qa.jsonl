{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "testing/utils.go\n@@ -57,7 +57,7 @@ type TestPDS struct {\n \tshutdown func()\n }\n \n-// HTTPHost returns a host:port string that the PDS server is running at\n+// RawHost returns a host:port string that the PDS server is running at\n func (tp *TestPDS) RawHost() string {\n \treturn tp.listener.Addr().String()\n }\n---\n"}], "ideal": "Title: update function name in comment\n\nBody: update function name in comment"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/relay/crawl.go\n@@ -3,6 +3,7 @@ package relay\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"time\"\n \n \t\"github.com/bluesky-social/indigo/cmd/relay/relay/models\"\n )\n@@ -71,6 +72,8 @@ func (r *Relay) ResubscribeAllHosts(ctx context.Context) error {\n \t\tif err != nil {\n \t\t\tlogger.Warn(\"failed to re-subscribe to host\", \"err\", err)\n \t\t}\n+\t\t// sleep for a very short period, so we don't open tons of sockets at the same time\n+\t\ttime.Sleep(1 * time.Millisecond)\n \t}\n \treturn nil\n }\n---\n"}], "ideal": "Title: add a 1ms delay between re-subscribing to PDS instances\n\nBody: Assuming 5k active PDS instances, this spreads things out over 5 seconds. had been seeing burst of errors when restarting relay, which I suspect is related to too many sockets (and DNS lookups) at the same time."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "api/bsky/feeddefs.go\n@@ -35,6 +35,8 @@ type FeedDefs_FeedViewPost struct {\n \tPost        *FeedDefs_PostView            `json:\"post\" cborgen:\"post\"`\n \tReason      *FeedDefs_FeedViewPost_Reason `json:\"reason,omitempty\" cborgen:\"reason,omitempty\"`\n \tReply       *FeedDefs_ReplyRef            `json:\"reply,omitempty\" cborgen:\"reply,omitempty\"`\n+\t// reqId: Unique identifier per request that may be passed back alongside interactions.\n+\tReqId *string `json:\"reqId,omitempty\" cborgen:\"reqId,omitempty\"`\n }\n \n type FeedDefs_FeedViewPost_Reason struct {\n@@ -104,6 +106,8 @@ type FeedDefs_Interaction struct {\n \t// feedContext: Context on a feed item that was originally supplied by the feed generator on getFeedSkeleton.\n \tFeedContext *string `json:\"feedContext,omitempty\" cborgen:\"feedContext,omitempty\"`\n \tItem        *string `json:\"item,omitempty\" cborgen:\"item,omitempty\"`\n+\t// reqId: Unique identifier per request that may be passed back alongside interactions.\n+\tReqId *string `json:\"reqId,omitempty\" cborgen:\"reqId,omitempty\"`\n }\n \n // FeedDefs_NotFoundPost is a \"notFoundPost\" in the app.bsky.feed.defs schema.\n@@ -207,7 +211,9 @@ type FeedDefs_ReasonPin struct {\n type FeedDefs_ReasonRepost struct {\n \tLexiconTypeID string                      `json:\"$type,const=app.bsky.feed.defs#reasonRepost\" cborgen:\"$type,const=app.bsky.feed.defs#reasonRepost\"`\n \tBy            *ActorDefs_ProfileViewBasic `json:\"by\" cborgen:\"by\"`\n+\tCid           *string                     `json:\"cid,omitempty\" cborgen:\"cid,omitempty\"`\n \tIndexedAt     string                      `json:\"indexedAt\" cborgen:\"indexedAt\"`\n+\tUri           *string                     `json:\"uri,omitempty\" cborgen:\"uri,omitempty\"`\n }\n \n // FeedDefs_ReplyRef is a \"replyRef\" in the app.bsky.feed.defs schema.\n---\napi/bsky/feedgetFeedSkeleton.go\n@@ -14,6 +14,8 @@ import (\n type FeedGetFeedSkeleton_Output struct {\n \tCursor *string                      `json:\"cursor,omitempty\" cborgen:\"cursor,omitempty\"`\n \tFeed   []*FeedDefs_SkeletonFeedPost `json:\"feed\" cborgen:\"feed\"`\n+\t// reqId: Unique identifier per request that may be passed back alongside interactions.\n+\tReqId *string `json:\"reqId,omitempty\" cborgen:\"reqId,omitempty\"`\n }\n \n // FeedGetFeedSkeleton calls the XRPC method \"app.bsky.feed.getFeedSkeleton\".\n---\napi/bsky/feedlike.go\n@@ -17,4 +17,5 @@ type FeedLike struct {\n \tLexiconTypeID string                         `json:\"$type,const=app.bsky.feed.like\" cborgen:\"$type,const=app.bsky.feed.like\"`\n \tCreatedAt     string                         `json:\"createdAt\" cborgen:\"createdAt\"`\n \tSubject       *comatprototypes.RepoStrongRef `json:\"subject\" cborgen:\"subject\"`\n+\tVia           *comatprototypes.RepoStrongRef `json:\"via,omitempty\" cborgen:\"via,omitempty\"`\n }\n---\napi/bsky/feedrepost.go\n@@ -17,4 +17,5 @@ type FeedRepost struct {\n \tLexiconTypeID string                         `json:\"$type,const=app.bsky.feed.repost\" cborgen:\"$type,const=app.bsky.feed.repost\"`\n \tCreatedAt     string                         `json:\"createdAt\" cborgen:\"createdAt\"`\n \tSubject       *comatprototypes.RepoStrongRef `json:\"subject\" cborgen:\"subject\"`\n+\tVia           *comatprototypes.RepoStrongRef `json:\"via,omitempty\" cborgen:\"via,omitempty\"`\n }\n---\napi/bsky/notificationlistNotifications.go\n@@ -19,7 +19,7 @@ type NotificationListNotifications_Notification struct {\n \tIndexedAt string                             `json:\"indexedAt\" cborgen:\"indexedAt\"`\n \tIsRead    bool                               `json:\"isRead\" cborgen:\"isRead\"`\n \tLabels    []*comatprototypes.LabelDefs_Label `json:\"labels,omitempty\" cborgen:\"labels,omitempty\"`\n-\t// reason: Expected values are 'like', 'repost', 'follow', 'mention', 'reply', 'quote', 'starterpack-joined', 'verified', and 'unverified'.\n+\t// reason: The reason why this notification was delivered - e.g. your post was liked, or you received a new follower.\n \tReason        string                   `json:\"reason\" cborgen:\"reason\"`\n \tReasonSubject *string                  `json:\"reasonSubject,omitempty\" cborgen:\"reasonSubject,omitempty\"`\n \tRecord        *util.LexiconTypeDecoder `json:\"record\" cborgen:\"record\"`\n---\n"}], "ideal": "Title: Latest Lexgen\n\nBody: This is to pull in the latest requirement changes via https://github.com/bluesky-social/atproto/pull/3882, specifically the \"via repost\" changes.\r\n\r\nAfter running `make lexgen`, there were several other changes that were deprecated, so I did not commit those. Happy to add them back if that's the preferred way of doing things, but doing so led to some lexgen weirdness, so I decided to leave them off for now to continue making progress."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/data/parse.go\n@@ -11,7 +11,7 @@ import (\n \n func parseFloat(f float64) (int64, error) {\n \tif f != float64(int64(f)) {\n-\t\treturn 0, fmt.Errorf(\"number was is not a safe integer: %f\", f)\n+\t\treturn 0, fmt.Errorf(\"number is not a safe integer: %f\", f)\n \t}\n \treturn int64(f), nil\n }\n---\n"}], "ideal": "Title: Remove extraneous word from error message (fixes #1086)\n\nBody: Fixes #1086 "}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/handlers.go\n@@ -65,7 +65,7 @@ func (s *Service) handleComAtprotoSyncRequestCrawl(c echo.Context, body *comatpr\n \t}\n \tgo s.ForwardSiblingRequest(c, b)\n \n-\treturn s.relay.SubscribeToHost(ctx, hostname, noSSL, false)\n+\treturn s.relay.SubscribeToHost(ctx, hostname, noSSL, admin)\n }\n \n func (s *Service) handleComAtprotoSyncListHosts(c echo.Context, cursor int64, limit int) (*comatproto.SyncListHosts_Output, error) {\n---\n"}], "ideal": "Title: bypass subscribe limits in /admin/pds/requestCrawl\n\nBody: `handleComAtprotoSyncRequestCrawl` should pass its boolean `admin` flag to `SubscribeToHost`, to let it bypass the daily new host limit when run as admin. Currently it just always passes `false`. The result is that when calling `goat relay admin host add` or the `/admin/pds/requestCrawl` endpoint, you get a \"500 new host subscriptions temporarily disabled\" error in response.\r\n"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/crypto/keys.go\n@@ -30,7 +30,8 @@ type PrivateKeyExportable interface {\n \t// No ASN.1 or other enclosing structure is applied to the bytes.\n \tBytes() []byte\n \n-\t// NOTE: should Multibase() (string, error) be part of this interface? Probably.\n+\t// String serialization of the key bytes in \"Multibase\" format.\n+\tMultibase() string\n }\n \n // Common interface for all the supported atproto cryptographic systems.\n---\natproto/crypto/keys_test.go\n@@ -166,9 +166,11 @@ func TestParsePrivateMultibase(t *testing.T) {\n \tassert.NoError(err)\n \t_, ok := privP256FromMB.(*PrivateKeyP256)\n \tassert.True(ok)\n+\tassert.Equal(privP256MB, privP256FromMB.Multibase())\n \n \tprivK256FromMB, err := ParsePrivateMultibase(privK256MB)\n \tassert.NoError(err)\n \t_, ok = privK256FromMB.(*PrivateKeyK256)\n \tassert.True(ok)\n+\tassert.Equal(privK256MB, privK256FromMB.Multibase())\n }\n---\n"}], "ideal": "Title: crypto: add Multibase() method to PrivateKeyExportable interface\n\nBody: Pretty simple one: actually add `Multibase()` output encoding to `PrivateKeyExportable` interface, as foreshadowed by an earlier comment.\r\n\r\nAdds a round-trip test for the two current curve types supported."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/lexgen/main.go\n@@ -64,9 +64,6 @@ func main() {\n \t\t&cli.StringFlag{\n \t\t\tName: \"outdir\",\n \t\t},\n-\t\t&cli.StringFlag{\n-\t\t\tName: \"prefix\",\n-\t\t},\n \t\t&cli.BoolFlag{\n \t\t\tName: \"gen-server\",\n \t\t},\n@@ -76,6 +73,9 @@ func main() {\n \t\t&cli.StringSliceFlag{\n \t\t\tName: \"types-import\",\n \t\t},\n+\t\t&cli.StringSliceFlag{\n+\t\t\tName: \"external-lexicons\",\n+\t\t},\n \t\t&cli.StringFlag{\n \t\t\tName:  \"package\",\n \t\t\tValue: \"schemagen\",\n@@ -109,6 +109,20 @@ func main() {\n \t\t\tschemas = append(schemas, s)\n \t\t}\n \n+\t\texternalPaths, err := expandArgs(cctx.StringSlice(\"external-lexicons\"))\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tvar externalSchemas []*lex.Schema\n+\t\tfor _, arg := range externalPaths {\n+\t\t\ts, err := lex.ReadSchema(arg)\n+\t\t\tif err != nil {\n+\t\t\t\treturn fmt.Errorf(\"failed to read file %q: %w\", arg, err)\n+\t\t\t}\n+\n+\t\t\texternalSchemas = append(externalSchemas, s)\n+\t\t}\n+\n \t\tbuildLiteral := cctx.String(\"build\")\n \t\tbuildPath := cctx.String(\"build-file\")\n \t\tvar packages []lex.Package\n@@ -145,7 +159,7 @@ func main() {\n \t\t\tif outdir == \"\" {\n \t\t\t\treturn fmt.Errorf(\"must specify output directory (--outdir)\")\n \t\t\t}\n-\t\t\tdefmap := lex.BuildExtDefMap(schemas, packages)\n+\t\t\tdefmap := lex.BuildExtDefMap(append(schemas, externalSchemas...), packages)\n \t\t\t_ = defmap\n \n \t\t\tpaths := cctx.StringSlice(\"types-import\")\n@@ -162,7 +176,7 @@ func main() {\n \t\t\t}\n \n \t\t} else {\n-\t\t\treturn lex.Run(schemas, packages)\n+\t\t\treturn lex.Run(schemas, externalSchemas, packages)\n \t\t}\n \n \t\treturn nil\n---\nlex/gen.go\n@@ -468,8 +468,8 @@ func ParsePackages(jsonBytes []byte) ([]Package, error) {\n \treturn packages, nil\n }\n \n-func Run(schemas []*Schema, packages []Package) error {\n-\tdefmap := BuildExtDefMap(schemas, packages)\n+func Run(schemas []*Schema, externalSchemas []*Schema, packages []Package) error {\n+\tdefmap := BuildExtDefMap(append(schemas, externalSchemas...), packages)\n \n \tfor _, pkg := range packages {\n \t\tprefix := pkg.Prefix\n---\n"}], "ideal": "Title: lexgen: add --external-lexicons\n\nBody: `cmd/lexgen` is unprepared for a world where it's not generating schemas for everything in `atproto`! Both type generation and server stub generation generate types/stubs for every specified lexicon; this causes generated code to be somewhere between \"challenging\" and \"unusable\" for external projects \u2014 we'd prefer to have codegen that creates types for our Go program while still being able to externally reference `com.atproto` and `app.bsky` schema\r\n\r\nThis change introduces an `--external-lexicons` flag that can take multiple directories. It functions the same way as the positional lexicon arguments, those lexicons are all loaded into the code and can be referenced, but their types/stubs are not  included as part of the generated output. This yields the following command for Streamplace; this generates types for Streamplace lexicons without generating atproto code:\r\n\r\n```shell\r\nlexgen \\\r\n\t\t-outdir ./pkg/spxrpc \\\r\n\t\t--build-file util/lexgen-types.json \\\r\n\t\t--external-lexicons ../atproto/lexicons \\\r\n\t\tlexicons/place/stream \\\r\n\t\tlexicons/app/bsky\r\n\r\n```\r\n\r\nAnd this does the same thing for generating server stubs:\r\n```\r\nlexgen \\\r\n\t\t--gen-server \\\r\n\t\t--types-import place.stream:stream.place/streamplace/pkg/streamplace \\\r\n\t\t--types-import app.bsky:github.com/bluesky-social/indigo/api/bsky \\\r\n\t\t--types-import com.atproto:github.com/bluesky-social/indigo/api/atproto \\\r\n\t\t--types-import chat.bsky:github.com/bluesky-social/indigo/api/chat \\\r\n\t\t--types-import tools.ozone:github.com/bluesky-social/indigo/api/ozone \\\r\n\t\t-outdir ./pkg/spxrpc \\\r\n\t\t--build-file util/lexgen-types.json \\\r\n\t\t--external-lexicons ../atproto/lexicons \\\r\n\t\t--package spxrpc \\\r\n\t\tlexicons/place/stream \\\r\n\t\tlexicons/app/bsky\r\n```\r\n\r\n`lexgen-types.json` looks like this:\r\n```json\r\n[\r\n  {\r\n    \"package\": \"bsky\",\r\n    \"prefix\": \"app.bsky\",\r\n    \"outdir\": \"api/bsky\",\r\n    \"import\": \"github.com/bluesky-social/indigo/api/bsky\"\r\n  },\r\n  {\r\n    \"package\": \"atproto\",\r\n    \"prefix\": \"com.atproto\",\r\n    \"outdir\": \"api/atproto\",\r\n    \"import\": \"github.com/bluesky-social/indigo/api/atproto\"\r\n  },\r\n  {\r\n    \"package\": \"chat\",\r\n    \"prefix\": \"chat.bsky\",\r\n    \"outdir\": \"api/chat\",\r\n    \"import\": \"github.com/bluesky-social/indigo/api/chat\"\r\n  },\r\n  {\r\n    \"package\": \"ozone\",\r\n    \"prefix\": \"tools.ozone\",\r\n    \"outdir\": \"api/ozone\",\r\n    \"import\": \"github.com/bluesky-social/indigo/api/ozone\"\r\n  },\r\n  {\r\n    \"package\": \"streamplace\",\r\n    \"prefix\": \"place.stream\",\r\n    \"outdir\": \"./pkg/streamplace\",\r\n    \"import\": \"stream.place/streamplace\"\r\n  }\r\n]\r\n```\r\n\r\nThis is a great tool, makes writing Go XRPC handlers really easy, let's get it usable by the community!\r\n\r\nEDIT: Oh also I removed `--prefix` which was referenced by nobody and did nothing."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "LICENSE-DUAL\n@@ -2,7 +2,7 @@ Except as otherwise noted in individual files, this software is licensed under t\n \n Downstream projects and end users may chose either license individually, or both together, at their discretion. The motivation for this dual-licensing is the additional software patent assurance provided by Apache 2.0.\n \n-Copyright (c) 2022-2025 Bluesky PBC, @whyrusleeping, and Contributors\n+Copyright (c) 2022-2025 Bluesky Social PBC, @whyrusleeping, and Contributors\n \n MIT: https://www.opensource.org/licenses/mit\n Apache-2.0: https://www.apache.org/licenses/LICENSE-2.0\n---\nREADME.md\n@@ -56,7 +56,7 @@ The [HACKING](./HACKING.md) file has a list of commands and packages in this rep\n \n _not to be confused with the [AT command set](https://en.wikipedia.org/wiki/Hayes_command_set) or [Adenosine triphosphate](https://en.wikipedia.org/wiki/Adenosine_triphosphate)_\n \n-The Authenticated Transfer Protocol (\"ATP\" or \"atproto\") is a decentralized social media protocol, developed by [Bluesky PBC](https://bsky.social). Learn more at:\n+The Authenticated Transfer Protocol (\"ATP\" or \"atproto\") is a decentralized social media protocol, developed by [Bluesky Social PBC](https://bsky.social). Learn more at:\n \n - [Overview and Guides](https://atproto.com/guides/overview) \ud83d\udc48 Best starting point\n - [Github Discussions](https://github.com/bluesky-social/atproto/discussions) \ud83d\udc48 Great place to ask questions\n---\n"}], "ideal": "Title: use legally registered name for company\n\nBody: I had this wrong previously; the formal company name does include \"Social\"."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "events/consumer.go\n@@ -5,14 +5,19 @@ import (\n \t\"fmt\"\n \t\"io\"\n \t\"log/slog\"\n+\t\"math\"\n+\t\"math/rand/v2\"\n \t\"net\"\n+\t\"net/http\"\n+\t\"net/url\"\n+\t\"sync/atomic\"\n \t\"time\"\n \n \t\"github.com/RussellLuo/slidingwindow\"\n \tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n-\t\"github.com/prometheus/client_golang/prometheus\"\n-\n+\t\"github.com/carlmjohnson/versioninfo\"\n \t\"github.com/gorilla/websocket\"\n+\t\"github.com/prometheus/client_golang/prometheus\"\n )\n \n type RepoStreamCallbacks struct {\n@@ -112,17 +117,164 @@ func (sr *instrumentedReader) Read(p []byte) (int, error) {\n \treturn n, err\n }\n \n+// Options that control how we should subscribe to a remote event stream\n+type HandleRepoStreamRobustOptions struct {\n+\t// The cursor to use when dialing the remote repo (optional)\n+\tCursor *int\n+\n+\t// The dialer user to establish the websocket connection\n+\tDialer *websocket.Dialer\n+\n+\t// The list of HTTP headers to pass when establishing the websocket connection. If users do\n+\t// not supply a `User-Agent`, a default will be provided.\n+\tHeader http.Header\n+\n+\t// The maximum number of consecutive reconnects to try before shutting down\n+\tMaxReconnectAttempts int\n+\n+\t// Uses the default logger if none is provided\n+\tLog *slog.Logger\n+}\n+\n+// Constructs an options object with a set of sane default arguments that can be overridden by the user\n+func DefaultHandleRepoStreamRobustOptions() *HandleRepoStreamRobustOptions {\n+\treturn &HandleRepoStreamRobustOptions{\n+\t\tDialer:               websocket.DefaultDialer,\n+\t\tHeader:               http.Header{},\n+\t\tMaxReconnectAttempts: 10,\n+\t\tLog:                  slog.Default().With(\"system\", \"events\"),\n+\t}\n+}\n+\n+// The same as `HandleRepoStream`, but with auto-reconnects in the case of upstream disconnects. `fullURL` must be\n+// the entire URL to which we will connect (i.e. `wss://example.com:8080/xrpc/com.atproto.sync.subscribeRepos`).\n+func HandleRepoStreamRobust(ctx context.Context, fullURL string, sched Scheduler, opts *HandleRepoStreamRobustOptions) error {\n+\tif fullURL == \"\" {\n+\t\treturn fmt.Errorf(\"fullURL is required\")\n+\t}\n+\tif sched == nil {\n+\t\treturn fmt.Errorf(\"sched is required\")\n+\t}\n+\tif opts == nil {\n+\t\treturn fmt.Errorf(\"invalid HandleRepoStreamRobust options\")\n+\t}\n+\n+\t// Set defaults if not provided\n+\tif opts.Dialer == nil {\n+\t\topts.Dialer = websocket.DefaultDialer\n+\t}\n+\tif opts.Header == nil {\n+\t\topts.Header = http.Header{}\n+\t}\n+\tif opts.Header.Get(\"User-Agent\") == \"\" {\n+\t\topts.Header.Set(\"User-Agent\", \"indigo/\"+versioninfo.Short())\n+\t}\n+\n+\tupstream, err := url.Parse(fullURL)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"invalid upstream url %q: %w\", fullURL, err)\n+\t}\n+\n+\tdefer sched.Shutdown()\n+\n+\t// Wrap all applicable event callbacks to track the cursor sequence number\n+\t// so we're up-to-date when attempting to reconnect\n+\tmonitor := newMonitoredScheduler(sched)\n+\tif opts.Cursor != nil {\n+\t\tmonitor.cursor.Store(int64(*opts.Cursor))\n+\t}\n+\n+\tfailures := 0\n+\tfor failures <= opts.MaxReconnectAttempts {\n+\t\tcursor := monitor.cursor.Load()\n+\t\tif cursor >= 0 {\n+\t\t\tupstream.RawQuery = fmt.Sprintf(\"cursor=%d\", cursor)\n+\t\t}\n+\n+\t\tcon, _, err := opts.Dialer.DialContext(ctx, upstream.String(), opts.Header)\n+\t\tif err != nil {\n+\t\t\tif failures >= opts.MaxReconnectAttempts {\n+\t\t\t\treturn fmt.Errorf(\"failed to dial host (max retries exceeded): %w\", err)\n+\t\t\t}\n+\n+\t\t\ttime.Sleep(backoffDuration(failures))\n+\t\t\tfailures++\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tmsgRead := false\n+\t\terr = handleRepoStream(ctx, con, monitor, opts.Log, &msgRead)\n+\t\tif msgRead {\n+\t\t\t// reset the failure counter\n+\t\t\tfailures = 0\n+\t\t}\n+\t\tif err != nil {\n+\t\t\tif failures >= opts.MaxReconnectAttempts {\n+\t\t\t\treturn fmt.Errorf(\"failed to stream from repo: %w\", err)\n+\t\t\t}\n+\n+\t\t\ttime.Sleep(backoffDuration(failures))\n+\t\t\tfailures++\n+\t\t\tcontinue\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+type monitoredScheduler struct {\n+\tsched  Scheduler\n+\tcursor atomic.Int64\n+}\n+\n+func newMonitoredScheduler(sched Scheduler) *monitoredScheduler {\n+\tms := &monitoredScheduler{sched: sched}\n+\tms.cursor.Store(-1)\n+\treturn ms\n+}\n+\n+func (s *monitoredScheduler) AddWork(ctx context.Context, repo string, xev *XRPCStreamEvent) error {\n+\tif seq, ok := xev.GetSequence(); ok {\n+\t\ts.cursor.Store(seq)\n+\t}\n+\n+\treturn s.sched.AddWork(ctx, repo, xev)\n+}\n+\n+func (s *monitoredScheduler) Shutdown() {\n+\ts.sched.Shutdown()\n+}\n+\n+func backoffDuration(retry int) time.Duration {\n+\tbaseMS := float64(50)\n+\n+\t// Exponential backoff: 2^retry * base\n+\tdurationMS := math.Pow(2, float64(retry)) * baseMS\n+\n+\t// Clamp\n+\tdurationMS = min(1000, durationMS)\n+\n+\t// Add jitter\n+\tjitter := durationMS * (0.25 + rand.Float64())\n+\n+\treturn time.Duration(jitter) * time.Millisecond\n+}\n+\n // HandleRepoStream\n // con is source of events\n // sched gets AddWork for each event\n // log may be nil for default logger\n func HandleRepoStream(ctx context.Context, con *websocket.Conn, sched Scheduler, log *slog.Logger) error {\n+\tdefer sched.Shutdown()\n+\treturn handleRepoStream(ctx, con, sched, log, nil)\n+}\n+\n+func handleRepoStream(ctx context.Context, con *websocket.Conn, sched Scheduler, log *slog.Logger, msgRead *bool) error {\n \tif log == nil {\n \t\tlog = slog.Default().With(\"system\", \"events\")\n \t}\n \tctx, cancel := context.WithCancel(ctx)\n \tdefer cancel()\n-\tdefer sched.Shutdown()\n \n \tremoteAddr := con.RemoteAddr().String()\n \n@@ -183,6 +335,9 @@ func HandleRepoStream(ctx context.Context, con *websocket.Conn, sched Scheduler,\n \t\tif err != nil {\n \t\t\treturn fmt.Errorf(\"con err at read: %w\", err)\n \t\t}\n+\t\tif msgRead != nil {\n+\t\t\t*msgRead = true\n+\t\t}\n \n \t\tswitch mt {\n \t\tdefault:\n---\n"}], "ideal": "Title: subscribeRepos Client Reconnects\n\nBody: We've been seeing periodic cases where firehose subscribers get booted off because they [fail to keep up](https://github.com/bluesky-social/indigo/blob/9c19d0c438ef38657dff9f2f55caa167271287c4/cmd/relay/stream/eventmgr/event_manager.go#L70-L94). Thus far, we've seen this during network turbulence events with one of our ISPs.\r\n\r\nThe candidate solution here is to add some number of retries on websocket closures now that the firehose will properly clean up network conns if the consumer is too slow (#1066).\r\n\r\nI was looking at splitter.go's [subscribeWithRedialer](https://github.com/bluesky-social/indigo/blob/9c19d0c438ef38657dff9f2f55caa167271287c4/splitter/splitter.go#L354) as prior art, but I wanted to specifically check for certain retry-able errors and not infinite loop.\r\n\r\nI hemmed and hawed about the look of this API as well as the function name for a while as well since there are a lot of options being passed in, and I eventually opted for a struct with a default function. IMO it's the simplest API to use, and it provides reasonable defaults. If there's a better pattern, I'm 100% game for that though."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/goat/blob.go\n@@ -113,7 +113,8 @@ func runBlobExport(cctx *cli.Context) error {\n \t\t\t}\n \t\t\tblobBytes, err := comatproto.SyncGetBlob(ctx, &xrpcc, cidStr, ident.DID.String())\n \t\t\tif err != nil {\n-\t\t\t\treturn err\n+\t\t\t\tfmt.Printf(\"%s\\tfailed %s\\n\", blobPath, err)\n+\t\t\t\tcontinue\n \t\t\t}\n \t\t\tif err := os.WriteFile(blobPath, blobBytes, 0666); err != nil {\n \t\t\t\treturn err\n---\n"}], "ideal": "Title: Changed error handling during blob export command in goat to help with account migration\n\nBody: Prints the error and continues rather than bailing entirely during blob export. Slightly worse in the \"i have a connection problem\" scenario, but means repository exports where some blobs are missing actually work now rather than getting stuck.\r\n\r\nWas trying to migrate my main to my own PDS and ran into it, and figured addressing it would be both simple enough and useful to others trying to do the same."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/testing/consumer.go\n@@ -27,7 +27,7 @@ type Consumer struct {\n func NewConsumer(host string) *Consumer {\n \tc := Consumer{\n \t\tHost:    host,\n-\t\tTimeout: time.Second * 3,\n+\t\tTimeout: time.Second * 10,\n \t}\n \treturn &c\n }\n---\n"}], "ideal": "Title: bump relay integration test timeout from 3s to 10s\n\nBody: Trying to reduce the frequency of flakey test failures in github actions CI. Suspect this is due to over-utilized test runners.\r\n\r\nThis should not impact \"happy path\" (tests passing), but makes working on the tests a bit annoying. Might be possible to check env vars to see if the test is running in CI and have a different timeout for that situation."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/stream/eventmgr/event_manager.go\n@@ -168,13 +168,20 @@ func (em *EventManager) Subscribe(ctx context.Context, ident string, filter func\n \t\t\t}\n \n \t\t\t// TODO: send an error frame or something?\n+\t\t\t// NOTE: not doing em.rmSubscriber(sub) here because it hasn't been added yet\n \t\t\tclose(out)\n \t\t\treturn\n \t\t}\n \n \t\t// now, start buffering events from the live stream\n \t\tem.addSubscriber(sub)\n \n+\t\t// ensure that we clean up any return paths from here out, after having added the subscriber. Note that `out` is not `sub.output`, so needs to be closed separately.\n+\t\tdefer func() {\n+\t\t\tclose(out)\n+\t\t\tem.rmSubscriber(sub)\n+\t\t}()\n+\n \t\tfirst := <-sub.outgoing\n \n \t\t// run playback again to get us to the events that have started buffering\n@@ -193,10 +200,6 @@ func (em *EventManager) Subscribe(ctx context.Context, ident string, filter func\n \t\t}); err != nil {\n \t\t\tif !errors.Is(err, ErrCaughtUp) {\n \t\t\t\tem.log.Error(\"events playback\", \"err\", err)\n-\n-\t\t\t\t// TODO: send an error frame or something?\n-\t\t\t\tclose(out)\n-\t\t\t\tem.rmSubscriber(sub)\n \t\t\t\treturn\n \t\t\t}\n \t\t}\n@@ -206,7 +209,6 @@ func (em *EventManager) Subscribe(ctx context.Context, ident string, filter func\n \t\t\tselect {\n \t\t\tcase out <- evt:\n \t\t\tcase <-done:\n-\t\t\t\tem.rmSubscriber(sub)\n \t\t\t\treturn\n \t\t\t}\n \t\t}\n---\nevents/events.go\n@@ -415,13 +415,20 @@ func (em *EventManager) Subscribe(ctx context.Context, ident string, filter func\n \t\t\t}\n \n \t\t\t// TODO: send an error frame or something?\n+\t\t\t// NOTE: not doing em.rmSubscriber(sub) here because it hasn't been added yet\n \t\t\tclose(out)\n \t\t\treturn\n \t\t}\n \n \t\t// now, start buffering events from the live stream\n \t\tem.addSubscriber(sub)\n \n+\t\t// ensure that we clean up any return paths from here out, after having added the subscriber. Note that `out` is not `sub.output`, so needs to be closed separately.\n+\t\tdefer func() {\n+\t\t\tclose(out)\n+\t\t\tem.rmSubscriber(sub)\n+\t\t}()\n+\n \t\tfirst := <-sub.outgoing\n \n \t\t// run playback again to get us to the events that have started buffering\n@@ -440,10 +447,6 @@ func (em *EventManager) Subscribe(ctx context.Context, ident string, filter func\n \t\t}); err != nil {\n \t\t\tif !errors.Is(err, ErrCaughtUp) {\n \t\t\t\tem.log.Error(\"events playback\", \"err\", err)\n-\n-\t\t\t\t// TODO: send an error frame or something?\n-\t\t\t\tclose(out)\n-\t\t\t\tem.rmSubscriber(sub)\n \t\t\t\treturn\n \t\t\t}\n \t\t}\n@@ -453,7 +456,6 @@ func (em *EventManager) Subscribe(ctx context.Context, ident string, filter func\n \t\t\tselect {\n \t\t\tcase out <- evt:\n \t\t\tcase <-done:\n-\t\t\t\tem.rmSubscriber(sub)\n \t\t\t\treturn\n \t\t\t}\n \t\t}\n---\n"}], "ideal": "Title: bgs: ensure output channel is closed if it isn't sub.output\n\nBody: The issue here is that when a cursor is supplied, sub.output isn't actually the channel which is passed along to calling code; the 'out' chan is what gets returned.\r\n\r\nThis means that sub.output getting closed needs to be wired through to 'out' getting closed as well.\r\n\r\nNOTE: this is in old relay code (\"BGS\"). If we like this fix, should copy it to new relay code (`indigo:cmd/relay/stream`) before merging."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/relay/host.go\n@@ -38,7 +38,7 @@ func (r *Relay) GetHostByID(ctx context.Context, hostID uint64) (*models.Host, e\n \tdefer span.End()\n \n \tvar host models.Host\n-\tif err := r.db.WithContext(ctx).Find(&host, hostID).Error; err != nil {\n+\tif err := r.db.WithContext(ctx).First(&host, hostID).Error; err != nil {\n \t\tif errors.Is(err, gorm.ErrRecordNotFound) {\n \t\t\treturn nil, ErrHostNotFound\n \t\t}\n@@ -125,7 +125,7 @@ func (r *Relay) UpdateHostAccountLimit(ctx context.Context, hostID uint64, accou\n //\n // Note that in some situations this may have partial success.\n func (r *Relay) PersistHostCursors(ctx context.Context, cursors *[]HostCursor) error {\n-\ttx := r.db.WithContext(ctx).WithContext(ctx).Begin()\n+\ttx := r.db.WithContext(ctx).Begin()\n \tfor _, cur := range *cursors {\n \t\tif cur.LastSeq <= 0 {\n \t\t\tcontinue\n---\n"}], "ideal": "Title: Small cleanup for relay host code\n\nBody: Minor changes: \r\n\r\n1. Removes duplicate WithContext() call\r\n2. Uses `First()` instead of `Find()` where only one struct is expected"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/crypto/jwk.go\n@@ -0,0 +1,124 @@\n+package crypto\n+\n+import (\n+\t\"crypto/ecdsa\"\n+\t\"crypto/elliptic\"\n+\t\"encoding/base64\"\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\t\"math/big\"\n+\n+\tsecp256k1 \"gitlab.com/yawning/secp256k1-voi\"\n+\tsecp256k1secec \"gitlab.com/yawning/secp256k1-voi/secec\"\n+)\n+\n+// Representation of a JSON Web Key (JWK), as relevant to the keys supported by this package.\n+//\n+// Expected to be marshalled/unmarshalled as JSON.\n+type JWK struct {\n+\tKeyType string  `json:\"kty\"`\n+\tCurve   string  `json:\"crv\"`\n+\tX       string  `json:\"x\"` // base64url, no padding\n+\tY       string  `json:\"y\"` // base64url, no padding\n+\tUse     string  `json:\"use,omitempty\"`\n+\tKeyID   *string `json:\"kid,omitempty\"`\n+}\n+\n+// Loads a [PublicKey] from JWK (serialized as JSON bytes)\n+func ParsePublicJWKBytes(jwkBytes []byte) (PublicKey, error) {\n+\tvar jwk JWK\n+\tif err := json.Unmarshal(jwkBytes, &jwk); err != nil {\n+\t\treturn nil, fmt.Errorf(\"parsing JWK JSON: %w\", err)\n+\t}\n+\treturn ParsePublicJWK(jwk)\n+}\n+\n+// Loads a [PublicKey] from JWK struct.\n+func ParsePublicJWK(jwk JWK) (PublicKey, error) {\n+\n+\tif jwk.KeyType != \"EC\" {\n+\t\treturn nil, fmt.Errorf(\"unsupported JWK key type: %s\", jwk.KeyType)\n+\t}\n+\n+\t// base64url with no encoding\n+\txbuf, err := base64.RawURLEncoding.DecodeString(jwk.X)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"invalid JWK base64 encoding: %w\", err)\n+\t}\n+\tybuf, err := base64.RawURLEncoding.DecodeString(jwk.Y)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"invalid JWK base64 encoding: %w\", err)\n+\t}\n+\n+\tswitch jwk.Curve {\n+\tcase \"P-256\":\n+\t\tcurve := elliptic.P256()\n+\n+\t\tvar x, y big.Int\n+\t\tx.SetBytes(xbuf)\n+\t\ty.SetBytes(ybuf)\n+\n+\t\tif !curve.Params().IsOnCurve(&x, &y) {\n+\t\t\treturn nil, fmt.Errorf(\"invalid P-256 public key (not on curve)\")\n+\t\t}\n+\t\tpubECDSA := &ecdsa.PublicKey{\n+\t\t\tCurve: curve,\n+\t\t\tX:     &x,\n+\t\t\tY:     &y,\n+\t\t}\n+\t\tpub := PublicKeyP256{pubP256: *pubECDSA}\n+\t\terr := pub.checkCurve()\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\treturn &pub, nil\n+\tcase \"secp256k1\": // K-256\n+\t\tif len(xbuf) != 32 || len(ybuf) != 32 {\n+\t\t\treturn nil, fmt.Errorf(\"invalid K-256 coordinates\")\n+\t\t}\n+\t\txarr := ([32]byte)(xbuf[:32])\n+\t\tyarr := ([32]byte)(ybuf[:32])\n+\t\tp, err := secp256k1.NewPointFromCoords(&xarr, &yarr)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"invalid K-256 coordinates: %w\", err)\n+\t\t}\n+\t\tpubK, err := secp256k1secec.NewPublicKeyFromPoint(p)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"invalid K-256/secp256k1 public key: %w\", err)\n+\t\t}\n+\t\tpub := PublicKeyK256{pubK256: pubK}\n+\t\terr = pub.ensureBytes()\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\treturn &pub, nil\n+\tdefault:\n+\t\treturn nil, fmt.Errorf(\"unsupported JWK cryptography: %s\", jwk.Curve)\n+\t}\n+}\n+\n+func (k *PublicKeyP256) JWK() (*JWK, error) {\n+\tjwk := JWK{\n+\t\tKeyType: \"EC\",\n+\t\tCurve:   \"P-256\",\n+\t\tX:       base64.RawURLEncoding.EncodeToString(k.pubP256.X.Bytes()),\n+\t\tY:       base64.RawURLEncoding.EncodeToString(k.pubP256.Y.Bytes()),\n+\t}\n+\treturn &jwk, nil\n+}\n+\n+func (k *PublicKeyK256) JWK() (*JWK, error) {\n+\traw := k.UncompressedBytes()\n+\tif len(raw) != 65 {\n+\t\treturn nil, fmt.Errorf(\"unexpected K-256 bytes size\")\n+\t}\n+\txbytes := raw[1:33]\n+\tybytes := raw[33:65]\n+\tjwk := JWK{\n+\t\tKeyType: \"EC\",\n+\t\tCurve:   \"secp256k1\",\n+\t\tX:       base64.RawURLEncoding.EncodeToString(xbytes),\n+\t\tY:       base64.RawURLEncoding.EncodeToString(ybytes),\n+\t}\n+\treturn &jwk, nil\n+}\n---\natproto/crypto/jwk_test.go\n@@ -0,0 +1,98 @@\n+package crypto\n+\n+import (\n+\t\"testing\"\n+\n+\t\"github.com/stretchr/testify/assert\"\n+)\n+\n+func TestParseJWK(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\tjwkTestFixtures := []string{\n+\t\t// https://datatracker.ietf.org/doc/html/rfc7517#appendix-A.1\n+\t\t`{\n+\t\t\t\"kty\":\"EC\",\n+          \t\"crv\":\"P-256\",\n+          \t\"x\":\"MKBCTNIcKUSDii11ySs3526iDZ8AiTo7Tu6KPAqv7D4\",\n+          \t\"y\":\"4Etl6SRW2YiLUrN5vfvVHuhp7x8PxltmWWlbbM4IFyM\",\n+          \t\"d\":\"870MB6gfuTJ4HtUnUvYMyJpr5eUZNP4Bk43bVdj3eAE\",\n+          \t\"use\":\"enc\",\n+          \t\"kid\":\"1\"\n+      \t}`,\n+\t\t// https://openid.net/specs/draft-jones-json-web-key-03.html; with kty in addition to alg\n+\t\t`{\n+\t\t\t\"alg\":\"EC\",\n+\t\t\t\"kty\":\"EC\",\n+\t\t\t\"crv\":\"P-256\",\n+\t\t\t\"x\":\"MKBCTNIcKUSDii11ySs3526iDZ8AiTo7Tu6KPAqv7D4\",\n+\t\t\t\"y\":\"4Etl6SRW2YiLUrN5vfvVHuhp7x8PxltmWWlbbM4IFyM\",\n+\t\t\t\"use\":\"enc\",\n+\t\t\t\"kid\":\"1\"\n+\t\t}`,\n+\t\t// https://w3c-ccg.github.io/lds-ecdsa-secp256k1-2019/; with kty in addition to alg\n+\t\t`{\n+    \t\t\"alg\": \"EC\",\n+    \t\t\"kty\": \"EC\",\n+    \t\t\"crv\": \"secp256k1\",\n+    \t\t\"kid\": \"JUvpllMEYUZ2joO59UNui_XYDqxVqiFLLAJ8klWuPBw\",\n+    \t\t\"x\": \"dWCvM4fTdeM0KmloF57zxtBPXTOythHPMm1HCLrdd3A\",\n+    \t\t\"y\": \"36uMVGM7hnw-N6GnjFcihWE3SkrhMLzzLCdPMXPEXlA\"\n+  \t\t}`,\n+\t}\n+\n+\tfor _, jwkBytes := range jwkTestFixtures {\n+\t\t_, err := ParsePublicJWKBytes([]byte(jwkBytes))\n+\t\tassert.NoError(err)\n+\t}\n+}\n+\n+func TestP256GenJWK(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\tpriv, err := GeneratePrivateKeyP256()\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tpub, err := priv.PublicKey()\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tpk, ok := pub.(*PublicKeyP256)\n+\tif !ok {\n+\t\tt.Fatal()\n+\t}\n+\tjwk, err := pk.JWK()\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\t_, err = ParsePublicJWK(*jwk)\n+\tassert.NoError(err)\n+}\n+\n+func TestK256GenJWK(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\tpriv, err := GeneratePrivateKeyK256()\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\tpub, err := priv.PublicKey()\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\tpk, ok := pub.(*PublicKeyK256)\n+\tif !ok {\n+\t\tt.Fatal()\n+\t}\n+\tjwk, err := pk.JWK()\n+\tif err != nil {\n+\t\tt.Fatal(err)\n+\t}\n+\n+\t_, err = ParsePublicJWK(*jwk)\n+\tassert.NoError(err)\n+}\n---\natproto/crypto/keys.go\n@@ -63,6 +63,9 @@ type PublicKey interface {\n \t// For systems with no compressed/uncompressed distinction, returns the same\n \t// value as Bytes().\n \tUncompressedBytes() []byte\n+\n+\t// Serialization as JWK struct (which can be marshalled to JSON)\n+\tJWK() (*JWK, error)\n }\n \n var ErrInvalidSignature = errors.New(\"crytographic signature invalid\")\n---\n"}], "ideal": "Title: basic JWK support in crypto SDK\n\nBody: Basic JWK serialization of the curves we use for atproto crypto (P-256, K-256), for public keys only. This will get used in OAuth implementation.\r\n\r\nThe decision to implement this directly instead of using something like https://github.com/lestrrat-go/jwx is entangled with deciding to use `golang-jwt` for service auth implementation (which is distinct from OAuth implementation, and doesn't directly require JWKs). I think the secp256k1 experimental support in `jwx/jwt` would pull in a new dependency/implementation, and I like our current choice, and it doesn't seem as easy to wedge in a new curve type/implementation with `jwx` family of packages.\r\n\r\nOn the other hand, I sure don't love parsing those uncompressed bytes out in to `(x, y)` coordinates!\r\n\r\nI thought about only exposing `[]byte` JSON instead of the `JWK` struct itself, but feels more idiomatic and flexible to just expose the struct. For example, will make it easier for calling code to deal with JWK sets (arrays of keys, used in OAuth client metadata)."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "util/ssrf/ssrf.go\n@@ -0,0 +1,128 @@\n+/*\n+ * Written in 2019 by Andrew Ayer.\n+ * Patched 2025, Bluesky Social PBC.\n+ *\n+ * Original: https://www.agwa.name/blog/post/preventing_server_side_request_forgery_in_golang\n+ *\n+ * To the extent possible under law, the author(s) have dedicated all\n+ * copyright and related and neighboring rights to this software to the\n+ * public domain worldwide. This software is distributed without any\n+ * warranty.\n+ *\n+ * You should have received a copy of the CC0 Public\n+ * Domain Dedication along with this software. If not, see\n+ * <https://creativecommons.org/publicdomain/zero/1.0/>.\n+ */\n+package ssrf\n+\n+import (\n+\t\"fmt\"\n+\t\"net\"\n+\t\"net/http\"\n+\t\"syscall\"\n+\t\"time\"\n+)\n+\n+func ipv4Net(a, b, c, d byte, subnetPrefixLen int) net.IPNet {\n+\treturn net.IPNet{\n+\t\tIP:   net.IPv4(a, b, c, d),\n+\t\tMask: net.CIDRMask(96+subnetPrefixLen, 128),\n+\t}\n+}\n+\n+var reservedIPv4Nets = []net.IPNet{\n+\tipv4Net(0, 0, 0, 0, 8),       // Current network\n+\tipv4Net(10, 0, 0, 0, 8),      // Private\n+\tipv4Net(100, 64, 0, 0, 10),   // RFC6598\n+\tipv4Net(127, 0, 0, 0, 8),     // Loopback\n+\tipv4Net(169, 254, 0, 0, 16),  // Link-local\n+\tipv4Net(172, 16, 0, 0, 12),   // Private\n+\tipv4Net(192, 0, 0, 0, 24),    // RFC6890\n+\tipv4Net(192, 0, 2, 0, 24),    // Test, doc, examples\n+\tipv4Net(192, 88, 99, 0, 24),  // IPv6 to IPv4 relay\n+\tipv4Net(192, 168, 0, 0, 16),  // Private\n+\tipv4Net(198, 18, 0, 0, 15),   // Benchmarking tests\n+\tipv4Net(198, 51, 100, 0, 24), // Test, doc, examples\n+\tipv4Net(203, 0, 113, 0, 24),  // Test, doc, examples\n+\tipv4Net(224, 0, 0, 0, 4),     // Multicast\n+\tipv4Net(240, 0, 0, 0, 4),     // Reserved (includes broadcast / 255.255.255.255)\n+}\n+\n+var globalUnicastIPv6Net = net.IPNet{\n+\tIP:   net.IP{0x20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},\n+\tMask: net.CIDRMask(3, 128),\n+}\n+\n+func isIPv6GlobalUnicast(address net.IP) bool {\n+\treturn globalUnicastIPv6Net.Contains(address)\n+}\n+\n+func isIPv4Reserved(address net.IP) bool {\n+\tfor _, reservedNet := range reservedIPv4Nets {\n+\t\tif reservedNet.Contains(address) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+func IsPublicIPAddress(address net.IP) bool {\n+\tif address.To4() != nil {\n+\t\treturn !isIPv4Reserved(address)\n+\t} else {\n+\t\treturn isIPv6GlobalUnicast(address)\n+\t}\n+}\n+\n+// Implementation of [net.Dialer] `Control` field (a function) which avoids some SSRF attacks by rejecting local IPv4 and IPv6 address ranges, and only allowing ports 80 or 443.\n+func PublicOnlyControl(network string, address string, conn syscall.RawConn) error {\n+\tif !(network == \"tcp4\" || network == \"tcp6\") {\n+\t\treturn fmt.Errorf(\"%s is not a safe network type\", network)\n+\t}\n+\n+\thost, port, err := net.SplitHostPort(address)\n+\tif err != nil {\n+\t\treturn fmt.Errorf(\"%s is not a valid host/port pair: %s\", address, err)\n+\t}\n+\n+\tipaddress := net.ParseIP(host)\n+\tif ipaddress == nil {\n+\t\treturn fmt.Errorf(\"%s is not a valid IP address\", host)\n+\t}\n+\n+\tif !IsPublicIPAddress(ipaddress) {\n+\t\treturn fmt.Errorf(\"%s is not a public IP address\", ipaddress)\n+\t}\n+\n+\tif !(port == \"80\" || port == \"443\") {\n+\t\treturn fmt.Errorf(\"%s is not a safe port number\", port)\n+\t}\n+\n+\treturn nil\n+}\n+\n+// [net.Dialer] with [PublicOnlyControl] for `Control` function (for SSRF protection). Other fields are same default values as standard library.\n+func PublicOnlyDialer() *net.Dialer {\n+\treturn &net.Dialer{\n+\t\tTimeout:   30 * time.Second,\n+\t\tKeepAlive: 30 * time.Second,\n+\t\tDualStack: true,\n+\t\tControl:   PublicOnlyControl,\n+\t}\n+}\n+\n+// [http.Transport] with [PublicOnlyDialer] for `DialContext` field (for SSRF protection). Other fields are same default values as standard library.\n+//\n+// Use this in an [http.Client] like: `c := http.Client{ Transport: PublicOnlyTransport() }`\n+func PublicOnlyTransport() *http.Transport {\n+\tdialer := PublicOnlyDialer()\n+\treturn &http.Transport{\n+\t\tProxy:                 http.ProxyFromEnvironment,\n+\t\tDialContext:           dialer.DialContext,\n+\t\tForceAttemptHTTP2:     true,\n+\t\tMaxIdleConns:          100,\n+\t\tIdleConnTimeout:       90 * time.Second,\n+\t\tTLSHandshakeTimeout:   10 * time.Second,\n+\t\tExpectContinueTimeout: 1 * time.Second,\n+\t}\n+}\n---\nutil/ssrf/ssrf_test.go\n@@ -0,0 +1,32 @@\n+package ssrf\n+\n+import (\n+\t\"net/http\"\n+\t\"testing\"\n+\n+\t\"github.com/stretchr/testify/assert\"\n+)\n+\n+func TestPublicOnlyTransport(t *testing.T) {\n+\tt.Skip(\"skipping local SSRF test\")\n+\tassert := assert.New(t)\n+\n+\tc := http.Client{\n+\t\tTransport: PublicOnlyTransport(),\n+\t}\n+\n+\t{\n+\t\t_, err := c.Get(\"http://127.0.0.1:2470/\")\n+\t\tassert.Error(err)\n+\t}\n+\n+\t{\n+\t\t_, err := c.Get(\"http://localhost:2470/path\")\n+\t\tassert.Error(err)\n+\t}\n+\n+\t{\n+\t\t_, err := c.Get(\"http://bsky.app:8080/path\")\n+\t\tassert.Error(err)\n+\t}\n+}\n---\n"}], "ideal": "Title: basic IP filtering net.Dialer for SSRF protection\n\nBody: Pulls in code from this 2019 blog post which still seems like the best pattern: https://www.agwa.name/blog/post/preventing_server_side_request_forgery_in_golang\r\n\r\nI looked around a bit and there are some packages that do similar things, but this seemed the best, and only a few dozen lines of code so just vendoring it in.\r\n\r\nThis code has no deps, so I put it in a sub-package of `util`, which will make it painless to depend on from other code (eg, OAuth client, relay) without entangling with any new deps."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/goat/plc.go\n@@ -11,6 +11,7 @@ import (\n \n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n+\t\"github.com/bluesky-social/indigo/util\"\n \n \t\"github.com/urfave/cli/v2\"\n )\n@@ -46,10 +47,26 @@ var cmdPLC = &cli.Command{\n \t\t\tUsage: \"output full operation log, as JSON lines\",\n \t\t\tFlags: []cli.Flag{\n \t\t\t\t&cli.StringFlag{\n-\t\t\t\t\tName: \"cursor\",\n+\t\t\t\t\tName:    \"cursor\",\n+\t\t\t\t\tAliases: []string{\"c\"},\n+\t\t\t\t\tUsage:   \"start at a given cursor offset (timestamp). use 'now' to start at current time\",\n \t\t\t\t},\n \t\t\t\t&cli.BoolFlag{\n-\t\t\t\t\tName: \"tail\",\n+\t\t\t\t\tName:    \"tail\",\n+\t\t\t\t\tAliases: []string{\"f\"},\n+\t\t\t\t\tUsage:   \"continue streaming PLC ops after reaching the end of log\",\n+\t\t\t\t},\n+\t\t\t\t&cli.DurationFlag{\n+\t\t\t\t\tName:    \"interval\",\n+\t\t\t\t\tAliases: []string{\"i\"},\n+\t\t\t\t\tValue:   3 * time.Second,\n+\t\t\t\t\tUsage:   \"sleep duration between batches for tail mode\",\n+\t\t\t\t},\n+\t\t\t\t&cli.IntFlag{\n+\t\t\t\t\tName:    \"batch-size\",\n+\t\t\t\t\tAliases: []string{\"s\"},\n+\t\t\t\t\tValue:   1000,\n+\t\t\t\t\tUsage:   \"batch size of operations per HTTP API request\",\n \t\t\t\t},\n \t\t\t},\n \t\t\tAction: runPLCDump,\n@@ -179,8 +196,10 @@ func runPLCData(cctx *cli.Context) error {\n func runPLCDump(cctx *cli.Context) error {\n \tctx := context.Background()\n \tplcHost := cctx.String(\"plc-host\")\n-\tclient := http.DefaultClient\n+\tclient := util.RobustHTTPClient()\n+\tsize := cctx.Int(\"batch-size\")\n \ttailMode := cctx.Bool(\"tail\")\n+\tinterval := cctx.Duration(\"interval\")\n \n \tcursor := cctx.String(\"cursor\")\n \tif cursor == \"now\" {\n@@ -193,7 +212,7 @@ func runPLCDump(cctx *cli.Context) error {\n \t\treturn err\n \t}\n \tq := req.URL.Query()\n-\tq.Add(\"count\", \"1000\")\n+\tq.Add(\"count\", fmt.Sprintf(\"%d\", size))\n \treq.URL.RawQuery = q.Encode()\n \n \tfor {\n@@ -218,7 +237,7 @@ func runPLCDump(cctx *cli.Context) error {\n \t\tlines := strings.Split(string(respBytes), \"\\n\")\n \t\tif len(lines) == 0 || (len(lines) == 1 && len(lines[0]) == 0) {\n \t\t\tif tailMode {\n-\t\t\t\ttime.Sleep(5 * time.Second)\n+\t\t\t\ttime.Sleep(interval)\n \t\t\t\tcontinue\n \t\t\t}\n \t\t\tbreak\n@@ -249,7 +268,7 @@ func runPLCDump(cctx *cli.Context) error {\n \t\t}\n \t\tif cursor != \"\" && cursor == lastCursor {\n \t\t\tif tailMode {\n-\t\t\t\ttime.Sleep(5 * time.Second)\n+\t\t\t\ttime.Sleep(interval)\n \t\t\t\tcontinue\n \t\t\t}\n \t\t\tbreak\n---\n"}], "ideal": "Title: goat: more plc dump args/ergonomics\n\nBody: Will probably self-merge."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "Makefile\n@@ -16,6 +16,7 @@ help: ## Print info about all commands\n \n .PHONY: build\n build: ## Build all executables\n+\tgo build ./cmd/goat\n \tgo build ./cmd/gosky\n \tgo build ./cmd/bigsky\n \tgo build ./cmd/relay\n---\ncmd/goat/relay.go\n@@ -1,8 +1,10 @@\n package main\n \n import (\n+\t\"context\"\n \t\"encoding/json\"\n \t\"fmt\"\n+\t\"sort\"\n \n \tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n@@ -93,6 +95,23 @@ var cmdRelay = &cli.Command{\n \t\t\t\t\t},\n \t\t\t\t\tAction: runRelayHostStatus,\n \t\t\t\t},\n+\t\t\t\t&cli.Command{\n+\t\t\t\t\tName:      \"diff\",\n+\t\t\t\t\tUsage:     \"compare host set (and seq) between two relay instances\",\n+\t\t\t\t\tArgsUsage: `<relay-A-url> <relay-B-url>`,\n+\t\t\t\t\tFlags: []cli.Flag{\n+\t\t\t\t\t\t&cli.BoolFlag{\n+\t\t\t\t\t\t\tName:  \"verbose\",\n+\t\t\t\t\t\t\tUsage: \"print all hosts\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t\t&cli.IntFlag{\n+\t\t\t\t\t\t\tName:  \"seq-slop\",\n+\t\t\t\t\t\t\tValue: 100,\n+\t\t\t\t\t\t\tUsage: \"sequence delta allowed as close enough\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t\tAction: runRelayHostDiff,\n+\t\t\t\t},\n \t\t\t},\n \t\t},\n \t\tcmdRelayAdmin,\n@@ -326,3 +345,125 @@ func runRelayHostStatus(cctx *cli.Context) error {\n \n \treturn nil\n }\n+\n+type hostInfo struct {\n+\tHostname string\n+\tStatus   string\n+\tSeq      int64\n+}\n+\n+func fetchHosts(ctx context.Context, relayHost string) ([]hostInfo, error) {\n+\n+\tclient := xrpc.Client{\n+\t\tHost: relayHost,\n+\t}\n+\n+\thosts := []hostInfo{}\n+\tcursor := \"\"\n+\tvar size int64 = 500\n+\tfor {\n+\t\tresp, err := comatproto.SyncListHosts(ctx, &client, cursor, size)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\n+\t\tfor _, h := range resp.Hosts {\n+\t\t\tif h.Status == nil || h.Seq == nil || *h.Seq <= 0 {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\t// TODO: only active or idle hosts?\n+\t\t\tinfo := hostInfo{\n+\t\t\t\tHostname: h.Hostname,\n+\t\t\t\tStatus:   *h.Status,\n+\t\t\t\tSeq:      *h.Seq,\n+\t\t\t}\n+\t\t\thosts = append(hosts, info)\n+\t\t}\n+\n+\t\tif resp.Cursor == nil || *resp.Cursor == \"\" {\n+\t\t\tbreak\n+\t\t}\n+\t\tcursor = *resp.Cursor\n+\t}\n+\treturn hosts, nil\n+}\n+\n+func runRelayHostDiff(cctx *cli.Context) error {\n+\tctx := cctx.Context\n+\tverbose := cctx.Bool(\"verbose\")\n+\tseqSlop := cctx.Int64(\"seq-slop\")\n+\n+\tif cctx.Args().Len() != 2 {\n+\t\treturn fmt.Errorf(\"expected two relay URLs are args\")\n+\t}\n+\n+\turlOne := cctx.Args().Get(0)\n+\turlTwo := cctx.Args().Get(1)\n+\n+\tlistOne, err := fetchHosts(ctx, urlOne)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tlistTwo, err := fetchHosts(ctx, urlTwo)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tallHosts := make(map[string]bool)\n+\tmapOne := make(map[string]hostInfo)\n+\tfor _, val := range listOne {\n+\t\tallHosts[val.Hostname] = true\n+\t\tmapOne[val.Hostname] = val\n+\t}\n+\tmapTwo := make(map[string]hostInfo)\n+\tfor _, val := range listTwo {\n+\t\tallHosts[val.Hostname] = true\n+\t\tmapTwo[val.Hostname] = val\n+\t}\n+\n+\tnames := []string{}\n+\tfor k, _ := range allHosts {\n+\t\tnames = append(names, k)\n+\t}\n+\tsort.Strings(names)\n+\n+\tfor _, k := range names {\n+\t\tone, okOne := mapOne[k]\n+\t\ttwo, okTwo := mapTwo[k]\n+\t\tif !okOne {\n+\t\t\tif !verbose && two.Status != \"active\" {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tfmt.Printf(\"%s\\t\\t%s/%d\\tA-missing\\n\", k, two.Status, two.Seq)\n+\t\t} else if !okTwo {\n+\t\t\tif !verbose && one.Status != \"active\" {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tfmt.Printf(\"%s\\t%s/%d\\t\\tB-missing\\n\", k, one.Status, one.Seq)\n+\t\t} else {\n+\t\t\tstatus := \"\"\n+\t\t\tif one.Status != two.Status {\n+\t\t\t\tstatus = \"diff-status\"\n+\t\t\t} else {\n+\t\t\t\tdelta := max(one.Seq, two.Seq) - min(one.Seq, two.Seq)\n+\t\t\t\tif delta == 0 {\n+\t\t\t\t\tstatus = \"sync\"\n+\t\t\t\t\tif !verbose {\n+\t\t\t\t\t\tcontinue\n+\t\t\t\t\t}\n+\t\t\t\t} else if delta < seqSlop {\n+\t\t\t\t\tstatus = \"nearly\"\n+\t\t\t\t\tif !verbose {\n+\t\t\t\t\t\tcontinue\n+\t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\tstatus = fmt.Sprintf(\"delta=%d\", delta)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tfmt.Printf(\"%s\\t%s/%d\\t%s/%d\\t%s\\n\", k, one.Status, one.Seq, two.Status, two.Seq, status)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n---\n"}], "ideal": "Title: goat relay host diff\n\nBody: little helper for comparing the host lists of two distinct relay instances.\r\n\r\nsequences are always counting up, and won't be exact matches! this implementation allows \"slop\" between the sequences.\r\n\r\nan alternative implementation would be do do multiple interleaved enumeration requests for each relay, then see if there is overlap between the ranges; if there is overlap, presumably they are both relatively in sync."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "splitter/handlers.go\n@@ -72,7 +72,7 @@ func (s *Splitter) HandleComAtprotoSyncRequestCrawl(c echo.Context) error {\n \t\t\t// new context to outlive original HTTP request\n \t\t\tctx := context.Background()\n \t\t\txrpcc := xrpc.Client{\n-\t\t\t\tClient: s.upstreamClient,\n+\t\t\t\tClient: s.peerClient,\n \t\t\t\tHost:   hostname,\n \t\t\t}\n \t\t\tif err := comatproto.SyncRequestCrawl(ctx, &xrpcc, &body); err != nil {\n@@ -129,7 +129,13 @@ func (s *Splitter) ProxyRequest(c echo.Context, hostname, scheme string) error {\n \t}\n \tdefer upstreamResp.Body.Close()\n \n-\trespWriter.Header()[\"Content-Type\"] = []string{upstreamResp.Header.Get(\"Content-Type\")}\n+\t// copy a subset of headers\n+\tfor _, hdr := range []string{\"Content-Type\", \"Content-Length\", \"Location\"} {\n+\t\tval := upstreamResp.Header.Get(hdr)\n+\t\tif val != \"\" {\n+\t\t\trespWriter.Header().Set(hdr, val)\n+\t\t}\n+\t}\n \trespWriter.WriteHeader(upstreamResp.StatusCode)\n \n \t_, err = io.Copy(respWriter, upstreamResp.Body)\n---\nsplitter/splitter.go\n@@ -43,6 +43,7 @@ type Splitter struct {\n \tlogger *slog.Logger\n \n \tupstreamClient *http.Client\n+\tpeerClient     *http.Client\n \tnextCrawlers   []*url.URL\n }\n \n@@ -122,11 +123,20 @@ func NewSplitter(conf SplitterConfig, nextCrawlers []string) (*Splitter, error)\n \t\treturn nil, fmt.Errorf(\"failed to parse upstream url %#v: %w\", conf.UpstreamHostHTTP(), err)\n \t}\n \n+\t// generic HTTP client for upstream relay and collectiondr; but disable automatic following of redirects\n+\tupstreamClient := http.Client{\n+\t\tTimeout: 10 * time.Second,\n+\t\tCheckRedirect: func(req *http.Request, via []*http.Request) error {\n+\t\t\treturn http.ErrUseLastResponse\n+\t\t},\n+\t}\n+\n \ts := &Splitter{\n \t\tconf:           conf,\n \t\tconsumers:      make(map[uint64]*SocketConsumer),\n \t\tlogger:         logger,\n-\t\tupstreamClient: util.RobustHTTPClient(),\n+\t\tupstreamClient: &upstreamClient,\n+\t\tpeerClient:     util.RobustHTTPClient(),\n \t\tnextCrawlers:   nextCrawlerURLs,\n \t}\n \n---\n"}], "ideal": "Title: rainbow: fix getRepo redirects\n\nBody: Rainbow was accidentially following HTTP redirects and streaming back full CAR files when handling getRepo requests.\r\n\r\nThis correctly passes through the HTTP 3xx response back to the client, which then does the request to the PDS.\r\n\r\nNote that proxying or returning the CAR directly isn't *forbidden*, it just isn't the behavior we want right now. We might eventually do proxying and coalescing/caching in rainbow/relay to reduce network load."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/main.go\n@@ -178,6 +178,8 @@ func run(args []string) error {\n \t\t\t\t},\n \t\t\t},\n \t\t},\n+\t\t// additional commands defined in pull.go\n+\t\tcmdPullHosts,\n \t}\n \treturn app.Run(os.Args)\n \n---\ncmd/relay/pull.go\n@@ -0,0 +1,162 @@\n+package main\n+\n+import (\n+\t\"errors\"\n+\t\"fmt\"\n+\n+\tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n+\t\"github.com/bluesky-social/indigo/atproto/identity\"\n+\t\"github.com/bluesky-social/indigo/cmd/relay/relay\"\n+\t\"github.com/bluesky-social/indigo/cmd/relay/relay/models\"\n+\t\"github.com/bluesky-social/indigo/util/cliutil\"\n+\t\"github.com/bluesky-social/indigo/xrpc\"\n+\n+\t\"github.com/urfave/cli/v2\"\n+)\n+\n+var cmdPullHosts = &cli.Command{\n+\tName:   \"pull-hosts\",\n+\tUsage:  \"initializes or updates host list from an existing relay (public API)\",\n+\tAction: runPullHosts,\n+\tFlags: []cli.Flag{\n+\t\t&cli.StringFlag{\n+\t\t\tName:    \"relay-host\",\n+\t\t\tUsage:   \"method, hostname, and port of relay to pull from\",\n+\t\t\tValue:   \"https://bsky.network\",\n+\t\t\tEnvVars: []string{\"RELAY_HOST\"},\n+\t\t},\n+\t\t&cli.StringFlag{\n+\t\t\tName:    \"db-url\",\n+\t\t\tUsage:   \"database connection string for relay database\",\n+\t\t\tValue:   \"sqlite://data/relay/relay.sqlite\",\n+\t\t\tEnvVars: []string{\"DATABASE_URL\"},\n+\t\t},\n+\t\t&cli.IntFlag{\n+\t\t\tName:    \"default-account-limit\",\n+\t\t\tValue:   100,\n+\t\t\tUsage:   \"max number of active accounts for new upstream hosts\",\n+\t\t\tEnvVars: []string{\"RELAY_DEFAULT_ACCOUNT_LIMIT\", \"RELAY_DEFAULT_REPO_LIMIT\"},\n+\t\t},\n+\t\t&cli.IntFlag{\n+\t\t\tName:    \"batch-size\",\n+\t\t\tValue:   500,\n+\t\t\tUsage:   \"host many hosts to pull at a time\",\n+\t\t\tEnvVars: []string{\"RELAY_PULL_HOSTS_BATCH_SIZE\"},\n+\t\t},\n+\t\t&cli.StringSliceFlag{\n+\t\t\tName:    \"trusted-domains\",\n+\t\t\tUsage:   \"domain names which mark trusted hosts; use wildcard prefix to match suffixes\",\n+\t\t\tValue:   cli.NewStringSlice(\"*.host.bsky.network\"),\n+\t\t\tEnvVars: []string{\"RELAY_TRUSTED_DOMAINS\"},\n+\t\t},\n+\t\t&cli.BoolFlag{\n+\t\t\tName:    \"skip-host-checks\",\n+\t\t\tUsage:   \"don't run describeServer requests to see if host is a PDS before adding\",\n+\t\t\tEnvVars: []string{\"RELAY_SKIP_HOST_CHECKS\"},\n+\t\t},\n+\t},\n+}\n+\n+func runPullHosts(cctx *cli.Context) error {\n+\tctx := cctx.Context\n+\n+\tif cctx.Args().Len() > 0 {\n+\t\treturn fmt.Errorf(\"unexpected arguments\")\n+\t}\n+\n+\tclient := xrpc.Client{\n+\t\tHost: cctx.String(\"relay-host\"),\n+\t}\n+\n+\tskipHostChecks := cctx.Bool(\"skip-host-checks\")\n+\n+\tdir := identity.DefaultDirectory()\n+\n+\tdburl := cctx.String(\"db-url\")\n+\tdb, err := cliutil.SetupDatabase(dburl, 10)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\trelayConfig := relay.DefaultRelayConfig()\n+\trelayConfig.DefaultRepoLimit = cctx.Int64(\"default-account-limit\")\n+\trelayConfig.TrustedDomains = cctx.StringSlice(\"trusted-domains\")\n+\n+\t// NOTE: setting evtmgr to nil\n+\tr, err := relay.NewRelay(db, nil, dir, relayConfig)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tchecker := relay.NewHostClient(relayConfig.UserAgent)\n+\n+\tcursor := \"\"\n+\tsize := cctx.Int64(\"batch-size\")\n+\tfor {\n+\t\tresp, err := comatproto.SyncListHosts(ctx, &client, cursor, size)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfor _, h := range resp.Hosts {\n+\t\t\tif h.Status == nil {\n+\t\t\t\tfmt.Printf(\"%s: status=unknown\\n\", h.Hostname)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tif !(models.HostStatus(*h.Status) == models.HostStatusActive || models.HostStatus(*h.Status) == models.HostStatusIdle) {\n+\t\t\t\tfmt.Printf(\"%s: status=%s\\n\", h.Hostname, *h.Status)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tif h.Seq == nil || *h.Seq <= 0 {\n+\t\t\t\tfmt.Printf(\"%s: no-cursor\\n\", h.Hostname)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\texisting, err := r.GetHost(ctx, h.Hostname)\n+\t\t\tif err != nil && !errors.Is(err, relay.ErrHostNotFound) {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tif existing != nil {\n+\t\t\t\tfmt.Printf(\"%s: exists\\n\", h.Hostname)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\thostname, noSSL, err := relay.ParseHostname(h.Hostname)\n+\t\t\tif err != nil {\n+\t\t\t\treturn fmt.Errorf(\"%w: %s\", err, h.Hostname)\n+\t\t\t}\n+\t\t\tif noSSL {\n+\t\t\t\t// skip \"localhost\" and non-SSL hosts (this is for public PDS instances)\n+\t\t\t\tfmt.Printf(\"%s: non-public\\n\", h.Hostname)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\taccountLimit := r.Config.DefaultRepoLimit\n+\t\t\ttrusted := relay.IsTrustedHostname(hostname, r.Config.TrustedDomains)\n+\t\t\tif trusted {\n+\t\t\t\taccountLimit = r.Config.TrustedRepoLimit\n+\t\t\t}\n+\n+\t\t\tif !skipHostChecks {\n+\t\t\t\tif err := checker.CheckHost(ctx, \"https://\"+hostname); err != nil {\n+\t\t\t\t\tfmt.Printf(\"%s: checking host: %s\\n\", h.Hostname, err)\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\thost := models.Host{\n+\t\t\t\tHostname:     hostname,\n+\t\t\t\tNoSSL:        noSSL,\n+\t\t\t\tStatus:       models.HostStatusActive,\n+\t\t\t\tTrusted:      trusted,\n+\t\t\t\tAccountLimit: accountLimit,\n+\t\t\t}\n+\t\t\tif err := db.Create(&host).Error; err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t\tfmt.Printf(\"%s: added\\n\", h.Hostname)\n+\t\t}\n+\t\tif resp.Cursor == nil || *resp.Cursor == \"\" {\n+\t\t\tbreak\n+\t\t}\n+\t\tcursor = *resp.Cursor\n+\t}\n+\treturn nil\n+}\n---\n"}], "ideal": "Title: relay pull-hosts command (for public bootstrapping)\n\nBody: This helper command queries an existing relay instance for known hosts, and adds them to the local instance (if they aren't already). The intention is to make bootstrapping a new full-network relay easier (eg, avoid wrangling bash script pipelines and admin API requests).\r\n\r\nIt does some filtering and checks to try and skip inactive/stale hosts: only \"active\" (or \"idle\") hosts which have seen at least one event remotely (aka, `seq` is positive), and does an (optional) HTTP request to `describeServer` on the host to check it is live.\r\n\r\nThis command should only be run if the overall relay isn't already running as a daemon. It is safe to run it multiple times, or after the relay has been running for some time.\r\n\r\n(this code is pretty off-the-cuff; I've run it a few times to test, and it isn't critical to our prod use, but could definitely use eyes)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/handlers_admin.go\n@@ -24,7 +24,6 @@ func (s *Service) handleAdminRequestCrawl(c echo.Context) error {\n \t\treturn &echo.HTTPError{Code: http.StatusBadRequest, Message: fmt.Sprintf(\"invalid body: %s\", err)}\n \t}\n \n-\t// func (s *Service) handleComAtprotoSyncRequestCrawl(ctx context.Context,body *comatproto.SyncRequestCrawl_Input) error\n \treturn s.handleComAtprotoSyncRequestCrawl(c, &body, true)\n }\n \n@@ -59,7 +58,8 @@ func (s *Service) handleAdminSetNewHostPerDayRateLimit(c echo.Context) error {\n \n \ts.relay.HostPerDayLimiter.SetLimit(limit)\n \n-\t// TODO: forward to SiblingRelayHosts\n+\t// NOTE: *not* forwarding to sibling instances\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n@@ -97,7 +97,9 @@ func (s *Service) handleAdminTakeDownRepo(c echo.Context) error {\n \t\t}\n \t}\n \n-\t// TODO: forward to SiblingRelayHosts\n+\t// forward on to any sibling instances\n+\tgo s.ForwardAdminRequest(c)\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n@@ -135,7 +137,9 @@ func (s *Service) handleAdminReverseTakedown(c echo.Context) error {\n \t\t}\n \t}\n \n-\t// TODO: forward to SiblingRelayHosts\n+\t// forward on to any sibling instances\n+\tgo s.ForwardAdminRequest(c)\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n@@ -306,6 +310,8 @@ func (s *Service) handleAdminKillUpstreamConn(c echo.Context) error {\n \t\treturn err\n \t}\n \n+\t// NOTE: *not* forwarding this request to sibling relays\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n@@ -337,7 +343,9 @@ func (s *Service) handleBlockHost(c echo.Context) error {\n \t// kill any active connection (there may not be one, so ignore error)\n \t_ = s.relay.Slurper.KillUpstreamConnection(ctx, host.Hostname, false)\n \n-\t// TODO: forward to SiblingRelayHosts\n+\t// forward on to any sibling instances\n+\tgo s.ForwardAdminRequest(c)\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n@@ -366,7 +374,9 @@ func (s *Service) handleUnblockHost(c echo.Context) error {\n \t\t}\n \t}\n \n-\t// TODO: forward to SiblingRelayHosts\n+\t// forward on to any sibling instances\n+\tgo s.ForwardAdminRequest(c)\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n@@ -412,7 +422,9 @@ func (s *Service) handleAdminBanDomain(c echo.Context) error {\n \t\treturn err\n \t}\n \n-\t// TODO: forward to SiblingRelayHosts\n+\t// forward on to any sibling instances\n+\tgo s.ForwardAdminRequest(c)\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n@@ -431,7 +443,9 @@ func (s *Service) handleAdminUnbanDomain(c echo.Context) error {\n \t\treturn err\n \t}\n \n-\t// TODO: forward to SiblingRelayHosts\n+\t// forward on to any sibling instances\n+\tgo s.ForwardAdminRequest(c)\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n@@ -470,7 +484,74 @@ func (s *Service) handleAdminChangeHostRateLimits(c echo.Context) error {\n \t\treturn echo.NewHTTPError(http.StatusInternalServerError, fmt.Sprintf(\"failed to update limits: %s\", err))\n \t}\n \n+\t// forward on to any sibling instances\n+\tgo s.ForwardAdminRequest(c)\n+\n \treturn c.JSON(http.StatusOK, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n }\n+\n+// this method expects to be run in a goroutine. it does not take a `context.Context`, the input `echo.Context` has likely be cancelled/closed, and does not return an error (only logs)\n+func (s *Service) ForwardAdminRequest(c echo.Context) {\n+\n+\tif len(s.config.SiblingRelayHosts) == 0 {\n+\t\treturn\n+\t}\n+\n+\t// if this request was forwarded, or user-agent matches, then don't forward\n+\treq := c.Request()\n+\tfwd := req.Header.Get(\"Forwarded\")\n+\tif strings.Contains(fwd, \"by=relay\") {\n+\t\treturn\n+\t}\n+\tuserAgent := req.Header.Get(\"User-Agent\")\n+\tif strings.Contains(userAgent, \"rainbow\") || strings.Contains(userAgent, \"relay\") {\n+\t\treturn\n+\t}\n+\n+\tclient := http.Client{\n+\t\tTimeout: 10 * time.Second,\n+\t}\n+\n+\tfor _, rawHost := range s.config.SiblingRelayHosts {\n+\t\thostname, noSSL, err := relay.ParseHostname(rawHost)\n+\t\tif err != nil {\n+\t\t\ts.logger.Error(\"invalid sibling hostname configured\", \"host\", rawHost, \"err\", err)\n+\t\t\treturn\n+\t\t}\n+\t\tu := req.URL\n+\t\tu.Host = hostname\n+\t\tif noSSL {\n+\t\t\tu.Scheme = \"http\"\n+\t\t} else {\n+\t\t\tu.Scheme = \"https\"\n+\t\t}\n+\t\tupstreamReq, err := http.NewRequest(req.Method, u.String(), req.Body)\n+\t\tif err != nil {\n+\t\t\ts.logger.Error(\"creating admin forward request failed\", \"method\", req.Method, \"url\", u.String(), \"err\", err)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\t// copy some headers from inbound request\n+\t\tfor k, vals := range req.Header {\n+\t\t\tif strings.ToLower(k) == \"accept\" || strings.ToLower(k) == \"authentication\" {\n+\t\t\t\tupstreamReq.Header.Add(k, vals[0])\n+\t\t\t}\n+\t\t}\n+\t\tupstreamReq.Header.Add(\"User-Agent\", s.relay.Config.UserAgent)\n+\t\tupstreamReq.Header.Add(\"Forwarded\", \"by=relay\")\n+\n+\t\tupstreamResp, err := client.Do(upstreamReq)\n+\t\tif err != nil {\n+\t\t\ts.logger.Error(\"forwarded admin HTTP request failed\", \"method\", req.Method, \"url\", u.String(), \"err\", err)\n+\t\t\tcontinue\n+\t\t}\n+\t\tupstreamResp.Body.Close()\n+\t\tif upstreamResp.StatusCode != http.StatusOK {\n+\t\t\ts.logger.Error(\"forwarded admin HTTP request failed\", \"method\", req.Method, \"url\", u.String(), \"statusCode\", upstreamResp.StatusCode)\n+\t\t\tcontinue\n+\t\t}\n+\t\ts.logger.Info(\"successfully forwarded admin HTTP request\", \"method\", req.Method, \"url\", u.String())\n+\t}\n+}\n---\n"}], "ideal": "Title: implement sibling relay admin request forwarding\n\nBody: This is the sketch of the feature, haven't tested it yet.\r\n\r\nIn particular, realized we don't have direct access between our multiple prod relay instances across WAN. Might need rainbow proxying support? Or some other hole-punch."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/main.go\n@@ -42,9 +42,9 @@ func run(args []string) error {\n \t\tVersion: versioninfo.Short(),\n \t}\n \tapp.Flags = []cli.Flag{\n-\t\t&cli.StringFlag{\n+\t\t&cli.StringSliceFlag{\n \t\t\tName:    \"admin-password\",\n-\t\t\tUsage:   \"secret password/token for accessing admin endpoints (random is used if not set)\",\n+\t\t\tUsage:   \"secret password/token for accessing admin endpoints (multiple values allowed)\",\n \t\t\tEnvVars: []string{\"RELAY_ADMIN_PASSWORD\", \"RELAY_ADMIN_KEY\"},\n \t\t},\n \t\t&cli.StringFlag{\n@@ -258,12 +258,13 @@ func runRelay(cctx *cli.Context) error {\n \t\tlogger.Info(\"sibling relay hosts configured for admin state forwarding\", \"servers\", svcConfig.SiblingRelayHosts)\n \t}\n \tif cctx.IsSet(\"admin-password\") {\n-\t\tsvcConfig.AdminPassword = cctx.String(\"admin-password\")\n+\t\tsvcConfig.AdminPasswords = cctx.StringSlice(\"admin-password\")\n \t} else {\n \t\tvar rblob [10]byte\n \t\t_, _ = rand.Read(rblob[:])\n-\t\tsvcConfig.AdminPassword = base64.URLEncoding.EncodeToString(rblob[:])\n-\t\tlogger.Info(\"generated random admin password\", \"username\", \"admin\", \"password\", svcConfig.AdminPassword)\n+\t\trandPassword := base64.URLEncoding.EncodeToString(rblob[:])\n+\t\tsvcConfig.AdminPasswords = []string{randPassword}\n+\t\tlogger.Info(\"generated random admin password\", \"username\", \"admin\", \"password\", randPassword)\n \t}\n \n \tevtman := eventmgr.NewEventManager(persister)\n---\ncmd/relay/service.go\n@@ -2,6 +2,7 @@ package main\n \n import (\n \t\"context\"\n+\t\"crypto/subtle\"\n \t\"encoding/base64\"\n \t\"log/slog\"\n \t\"net\"\n@@ -29,8 +30,8 @@ type ServiceConfig struct {\n \t// list of hosts which get forwarded admin state changes (takedowns, etc)\n \tSiblingRelayHosts []string\n \n-\t// verified against Basic admin auth\n-\tAdminPassword string\n+\t// verified against Basic admin auth. multiple passwords are allowed server-side, to make secret rotations operationally easier\n+\tAdminPasswords []string\n \n \t// how long to wait for the requested server socket to become available for use\n \tListenerBootTimeout time.Duration\n@@ -197,12 +198,27 @@ func (svc *Service) Shutdown() []error {\n }\n \n func (svc *Service) checkAdminAuth(next echo.HandlerFunc) echo.HandlerFunc {\n-\theaderVal := \"Basic \" + base64.StdEncoding.EncodeToString([]byte(\"admin:\"+svc.config.AdminPassword))\n+\n+\t// pre-compute valid HTTP auth headers based on the set of\n+\tvalidAuthHeaders := []string{}\n+\tfor _, pw := range svc.config.AdminPasswords {\n+\t\thdr := \"Basic \" + base64.StdEncoding.EncodeToString([]byte(\"admin:\"+pw))\n+\t\tvalidAuthHeaders = append(validAuthHeaders, hdr)\n+\t}\n+\n+\t// for paths that this middleware is applied to, enforce that the auth header must exist and match one of the known passwords\n \treturn func(c echo.Context) error {\n \t\thdr := c.Request().Header.Get(\"Authorization\")\n-\t\tif hdr != headerVal {\n-\t\t\treturn echo.ErrForbidden\n+\t\tif hdr == \"\" {\n+\t\t\tc.Response().Header().Set(\"WWW-Authenticate\", \"Basic\")\n+\t\t\treturn echo.ErrUnauthorized\n+\t\t}\n+\t\tfor _, val := range validAuthHeaders {\n+\t\t\tif subtle.ConstantTimeCompare([]byte(hdr), []byte(val)) == 1 {\n+\t\t\t\treturn next(c)\n+\t\t\t}\n \t\t}\n-\t\treturn next(c)\n+\t\tc.Response().Header().Set(\"WWW-Authenticate\", \"Basic\")\n+\t\treturn echo.ErrUnauthorized\n \t}\n }\n---\n"}], "ideal": "Title: support multiple admin passwords\n\nBody: - relay support for multiple admin passwords at the same time (to make secret rotation easier)\r\n- have a parallel PR going with README updates; will mention in that PR that the env var is comma-separated, so passwords can't contain a comma\r\n- does not change the arg name or env var name, so existing configs work fine\r\n- also switches to constant-time string comparison using go stdlib (more secure)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/service.go\n@@ -2,7 +2,7 @@ package main\n \n import (\n \t\"context\"\n-\t\"encoding/base64\"\n+\t\"fmt\"\n \t\"log/slog\"\n \t\"net\"\n \t\"net/http\"\n@@ -197,7 +197,7 @@ func (svc *Service) Shutdown() []error {\n }\n \n func (svc *Service) checkAdminAuth(next echo.HandlerFunc) echo.HandlerFunc {\n-\theaderVal := \"Basic \" + base64.StdEncoding.EncodeToString([]byte(\"admin:\"+svc.config.AdminPassword))\n+\theaderVal := fmt.Sprintf(\"Bearer %s\", svc.config.AdminPassword)\n \treturn func(c echo.Context) error {\n \t\thdr := c.Request().Header.Get(\"Authorization\")\n \t\tif hdr != headerVal {\n---\n"}], "ideal": "Title: Fix Relay Admin Page Auth\n\nBody: Found this while doing a read-through of the new code and poking around. Without this change, when attempting to log in to the local admin UI, I get `Failed to validate Admin Token: Status 403`.\r\n\r\nEither the UI should send basic auth, or the server handler should receive a bearer token. I just went with the server-side change, but if you'd prefer that the UI sends basic auth, happy to do that instead.\r\n\r\n<img width=\"1329\" alt=\"Screenshot 2025-04-17 at 17 45 31\" src=\"https://github.com/user-attachments/assets/5cad2209-790e-46f7-9093-e612e1b52d35\" />\r\n"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/relay/handlers.go\n@@ -81,10 +81,10 @@ func (s *Service) handleComAtprotoSyncListHosts(c echo.Context, cursor int64, li\n \n \tfor i, host := range hosts {\n \t\tresp.Hosts[i] = &comatproto.SyncListHosts_Host{\n-\t\t\t// TODO: AccountCount\n-\t\t\tHostname: host.Hostname,\n-\t\t\tSeq:      &host.LastSeq,\n-\t\t\tStatus:   (*string)(&host.Status),\n+\t\t\tHostname:     host.Hostname,\n+\t\t\tSeq:          &host.LastSeq,\n+\t\t\tStatus:       (*string)(&host.Status),\n+\t\t\tAccountCount: &host.AccountCount,\n \t\t}\n \t}\n \n@@ -148,9 +148,13 @@ func (s *Service) handleComAtprotoSyncListRepos(c echo.Context, cursor int64, li\n \t\t\treturn nil, echo.NewHTTPError(http.StatusInternalServerError, fmt.Sprintf(\"failed to get repo root for (%s): %v\", acc.DID, err.Error()))\n \t\t}\n \n+\t\tactive := acc.IsActive()\n \t\tresp.Repos[i] = &comatproto.SyncListRepos_Repo{\n-\t\t\tDid:  acc.DID,\n-\t\t\tHead: repo.CommitCID,\n+\t\t\tDid:    acc.DID,\n+\t\t\tHead:   repo.CommitCID,\n+\t\t\tRev:    repo.Rev,\n+\t\t\tActive: &active,\n+\t\t\tStatus: acc.StatusField(),\n \t\t}\n \t}\n \n---\ncmd/relay/relay/models/models.go\n@@ -5,11 +5,11 @@ import (\n )\n \n type DomainBan struct {\n-\tID uint64 `gorm:\"column:id;primarykey\"`\n+\tID uint64 `gorm:\"column:id;primarykey\" json:\"id\"`\n \t// CreatedAt is automatically managed by gorm (by convention)\n-\tCreatedAt time.Time\n+\tCreatedAt time.Time `json:\"createdAt\"`\n \n-\tDomain string `gorm:\"unique\"`\n+\tDomain string `gorm:\"unique\" json:\"domain\"`\n }\n \n type HostStatus string\n@@ -23,31 +23,31 @@ const (\n )\n \n type Host struct {\n-\tID uint64 `gorm:\"column:id;primarykey\"`\n+\tID uint64 `gorm:\"column:id;primarykey\" json:\"id\"`\n \n \t// these fields are automatically managed by gorm (by convention)\n-\tCreatedAt time.Time\n-\tUpdatedAt time.Time\n+\tCreatedAt time.Time `json:\"createdAt\"`\n+\tUpdatedAt time.Time `json:\"updatedAt\"`\n \n \t// hostname, without URL scheme. if localhost, must include a port number; otherwise must not include port\n-\tHostname string `gorm:\"column:hostname;uniqueIndex;not null\"`\n+\tHostname string `gorm:\"column:hostname;uniqueIndex;not null\" json:\"hostname\"`\n \n \t// indicates ws:// not wss://\n-\tNoSSL bool `gorm:\"column:no_ssl;default:false\"`\n+\tNoSSL bool `gorm:\"column:no_ssl;default:false\" json:\"noSSL\"`\n \n \t// maximum number of active accounts\n-\tAccountLimit int64 `gorm:\"column:account_limit\"`\n+\tAccountLimit int64 `gorm:\"column:account_limit\" json:\"accountLimit\"`\n \n \t// indicates this is a highly trusted host (PDS), and different rate limits apply\n-\tTrusted bool `gorm:\"column:trusted;default:false\"`\n+\tTrusted bool `gorm:\"column:trusted;default:false\" json:\"trusted\"`\n \n-\tStatus HostStatus `gorm:\"column:status;default:active\"`\n+\tStatus HostStatus `gorm:\"column:status;default:active\" json:\"status\"`\n \n \t// the last sequence number persisted for this host. updated periodically, and at shutdown. negative number indicates no sequence recorded\n-\tLastSeq int64 `gorm:\"column:last_seq;default:-1\"`\n+\tLastSeq int64 `gorm:\"column:last_seq;default:-1\" json:\"lastSeq\"`\n \n \t// represents the number of accounts on the host, minus any in \"deleted\" state\n-\tAccountCount int64 `gorm:\"column:account_count;default:0\"`\n+\tAccountCount int64 `gorm:\"column:account_count;default:0\" json:\"accountCount\"`\n }\n \n func (Host) TableName() string {\n@@ -73,13 +73,13 @@ var (\n )\n \n type Account struct {\n-\tUID uint64 `gorm:\"column:uid;primarykey\"`\n-\tDID string `gorm:\"column:did;uniqueIndex;not null\"`\n+\tUID uint64 `gorm:\"column:uid;primarykey\" json:\"uid\"`\n+\tDID string `gorm:\"column:did;uniqueIndex;not null\" json:\"did\"`\n \n \t// this is a reference to the ID field on Host; but it is not an explicit foreign key\n-\tHostID         uint64        `gorm:\"column:host_id;not null\"`\n-\tStatus         AccountStatus `gorm:\"column:status;not null;default:active\"`\n-\tUpstreamStatus AccountStatus `gorm:\"column:upstream_status;not null;default:active\"`\n+\tHostID         uint64        `gorm:\"column:host_id;not null\" json:\"hostID\"`\n+\tStatus         AccountStatus `gorm:\"column:status;not null;default:active\" json:\"status\"`\n+\tUpstreamStatus AccountStatus `gorm:\"column:upstream_status;not null;default:active\" json:\"upstreamStatus\"`\n }\n \n func (Account) TableName() string {\n@@ -89,14 +89,14 @@ func (Account) TableName() string {\n // This is a small extension table to `Account`, which holds fast-changing fields updated on every firehose event.\n type AccountRepo struct {\n \t// references Account.UID, but not set up as a foreign key\n-\tUID uint64 `gorm:\"column:uid;primarykey\"`\n-\tRev string `gorm:\"column:rev;not null\"`\n+\tUID uint64 `gorm:\"column:uid;primarykey\" json:\"uid\"`\n+\tRev string `gorm:\"column:rev;not null\" json:\"rev\"`\n \n \t// The CID of the entire signed commit block. Sometimes called the \"head\"\n-\tCommitCID string `gorm:\"column:commit_cid;not null\"`\n+\tCommitCID string `gorm:\"column:commit_cid;not null\" json:\"commitCID\"`\n \n \t// The CID of the top of the repo MST, which is the 'data' field within the commit block. This becomes 'prevData'\n-\tCommitDataCID string `gorm:\"column:commit_data_cid;not null\"`\n+\tCommitDataCID string `gorm:\"column:commit_data_cid;not null\" json:\"commitDataCID\"`\n }\n \n func (AccountRepo) TableName() string {\n---\n"}], "ideal": "Title: relay tweaks: JSON fields for db models, and fix some API endpoints\n\nBody: Intent is to self-merge this"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/identity.go\n@@ -13,25 +13,25 @@ import (\n \n // Represents an atproto identity. Could be a regular user account, or a service account (eg, feed generator)\n type Identity struct {\n-\tDID syntax.DID `json:\"did\"`\n+\tDID syntax.DID\n \n \t// Handle/DID mapping must be bi-directionally verified. If that fails, the Handle should be the special 'handle.invalid' value\n-\tHandle syntax.Handle `json:\"handle\"`\n+\tHandle syntax.Handle\n \n \t// These fields represent a parsed subset of a DID document. They are all nullable. Note that the services and keys maps do not preserve order, so they don't exactly round-trip DID documents.\n-\tAlsoKnownAs []string           `json:\"alsoKnownAs\"`\n-\tServices    map[string]Service `json:\"services\"`\n-\tKeys        map[string]Key     `json:\"keys\"`\n+\tAlsoKnownAs []string\n+\tServices    map[string]Service\n+\tKeys        map[string]Key\n }\n \n type Key struct {\n-\tType               string `json:\"type\"`\n-\tPublicKeyMultibase string `json:\"publicKeyMultibase\"`\n+\tType               string\n+\tPublicKeyMultibase string\n }\n \n type Service struct {\n-\tType string `json:\"type\"`\n-\tURL  string `json:\"url\"`\n+\tType string\n+\tURL  string\n }\n \n // Extracts the information relevant to atproto from an arbitrary DID document.\n---\n"}], "ideal": "Title: Revert \"make identity.Identity more easily JSON serializable\"\n\nBody: This caused problems in prod. Unbeknownst to me, we had been serializing identity metadata as JSON using this struct and persisting it. Then passing back to TypeScript (not golang!), which depended on the capitalization (case-sensitive JSON parsing).\r\n\r\nReverting for now. Note that the go stdlib JSON code is actually case-insensitive for keys, so the text fixtures in this repo which had been updated to depend on this are not impacted (!).\r\n\r\nDirect link to original PR: https://github.com/bluesky-social/indigo/pull/1017"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/sonar/sonar.go\n@@ -3,6 +3,7 @@ package main\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"encoding/json\"\n \t\"fmt\"\n \t\"log/slog\"\n \t\"os\"\n@@ -14,7 +15,6 @@ import (\n \tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n \t\"github.com/bluesky-social/indigo/api/bsky\"\n \tlexutil \"github.com/bluesky-social/indigo/lex/util\"\n-\t\"github.com/goccy/go-json\"\n \n \t\"github.com/bluesky-social/indigo/events\"\n \t\"github.com/bluesky-social/indigo/repo\"\n---\ngo.mod\n@@ -1,6 +1,7 @@\n module github.com/bluesky-social/indigo\n \n go 1.23\n+\n toolchain go1.23.8\n \n require (\n@@ -15,7 +16,6 @@ require (\n \tgithub.com/dustinkirkland/golang-petname v0.0.0-20231002161417-6a283f1aaaf2\n \tgithub.com/flosch/pongo2/v6 v6.0.0\n \tgithub.com/go-redis/cache/v9 v9.0.0\n-\tgithub.com/goccy/go-json v0.10.2\n \tgithub.com/gocql/gocql v1.7.0\n \tgithub.com/golang-jwt/jwt v3.2.2+incompatible\n \tgithub.com/gorilla/websocket v1.5.1\n@@ -90,6 +90,7 @@ require (\n \tgithub.com/dgryski/go-rendezvous v0.0.0-20200823014737-9f7001d12a5f // indirect\n \tgithub.com/getsentry/sentry-go v0.27.0 // indirect\n \tgithub.com/go-redis/redis v6.15.9+incompatible // indirect\n+\tgithub.com/goccy/go-json v0.10.2 // indirect\n \tgithub.com/golang/snappy v0.0.4 // indirect\n \tgithub.com/hailocab/go-hostpool v0.0.0-20160125115350-e80d13ce29ed // indirect\n \tgithub.com/hashicorp/golang-lru v1.0.2 // indirect\n---\n"}], "ideal": "Title: sonar: just use stdlib json (removing go-json dependency)\n\nBody: Fine to use this elsewhere for perf, but let's get it out of this dependency tree.\r\n\r\n(note: this is not actually related to recent serialization bug, just cleaning this up)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/goat/firehose.go\n@@ -141,6 +141,12 @@ func runFirehose(cctx *cli.Context) error {\n \tif err != nil {\n \t\treturn fmt.Errorf(\"invalid relayHost URI: %w\", err)\n \t}\n+\tswitch u.Scheme {\n+\tcase \"http\":\n+\t\tu.Scheme = \"ws\"\n+\tcase \"https\":\n+\t\tu.Scheme = \"wss\"\n+\t}\n \tu.Path = \"xrpc/com.atproto.sync.subscribeRepos\"\n \tif cctx.IsSet(\"cursor\") {\n \t\tu.RawQuery = fmt.Sprintf(\"cursor=%d\", cctx.Int(\"cursor\"))\n@@ -277,10 +283,12 @@ func (gfc *GoatFirehoseConsumer) handleSyncEvent(ctx context.Context, evt *comat\n \tif gfc.Quiet {\n \t\treturn nil\n \t}\n-\tevt.Blocks = nil\n+\tif !gfc.Blocks {\n+\t\tevt.Blocks = nil\n+\t}\n \tout := make(map[string]interface{})\n \tout[\"type\"] = \"sync\"\n-\tout[\"commit\"] = commit.AsData()\n+\tout[\"commit\"] = commit.AsData() // NOTE: funky, but helpful, to include this in output\n \tout[\"payload\"] = evt\n \tb, err := json.Marshal(out)\n \tif err != nil {\n---\ncmd/goat/relay.go\n@@ -5,6 +5,7 @@ import (\n \t\"fmt\"\n \n \tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n+\t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \t\"github.com/bluesky-social/indigo/xrpc\"\n \n \t\"github.com/urfave/cli/v2\"\n@@ -27,8 +28,9 @@ var cmdRelay = &cli.Command{\n \t\t\tUsage: \"sub-commands for accounts/repos on relay\",\n \t\t\tSubcommands: []*cli.Command{\n \t\t\t\t&cli.Command{\n-\t\t\t\t\tName:  \"list\",\n-\t\t\t\t\tUsage: \"enumerate all accounts\",\n+\t\t\t\t\tName:    \"list\",\n+\t\t\t\t\tAliases: []string{\"ls\"},\n+\t\t\t\t\tUsage:   \"enumerate all accounts\",\n \t\t\t\t\tFlags: []cli.Flag{\n \t\t\t\t\t\t&cli.StringFlag{\n \t\t\t\t\t\t\tName:    \"collection\",\n@@ -42,17 +44,54 @@ var cmdRelay = &cli.Command{\n \t\t\t\t\t},\n \t\t\t\t\tAction: runRelayAccountList,\n \t\t\t\t},\n+\t\t\t\t&cli.Command{\n+\t\t\t\t\tName:      \"status\",\n+\t\t\t\t\tArgsUsage: `<did>`,\n+\t\t\t\t\tUsage:     \"describe status of individual account\",\n+\t\t\t\t\tFlags: []cli.Flag{\n+\t\t\t\t\t\t&cli.BoolFlag{\n+\t\t\t\t\t\t\tName:  \"json\",\n+\t\t\t\t\t\t\tUsage: \"print output as JSON\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t\tAction: runRelayAccountStatus,\n+\t\t\t\t},\n \t\t\t},\n \t\t},\n \t\t&cli.Command{\n \t\t\tName:  \"host\",\n \t\t\tUsage: \"sub-commands for upstream hosts (eg, PDS)\",\n \t\t\tSubcommands: []*cli.Command{\n \t\t\t\t&cli.Command{\n-\t\t\t\t\tName:      \"add\",\n+\t\t\t\t\tName:      \"request-crawl\",\n+\t\t\t\t\tAliases:   []string{\"add\"},\n \t\t\t\t\tUsage:     \"request crawl of upstream host (eg, PDS)\",\n \t\t\t\t\tArgsUsage: `<hostname>`,\n-\t\t\t\t\tAction:    runRelayHostAdd,\n+\t\t\t\t\tAction:    runRelayHostRequestCrawl,\n+\t\t\t\t},\n+\t\t\t\t&cli.Command{\n+\t\t\t\t\tName:    \"list\",\n+\t\t\t\t\tAliases: []string{\"ls\"},\n+\t\t\t\t\tUsage:   \"enumerate all hosts indexed by relay\",\n+\t\t\t\t\tFlags: []cli.Flag{\n+\t\t\t\t\t\t&cli.BoolFlag{\n+\t\t\t\t\t\t\tName:  \"json\",\n+\t\t\t\t\t\t\tUsage: \"print output as JSON lines\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t\tAction: runRelayHostList,\n+\t\t\t\t},\n+\t\t\t\t&cli.Command{\n+\t\t\t\t\tName:      \"status\",\n+\t\t\t\t\tArgsUsage: `<hostname>`,\n+\t\t\t\t\tUsage:     \"describe status of individual host\",\n+\t\t\t\t\tFlags: []cli.Flag{\n+\t\t\t\t\t\t&cli.BoolFlag{\n+\t\t\t\t\t\t\tName:  \"json\",\n+\t\t\t\t\t\t\tUsage: \"print output as JSON\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t\tAction: runRelayHostStatus,\n \t\t\t\t},\n \t\t\t},\n \t\t},\n@@ -103,7 +142,7 @@ func runRelayAccountList(cctx *cli.Context) error {\n \t\t\t\t\tfmt.Println(string(b))\n \t\t\t\t} else {\n \t\t\t\t\tstatus := \"unknown\"\n-\t\t\t\t\tif r.Active != nil && *r.Active == true {\n+\t\t\t\t\tif r.Active != nil && *r.Active {\n \t\t\t\t\t\tstatus = \"active\"\n \t\t\t\t\t} else if r.Status != nil {\n \t\t\t\t\t\tstatus = *r.Status\n@@ -121,7 +160,55 @@ func runRelayAccountList(cctx *cli.Context) error {\n \treturn nil\n }\n \n-func runRelayHostAdd(cctx *cli.Context) error {\n+func runRelayAccountStatus(cctx *cli.Context) error {\n+\tctx := cctx.Context\n+\n+\tdidStr := cctx.Args().First()\n+\tif didStr == \"\" {\n+\t\treturn fmt.Errorf(\"need to provide account DID as argument\")\n+\t}\n+\tif cctx.Args().Len() != 1 {\n+\t\treturn fmt.Errorf(\"unexpected arguments\")\n+\t}\n+\n+\tdid, err := syntax.ParseDID(didStr)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tclient := xrpc.Client{\n+\t\tHost: cctx.String(\"relay-host\"),\n+\t}\n+\n+\tr, err := comatproto.SyncGetRepoStatus(ctx, &client, did.String())\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif cctx.Bool(\"json\") {\n+\t\tb, err := json.Marshal(r)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Println(string(b))\n+\t} else {\n+\t\tstatus := \"unknown\"\n+\t\tif r.Active {\n+\t\t\tstatus = \"active\"\n+\t\t} else if r.Status != nil {\n+\t\t\tstatus = *r.Status\n+\t\t}\n+\t\trev := \"\"\n+\t\tif r.Rev != nil {\n+\t\t\trev = *r.Rev\n+\t\t}\n+\t\tfmt.Printf(\"%s\\t%s\\t%s\\n\", r.Did, status, rev)\n+\t}\n+\n+\treturn nil\n+}\n+\n+func runRelayHostRequestCrawl(cctx *cli.Context) error {\n \tctx := cctx.Context\n \n \thostname := cctx.Args().First()\n@@ -143,3 +230,99 @@ func runRelayHostAdd(cctx *cli.Context) error {\n \tfmt.Println(\"success\")\n \treturn nil\n }\n+\n+func runRelayHostList(cctx *cli.Context) error {\n+\tctx := cctx.Context\n+\n+\tif cctx.Args().Len() > 0 {\n+\t\treturn fmt.Errorf(\"unexpected arguments\")\n+\t}\n+\n+\tclient := xrpc.Client{\n+\t\tHost: cctx.String(\"relay-host\"),\n+\t}\n+\n+\tcursor := \"\"\n+\tvar size int64 = 500\n+\tfor {\n+\t\tresp, err := comatproto.SyncListHosts(ctx, &client, cursor, size)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\n+\t\tfor _, h := range resp.Hosts {\n+\t\t\tif cctx.Bool(\"json\") {\n+\t\t\t\tb, err := json.Marshal(h)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\t\t\t\tfmt.Println(string(b))\n+\t\t\t} else {\n+\t\t\t\tstatus := \"\"\n+\t\t\t\tif h.Status != nil {\n+\t\t\t\t\tstatus = *h.Status\n+\t\t\t\t}\n+\t\t\t\tcount := \"\"\n+\t\t\t\tif h.AccountCount != nil {\n+\t\t\t\t\tcount = fmt.Sprintf(\"%d\", *h.AccountCount)\n+\t\t\t\t}\n+\t\t\t\tseq := \"\"\n+\t\t\t\tif h.Seq != nil {\n+\t\t\t\t\tseq = fmt.Sprintf(\"%d\", *h.Seq)\n+\t\t\t\t}\n+\t\t\t\tfmt.Printf(\"%s\\t%s\\t%s\\t%s\\n\", h.Hostname, status, count, seq)\n+\t\t\t}\n+\t\t}\n+\n+\t\tif resp.Cursor == nil || *resp.Cursor == \"\" {\n+\t\t\tbreak\n+\t\t}\n+\t\tcursor = *resp.Cursor\n+\t}\n+\treturn nil\n+}\n+\n+func runRelayHostStatus(cctx *cli.Context) error {\n+\tctx := cctx.Context\n+\n+\thostname := cctx.Args().First()\n+\tif hostname == \"\" {\n+\t\treturn fmt.Errorf(\"need to provide hostname as argument\")\n+\t}\n+\tif cctx.Args().Len() != 1 {\n+\t\treturn fmt.Errorf(\"unexpected arguments\")\n+\t}\n+\n+\tclient := xrpc.Client{\n+\t\tHost: cctx.String(\"relay-host\"),\n+\t}\n+\n+\th, err := comatproto.SyncGetHostStatus(ctx, &client, hostname)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\tif cctx.Bool(\"json\") {\n+\t\tb, err := json.Marshal(h)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tfmt.Println(string(b))\n+\t} else {\n+\t\tstatus := \"\"\n+\t\tif h.Status != nil {\n+\t\t\tstatus = *h.Status\n+\t\t}\n+\t\tcount := \"\"\n+\t\tif h.AccountCount != nil {\n+\t\t\tcount = fmt.Sprintf(\"%d\", *h.AccountCount)\n+\t\t}\n+\t\tseq := \"\"\n+\t\tif h.Seq != nil {\n+\t\t\tseq = fmt.Sprintf(\"%d\", *h.Seq)\n+\t\t}\n+\t\tfmt.Printf(\"%s\\t%s\\t%s\\t%s\\n\", h.Hostname, status, count, seq)\n+\t}\n+\n+\treturn nil\n+}\n---\ncmd/goat/relay_admin.go\n@@ -92,16 +92,7 @@ var cmdRelayAdmin = &cli.Command{\n \t\t\t\t\tArgsUsage: `<hostname>`,\n \t\t\t\t\tFlags: []cli.Flag{\n \t\t\t\t\t\t&cli.IntFlag{\n-\t\t\t\t\t\t\tName: \"per-second\",\n-\t\t\t\t\t\t},\n-\t\t\t\t\t\t&cli.IntFlag{\n-\t\t\t\t\t\t\tName: \"per-hour\",\n-\t\t\t\t\t\t},\n-\t\t\t\t\t\t&cli.IntFlag{\n-\t\t\t\t\t\t\tName: \"per-day\",\n-\t\t\t\t\t\t},\n-\t\t\t\t\t\t&cli.IntFlag{\n-\t\t\t\t\t\t\tName: \"repo-limit\",\n+\t\t\t\t\t\t\tName: \"account-limit\",\n \t\t\t\t\t\t},\n \t\t\t\t\t},\n \t\t\t\t\tAction: runRelayAdminHostConfig,\n@@ -376,17 +367,8 @@ func runRelayAdminHostConfig(cctx *cli.Context) error {\n \tbody := map[string]any{\n \t\t\"host\": hostname,\n \t}\n-\tif cctx.IsSet(\"per-second\") {\n-\t\tbody[\"per_second\"] = cctx.Int(\"per-second\")\n-\t}\n-\tif cctx.IsSet(\"per-hour\") {\n-\t\tbody[\"per_hour\"] = cctx.Int(\"per-hour\")\n-\t}\n-\tif cctx.IsSet(\"per-day\") {\n-\t\tbody[\"per_day\"] = cctx.Int(\"per-day\")\n-\t}\n-\tif cctx.IsSet(\"repo-limit\") {\n-\t\tbody[\"repo_limit\"] = cctx.Int(\"repo-limit\")\n+\tif cctx.IsSet(\"account-limit\") {\n+\t\tbody[\"repo_limit\"] = cctx.Int(\"account-limit\")\n \t}\n \n \t_, err = client.Do(\"POST\", path, nil, body)\n---\n"}], "ideal": "Title: more `goat relay` helpers\n\nBody: - host lists and status info\r\n- more flexible firehose-mode host parsing (wss:// vs https://)\r\n- include blocks in `#sync` firehose output (if requested)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/data/blob.go\n@@ -27,7 +27,7 @@ type LegacyBlobSchema struct {\n }\n \n type BlobSchema struct {\n-\tLexiconTypeID string  `json:\"$type,const=blob\" cborgen:\"$type,const=blob\"`\n+\tLexiconTypeID string  `json:\"$type\" cborgen:\"$type,const=blob\"`\n \tRef           CIDLink `json:\"ref\" cborgen:\"ref\"`\n \tMimeType      string  `json:\"mimeType\" cborgen:\"mimeType\"`\n \tSize          int64   `json:\"size\" cborgen:\"size\"`\n---\natproto/lexicon/language.go\n@@ -14,7 +14,7 @@ import (\n \n // Serialization helper type for top-level Lexicon schema JSON objects (files)\n type SchemaFile struct {\n-\tLexicon     int                  `json:\"lexicon,const=1\"`\n+\tLexicon     int                  `json:\"lexicon\"` // must be 1\n \tID          string               `json:\"id\"`\n \tDescription *string              `json:\"description,omitempty\"`\n \tDefs        map[string]SchemaDef `json:\"defs\"`\n@@ -287,7 +287,7 @@ func (s *SchemaDef) UnmarshalJSON(b []byte) error {\n }\n \n type SchemaRecord struct {\n-\tType        string       `json:\"type,const=record\"`\n+\tType        string       `json:\"type\"` // \"record\"\n \tDescription *string      `json:\"description,omitempty\"`\n \tKey         string       `json:\"key\"`\n \tRecord      SchemaObject `json:\"record\"`\n@@ -306,7 +306,7 @@ func (s *SchemaRecord) CheckSchema() error {\n }\n \n type SchemaQuery struct {\n-\tType        string        `json:\"type,const=query\"`\n+\tType        string        `json:\"type\"` // \"query\"\n \tDescription *string       `json:\"description,omitempty\"`\n \tParameters  SchemaParams  `json:\"parameters\"`\n \tOutput      *SchemaBody   `json:\"output\"`\n@@ -328,7 +328,7 @@ func (s *SchemaQuery) CheckSchema() error {\n }\n \n type SchemaProcedure struct {\n-\tType        string        `json:\"type,const=procedure\"`\n+\tType        string        `json:\"type\"` // \"procedure\"\n \tDescription *string       `json:\"description,omitempty\"`\n \tParameters  SchemaParams  `json:\"parameters\"`\n \tOutput      *SchemaBody   `json:\"output\"`           // optional\n@@ -356,7 +356,7 @@ func (s *SchemaProcedure) CheckSchema() error {\n }\n \n type SchemaSubscription struct {\n-\tType        string         `json:\"type,const=subscription\"`\n+\tType        string         `json:\"type\"` // \"subscription\"\n \tDescription *string        `json:\"description,omitempty\"`\n \tParameters  SchemaParams   `json:\"parameters\"`\n \tMessage     *SchemaMessage `json:\"message,omitempty\"` // TODO(specs): is this really optional?\n@@ -429,7 +429,7 @@ func (s *SchemaError) Validate(d any) error {\n }\n \n type SchemaNull struct {\n-\tType        string  `json:\"type,const=null\"`\n+\tType        string  `json:\"type\"` // \"null\"\n \tDescription *string `json:\"description,omitempty\"`\n }\n \n@@ -445,7 +445,7 @@ func (s *SchemaNull) Validate(d any) error {\n }\n \n type SchemaBoolean struct {\n-\tType        string  `json:\"type,const=bool\"`\n+\tType        string  `json:\"type\"` // \"bool\"\n \tDescription *string `json:\"description,omitempty\"`\n \tDefault     *bool   `json:\"default,omitempty\"`\n \tConst       *bool   `json:\"const,omitempty\"`\n@@ -470,7 +470,7 @@ func (s *SchemaBoolean) Validate(d any) error {\n }\n \n type SchemaInteger struct {\n-\tType        string  `json:\"type,const=integer\"`\n+\tType        string  `json:\"type\"` // \"integer\"\n \tDescription *string `json:\"description,omitempty\"`\n \tMinimum     *int    `json:\"minimum,omitempty\"`\n \tMaximum     *int    `json:\"maximum,omitempty\"`\n@@ -518,7 +518,7 @@ func (s *SchemaInteger) Validate(d any) error {\n }\n \n type SchemaString struct {\n-\tType         string   `json:\"type,const=string\"`\n+\tType         string   `json:\"type\"` // \"string\"\n \tDescription  *string  `json:\"description,omitempty\"`\n \tFormat       *string  `json:\"format,omitempty\"`\n \tMinLength    *int     `json:\"minLength,omitempty\"`\n@@ -647,7 +647,7 @@ func (s *SchemaString) Validate(d any, flags ValidateFlags) error {\n }\n \n type SchemaBytes struct {\n-\tType        string  `json:\"type,const=bytes\"`\n+\tType        string  `json:\"type\"` // \"bytes\"\n \tDescription *string `json:\"description,omitempty\"`\n \tMinLength   *int    `json:\"minLength,omitempty\"`\n \tMaxLength   *int    `json:\"maxLength,omitempty\"`\n@@ -676,7 +676,7 @@ func (s *SchemaBytes) Validate(d any) error {\n }\n \n type SchemaCIDLink struct {\n-\tType        string  `json:\"type,const=cid-link\"`\n+\tType        string  `json:\"type\"` // \"cid-link\"\n \tDescription *string `json:\"description,omitempty\"`\n }\n \n@@ -693,7 +693,7 @@ func (s *SchemaCIDLink) Validate(d any) error {\n }\n \n type SchemaArray struct {\n-\tType        string    `json:\"type,const=array\"`\n+\tType        string    `json:\"type\"` // \"array\"\n \tDescription *string   `json:\"description,omitempty\"`\n \tItems       SchemaDef `json:\"items\"`\n \tMinLength   *int      `json:\"minLength,omitempty\"`\n@@ -712,7 +712,7 @@ func (s *SchemaArray) CheckSchema() error {\n }\n \n type SchemaObject struct {\n-\tType        string               `json:\"type,const=object\"`\n+\tType        string               `json:\"type\"` // \"object\"\n \tDescription *string              `json:\"description,omitempty\"`\n \tProperties  map[string]SchemaDef `json:\"properties\"`\n \tRequired    []string             `json:\"required,omitempty\"`\n@@ -755,7 +755,7 @@ func (s *SchemaObject) IsNullable(k string) bool {\n }\n \n type SchemaBlob struct {\n-\tType        string   `json:\"type,const=blob\"`\n+\tType        string   `json:\"type\"` // \"blob\"\n \tDescription *string  `json:\"description,omitempty\"`\n \tAccept      []string `json:\"accept,omitempty\"`\n \tMaxSize     *int     `json:\"maxSize,omitempty\"`\n@@ -796,7 +796,7 @@ func (s *SchemaBlob) Validate(d any, flags ValidateFlags) error {\n }\n \n type SchemaParams struct {\n-\tType        string               `json:\"type,const=params\"`\n+\tType        string               `json:\"type\"` // \"params\"\n \tDescription *string              `json:\"description,omitempty\"`\n \tProperties  map[string]SchemaDef `json:\"properties\"` // boolean, integer, string, or unknown; or an array of these types\n \tRequired    []string             `json:\"required,omitempty\"`\n@@ -835,7 +835,7 @@ func (s *SchemaParams) CheckSchema() error {\n }\n \n type SchemaToken struct {\n-\tType        string  `json:\"type,const=token\"`\n+\tType        string  `json:\"type\"` // \"token\"\n \tDescription *string `json:\"description,omitempty\"`\n \t// the fully-qualified identifier of this token\n \tfullName string\n@@ -863,7 +863,7 @@ func (s *SchemaToken) Validate(d any) error {\n }\n \n type SchemaRef struct {\n-\tType        string  `json:\"type,const=ref\"`\n+\tType        string  `json:\"type\"` // \"ref\"\n \tDescription *string `json:\"description,omitempty\"`\n \tRef         string  `json:\"ref\"`\n \t// full path of reference\n@@ -882,7 +882,7 @@ func (s *SchemaRef) CheckSchema() error {\n }\n \n type SchemaUnion struct {\n-\tType        string   `json:\"type,const=union\"`\n+\tType        string   `json:\"type\"` // \"union\"\n \tDescription *string  `json:\"description,omitempty\"`\n \tRefs        []string `json:\"refs\"`\n \tClosed      *bool    `json:\"closed,omitempty\"`\n@@ -905,7 +905,7 @@ func (s *SchemaUnion) CheckSchema() error {\n }\n \n type SchemaUnknown struct {\n-\tType        string  `json:\"type,const=unknown\"`\n+\tType        string  `json:\"type\"` // \"unknown\"\n \tDescription *string `json:\"description,omitempty\"`\n }\n \n---\n"}], "ideal": "Title: remove invalid JSON 'const=' struct field tags\n\nBody: I assumed this worked, but it doesn't!\r\n\r\nFound via golangci-lint."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": ".gitignore\n@@ -36,6 +36,7 @@ test-coverage.out\n # Don't ignore this file itself, or other specific dotfiles\n !.gitignore\n !.github/\n+!.golangci.yaml\n \n # Don't commit your (default location) creds\n bsky.auth\n---\n.golangci.yaml\n@@ -0,0 +1,17 @@\n+version: \"2\"\n+\n+issues:\n+  max-issues-per-linter: 0\n+  max-same-issues: 0\n+\n+linters:\n+  disable:\n+    - errcheck\n+    - gocritic\n+    - unused\n+  settings:\n+    errcheck:\n+      check-type-assertions: true\n+      disable-default-exclusions: true\n+    gocritic:\n+      enable-all: true\n---\natproto/identity/apidir/apidir.go\n@@ -40,11 +40,6 @@ type handleBody struct {\n \tDID syntax.DID `json:\"did\"`\n }\n \n-type errorBody struct {\n-\tName    string `json:\"error\"`\n-\tMessage string `json:\"message,omitempty\"`\n-}\n-\n func NewAPIDirectory(host string) APIDirectory {\n \treturn APIDirectory{\n \t\tClient: &http.Client{\n---\natproto/identity/directory.go\n@@ -57,7 +57,7 @@ var ErrDIDResolutionFailed = errors.New(\"DID resolution failed\")\n var ErrKeyNotDeclared = errors.New(\"DID document did not declare a relevant public key\")\n \n // Handle was invalid, in a situation where a valid handle is required.\n-var ErrInvalidHandle = errors.New(\"Invalid Handle\")\n+var ErrInvalidHandle = errors.New(\"invalid handle\")\n \n var DefaultPLCURL = \"https://plc.directory\"\n \n---\natproto/lexicon/cmd/lextool/net.go\n@@ -65,6 +65,9 @@ func runValidateRecord(cctx *cli.Context) error {\n \t}\n \n \tbody, err := data.UnmarshalJSON(respBytes)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n \trecord, ok := body[\"value\"].(map[string]any)\n \tif !ok {\n \t\treturn fmt.Errorf(\"fetched record was not an object\")\n---\natproto/repo/mst/mst_interop_test.go\n@@ -104,9 +104,8 @@ func TestInteropKnownMaps(t *testing.T) {\n }\n \n func TestInteropKnownMapsTricky(t *testing.T) {\n-\tassert := assert.New(t)\n-\n \tt.Skip(\"TODO: these are currently disallowed in typescript implementation\")\n+\tassert := assert.New(t)\n \n \tcid1str := \"bafyreie5cvv4h45feadgeuwhbcutmh6t2ceseocckahdoe6uat64zmz454\"\n \n---\natproto/repo/mst/mst_test.go\n@@ -180,7 +180,7 @@ func TestRandomTree(t *testing.T) {\n \n \tmapKeys := make([]string, len(inMap))\n \ti := 0\n-\tfor k, _ := range inMap {\n+\tfor k := range inMap {\n \t\tmapKeys[i] = k\n \t\ti++\n \t}\n---\natproto/repo/mst/node.go\n@@ -186,7 +186,7 @@ func (n *Node) compareKey(key []byte, markDirty bool) (int, error) {\n \t\t// TODO: should we actually return 0 in this case?\n \t\treturn 0, fmt.Errorf(\"can't determine key range of empty MST node\")\n \t}\n-\tif markDirty == true {\n+\tif markDirty {\n \t\tn.Dirty = true\n \t}\n \t// check if lower than this entire node\n---\natproto/repo/mst/node_insert.go\n@@ -1,6 +1,7 @@\n package mst\n \n import (\n+\t\"errors\"\n \t\"fmt\"\n \t\"slices\"\n \n@@ -66,7 +67,9 @@ func (n *Node) insert(key []byte, val cid.Cid, height int) (*Node, *cid.Cid, err\n \t}\n \n \t// include \"covering\" proof for this operation\n-\tproveMutation(n, key)\n+\tif err := proveMutation(n, key); err != nil && !errors.Is(err, ErrPartialTree) {\n+\t\treturn nil, nil, err\n+\t}\n \n \tif !split {\n \t\t// TODO: is this really necessary? or can we just slices.Insert beyond the end of a slice?\n---\natproto/repo/mst/node_remove.go\n@@ -1,6 +1,7 @@\n package mst\n \n import (\n+\t\"errors\"\n \t\"fmt\"\n \t\"slices\"\n \n@@ -61,7 +62,9 @@ func (n *Node) remove(key []byte, height int) (*Node, *cid.Cid, error) {\n \t}\n \n \t// marks adjacent child nodes dirty to include as \"proof\"\n-\tproveMutation(n, key)\n+\tif err := proveMutation(n, key); err != nil && !errors.Is(err, ErrPartialTree) {\n+\t\treturn nil, nil, err\n+\t}\n \n \t// check if top of node is now just a pointer\n \tif top {\n---\natproto/repo/operation.go\n@@ -147,7 +147,7 @@ func NormalizeOps(list []Operation) ([]Operation, error) {\n \n \tset := map[string]bool{}\n \tfor _, op := range list {\n-\t\tif _, ok := set[op.Path]; ok != false {\n+\t\tif _, ok := set[op.Path]; ok {\n \t\t\treturn nil, fmt.Errorf(\"duplicate path in operation list\")\n \t\t}\n \t\tset[op.Path] = true\n---\natproto/repo/operation_test.go\n@@ -91,9 +91,10 @@ func TestBasicOperation(t *testing.T) {\n \tassert.NoError(err)\n \tassert.Error(CheckOp(tree, op))\n \n-\top, err = ApplyOp(tree, \"color/pink\", &c3)\n+\t_, err = ApplyOp(tree, \"color/pink\", &c3)\n \tassert.NoError(err)\n \top, err = ApplyOp(tree, \"color/pink\", &c2)\n+\tassert.NoError(err)\n \tassert.NoError(CheckOp(tree, op))\n \tassert.True(op.IsUpdate())\n \terr = InvertOp(tree, op)\n@@ -130,7 +131,7 @@ func randomOperations(t *testing.T, size, opCount, iterations int) {\n \t}\n \tmapKeys := make([]string, len(startMap))\n \ti := 0\n-\tfor k, _ := range startMap {\n+\tfor k := range startMap {\n \t\tmapKeys[i] = k\n \t\ti++\n \t}\n---\natproto/syntax/did.go\n@@ -14,7 +14,6 @@ import (\n type DID string\n \n var didRegex = regexp.MustCompile(`^did:[a-z]+:[a-zA-Z0-9._:%-]*[a-zA-Z0-9._-]$`)\n-var plcChars = \"\"\n \n func isASCIIAlphaNum(c rune) bool {\n \tif (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || (c >= '0' && c <= '9') {\n---\natproto/syntax/tid.go\n@@ -58,7 +58,7 @@ func NewTIDFromInteger(v uint64) TID {\n \n // Constructs a new TID from a UNIX timestamp (in milliseconds) and clock ID value.\n func NewTID(unixMicros int64, clockId uint) TID {\n-\tvar v uint64 = (uint64(unixMicros&0x1F_FFFF_FFFF_FFFF) << 10) | uint64(clockId&0x3FF)\n+\tv := (uint64(unixMicros&0x1F_FFFF_FFFF_FFFF) << 10) | uint64(clockId&0x3FF)\n \treturn NewTIDFromInteger(v)\n }\n \n---\n"}], "ideal": "Title: batch of golangci-lint fixes in `atproto/*`\n\nBody: This isn't everything, just a first pass. There were some real issues with errors not getting wired through.\r\n\r\nI'm kind of ambivalent about the pattern:\r\n\r\n```go\r\n\tdefer func() {\r\n\t\t_ = resp.Body.Close()\r\n\t}()\r\n```\r\n\r\nbut do want to make any non-defer error returns explicit."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/collectiondir/serve.go\n@@ -405,6 +405,7 @@ func (cs *collectionServer) StartApiServer(ctx context.Context, addr string) err\n \t}\n \te := echo.New()\n \te.HideBanner = true\n+\te.HTTPErrorHandler = cs.errorHandler\n \n \te.Use(svcutil.MetricsMiddleware)\n \te.Use(middleware.CORSWithConfig(middleware.CORSConfig{\n@@ -455,6 +456,26 @@ func getLimit(c echo.Context, min, defaultLim, max int) int {\n \treturn lv\n }\n \n+type xrpcError struct {\n+\tError   string `json:\"error\"`\n+\tMessage string `json:\"message\"`\n+}\n+\n+func (srv *collectionServer) errorHandler(err error, c echo.Context) {\n+\tcode := http.StatusInternalServerError\n+\tvar errorMessage string\n+\tif he, ok := err.(*echo.HTTPError); ok {\n+\t\tcode = he.Code\n+\t\terrorMessage = fmt.Sprintf(\"%s\", he.Message)\n+\t}\n+\tif code >= 500 && code <= 599 {\n+\t\tslog.With(\"err\", err).Error(\"collectiondir-http-internal-error\")\n+\t}\n+\tif !c.Response().Committed {\n+\t\tc.JSON(code, xrpcError{Error: \"InternalError\", Message: errorMessage})\n+\t}\n+}\n+\n // /xrpc/com.atproto.sync.listReposByCollection?collection={}&cursor={}&limit={50<=N<=1000}\n // /v1/getDidsForCollection?collection={}&cursor={}&limit={50<=N<=1000}\n //\n@@ -465,14 +486,20 @@ func (cs *collectionServer) getDidsForCollection(c echo.Context) error {\n \tcollection := c.QueryParam(\"collection\")\n \t_, err := syntax.ParseNSID(collection)\n \tif err != nil {\n-\t\treturn c.String(http.StatusBadRequest, fmt.Sprintf(\"bad collection nsid, %s\", err.Error()))\n+\t\treturn c.JSON(http.StatusBadRequest, xrpcError{\n+\t\t\tError:   \"InvalidCollectionNSID\",\n+\t\t\tMessage: err.Error(),\n+\t\t})\n \t}\n \tcursor := c.QueryParam(\"cursor\")\n \tlimit := getLimit(c, 1, 500, 10_000)\n \tthey, nextCursor, err := cs.pcd.ReadCollection(ctx, collection, cursor, limit)\n \tif err != nil {\n \t\tslog.Error(\"ReadCollection\", \"collection\", collection, \"cursor\", cursor, \"limit\", limit, \"err\", err)\n-\t\treturn c.String(http.StatusInternalServerError, \"oops\")\n+\t\treturn c.JSON(http.StatusInternalServerError, xrpcError{\n+\t\t\tError:   \"InternalError\",\n+\t\t\tMessage: err.Error(),\n+\t\t})\n \t}\n \tcs.log.Info(\"getDidsForCollection\", \"collection\", collection, \"cursor\", cursor, \"limit\", limit, \"count\", len(they), \"nextCursor\", nextCursor)\n \tvar out comatproto.SyncListReposByCollection_Output\n---\n"}], "ideal": "Title: Gracefully Handle XRPC Errors in Collectiondir\n\nBody: Similar to what we do with [other services](https://github.com/bluesky-social/indigo/blob/8500c47d717c0a6004191d5246b37d322210e72b/cmd/bluepages/server.go#L205) that speak XRPC, collectiondir should respond with the standard error response format according to [the docs](https://atproto.com/specs/xrpc).\r\n\r\nI'm not 100% that we want this same format for the \"admin\" handlers on this service. Happy to apply this to all handlers if that's the case, but for now, I've only modified the actual XRPC request (there's only one on the collectiondir service at this time).\r\n\r\nHere's an example failed response, and a successful response with these new error handlers:\r\n\r\n```\r\n$ xh -v localhost:2510/xrpc/com.atproto.sync.listReposByCollection?collection=bad\r\nGET /xrpc/com.atproto.sync.listReposByCollection?collection=bad HTTP/1.1\r\nAccept: */*\r\nAccept-Encoding: gzip, deflate, br, zstd\r\nConnection: keep-alive\r\nHost: localhost:2510\r\nUser-Agent: xh/0.24.0\r\n\r\nHTTP/1.1 400 Bad Request\r\nContent-Length: 84\r\nContent-Type: application/json; charset=UTF-8\r\nDate: Mon, 14 Apr 2025 15:51:04 GMT\r\nVary: Origin\r\n\r\n{\r\n    \"error\": \"InvalidCollectionNSID\",\r\n    \"message\": \"NSID syntax didn't validate via regex\"\r\n}\r\n```\r\n\r\n```\r\n$ xh -v localhost:2510/xrpc/com.atproto.sync.listReposByCollection?collection=a.b.c\r\nGET /xrpc/com.atproto.sync.listReposByCollection?collection=a.b.c HTTP/1.1\r\nAccept: */*\r\nAccept-Encoding: gzip, deflate, br, zstd\r\nConnection: keep-alive\r\nHost: localhost:2510\r\nUser-Agent: xh/0.24.0\r\n\r\nHTTP/1.1 200 OK\r\nContent-Length: 13\r\nContent-Type: application/json; charset=UTF-8\r\nDate: Mon, 14 Apr 2025 15:54:52 GMT\r\nVary: Origin\r\n\r\n{\r\n    \"repos\": []\r\n}\r\n```"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/collectiondir/serve.go\n@@ -5,10 +5,12 @@ import (\n \t\"context\"\n \t\"encoding/csv\"\n \t\"encoding/json\"\n+\t\"errors\"\n \t\"fmt\"\n \t\"log/slog\"\n \t\"net\"\n \t\"net/http\"\n+\t_ \"net/http/pprof\"\n \t\"net/url\"\n \t\"os\"\n \t\"os/signal\"\n@@ -193,12 +195,12 @@ func (cs *collectionServer) run(cctx *cli.Context) error {\n \tif err != nil {\n \t\treturn fmt.Errorf(\"lru init, %w\", err)\n \t}\n-\tcs.wg.Add(1)\n-\tgo cs.ingestReceiver()\n \tcs.log = log\n \tcs.ctx = cctx.Context\n \tcs.AdminToken = cctx.String(\"admin-token\")\n \tcs.ExepctedAuthHeader = \"Bearer \" + cs.AdminToken\n+\tcs.wg.Add(1)\n+\tgo cs.ingestReceiver()\n \tpebblePath := cctx.String(\"pebble\")\n \tcs.pcd = &PebbleCollectionDirectory{\n \t\tlog: cs.log,\n@@ -215,17 +217,17 @@ func (cs *collectionServer) run(cctx *cli.Context) error {\n \t\t}\n \t}\n \tcs.statsCacheFresh.L = &cs.statsCacheLock\n-\terrchan := make(chan error, 3)\n-\tapiAddr := cctx.String(\"api-listen\")\n+\n+\tapiServerEcho, err := cs.createApiServer(cctx.Context, cctx.String(\"api-listen\"))\n+\tif err != nil {\n+\t\treturn err\n+\t}\n \tcs.wg.Add(1)\n-\tgo func() {\n-\t\terrchan <- cs.StartApiServer(cctx.Context, apiAddr)\n-\t}()\n-\tmetricsAddr := cctx.String(\"metrics-listen\")\n+\tgo func() { cs.StartApiServer(cctx.Context, apiServerEcho) }()\n+\n+\tcs.createMetricsServer(cctx.String(\"metrics-listen\"))\n \tcs.wg.Add(1)\n-\tgo func() {\n-\t\terrchan <- cs.StartMetricsServer(cctx.Context, metricsAddr)\n-\t}()\n+\tgo func() { cs.StartMetricsServer(cctx.Context) }()\n \n \tupstream := cctx.String(\"upstream\")\n \tif upstream != \"\" {\n@@ -247,19 +249,9 @@ func (cs *collectionServer) run(cctx *cli.Context) error {\n \t\tgo cs.handleFirehose(fhevents)\n \t}\n \n-\tselect {\n-\tcase <-signals:\n-\t\tlog.Info(\"received shutdown signal\")\n-\t\tgo errchanlog(cs.log, \"server error\", errchan)\n-\t\treturn cs.Shutdown()\n-\tcase err := <-errchan:\n-\t\tif err != nil {\n-\t\t\tlog.Error(\"server error\", \"err\", err)\n-\t\t\tgo errchanlog(cs.log, \"server error\", errchan)\n-\t\t\treturn cs.Shutdown()\n-\t\t}\n-\t}\n-\treturn nil\n+\t<-signals\n+\tlog.Info(\"received shutdown signal\")\n+\treturn cs.Shutdown()\n }\n \n func (cs *collectionServer) openDau() error {\n@@ -282,29 +274,34 @@ func (cs *collectionServer) openDau() error {\n \treturn nil\n }\n \n-func errchanlog(log *slog.Logger, msg string, errchan <-chan error) {\n-\tfor err := range errchan {\n-\t\tlog.Error(msg, \"err\", err)\n-\t}\n-}\n-\n func (cs *collectionServer) Shutdown() error {\n \tclose(cs.shutdown)\n-\tgo func() {\n+\n+\tfunc() {\n+\t\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n+\t\tdefer cancel()\n+\n \t\tcs.log.Info(\"metrics shutdown start\")\n-\t\tsherr := cs.metricsServer.Shutdown(context.Background())\n+\t\tsherr := cs.metricsServer.Shutdown(ctx)\n \t\tcs.log.Info(\"metrics shutdown\", \"err\", sherr)\n \t}()\n-\tcs.log.Info(\"api shutdown start...\")\n-\terr := cs.apiServer.Shutdown(context.Background())\n-\tcs.log.Info(\"api shutdown, thread wait...\", \"err\", err)\n-\tcs.wg.Wait()\n+\n+\tfunc() {\n+\t\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n+\t\tdefer cancel()\n+\n+\t\tcs.log.Info(\"api shutdown start...\")\n+\t\terr := cs.apiServer.Shutdown(ctx)\n+\t\tcs.log.Info(\"api shutdown, thread wait...\", \"err\", err)\n+\t}()\n+\n \tcs.log.Info(\"threads done, db close...\")\n-\tee := cs.pcd.Close()\n-\tif ee != nil {\n-\t\tcs.log.Error(\"failed to shutdown pebble\", \"err\", ee)\n+\terr := cs.pcd.Close()\n+\tif err != nil {\n+\t\tcs.log.Error(\"failed to shutdown pebble\", \"err\", err)\n \t}\n \tcs.log.Info(\"db done. done.\")\n+\tcs.wg.Wait()\n \treturn err\n }\n \n@@ -384,23 +381,33 @@ func (cs *collectionServer) handleCommit(commit *comatproto.SyncSubscribeRepos_C\n \t}\n }\n \n-func (cs *collectionServer) StartMetricsServer(ctx context.Context, addr string) error {\n-\tdefer cs.wg.Done()\n-\tdefer cs.log.Info(\"metrics server exit\")\n+func (cs *collectionServer) createMetricsServer(addr string) {\n+\te := echo.New()\n+\te.GET(\"/metrics\", echo.WrapHandler(promhttp.Handler()))\n+\te.Any(\"/debug/pprof/*\", echo.WrapHandler(http.DefaultServeMux))\n+\n \tcs.metricsServer = &http.Server{\n \t\tAddr:    addr,\n-\t\tHandler: promhttp.Handler(),\n+\t\tHandler: e,\n \t}\n-\treturn cs.metricsServer.ListenAndServe()\n }\n \n-func (cs *collectionServer) StartApiServer(ctx context.Context, addr string) error {\n+func (cs *collectionServer) StartMetricsServer(ctx context.Context) {\n \tdefer cs.wg.Done()\n-\tdefer cs.log.Info(\"api server exit\")\n+\tdefer cs.log.Info(\"metrics server exit\")\n+\n+\terr := cs.metricsServer.ListenAndServe()\n+\tif err != nil && !errors.Is(err, http.ErrServerClosed) {\n+\t\tslog.Error(\"error in metrics server\", \"err\", err)\n+\t\tos.Exit(1)\n+\t}\n+}\n+\n+func (cs *collectionServer) createApiServer(ctx context.Context, addr string) (*echo.Echo, error) {\n \tvar lc net.ListenConfig\n \tli, err := lc.Listen(ctx, \"tcp\", addr)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn nil, err\n \t}\n \te := echo.New()\n \te.HideBanner = true\n@@ -430,7 +437,17 @@ func (cs *collectionServer) StartApiServer(ctx context.Context, addr string) err\n \t\tHandler: e,\n \t}\n \tcs.apiServer = srv\n-\treturn srv.Serve(li)\n+\treturn e, nil\n+}\n+\n+func (cs *collectionServer) StartApiServer(ctx context.Context, e *echo.Echo) {\n+\tdefer cs.wg.Done()\n+\tdefer cs.log.Info(\"api server exit\")\n+\terr := cs.apiServer.Serve(e.Listener)\n+\tif err != nil && !errors.Is(err, http.ErrServerClosed) {\n+\t\tslog.Error(\"error in api server\", \"err\", err)\n+\t\tos.Exit(1)\n+\t}\n }\n \n const statsCacheDuration = time.Second * 300\n---\n"}], "ideal": "Title: Collectiondir Improvements\n\nBody: Perhaps best reviewed by looking at each individual commit.\r\n\r\nAll of these were found by running this, then sending a ctrl+c:\r\n\r\n```bash\r\ngo run -race ./cmd/collectiondir serve --pebble ~/local/data/collectiondir --dau-directory ~/local/data/collectiondir\r\n```\r\n\r\nThis PR improves a few small but important things about the collectiondir service:\r\n\r\n1. This service does not have pprof on the metrics router (f16258882a1c6a82c25465547ae824afbeec9486)\r\n    a. `/metrics` and `/debug/pprof/` now live side-by-side\r\n    b. All services should have pprof enabled on private metrics routers\r\n2. Fixes a race condition on startup where we're binding a bunch of fields on `cs` after launching a goroutine that uses some of those fields (82656e88f5ed5ff706c00cfabb98701c3e8e6d0a)\r\n3. Fixes an issue where sending a SIGTERM to the service causes it to start shutting down, but the service never actually dies because there is an infinite hang due to an errant `cs.wg.Wait()` (8c00259a165833ad0e8e8870691b5f55e3725ea8)\r\n    a. In general though, the `errchan` is not a good approach. Prefer to let each background goroutine do its logging and only coordinate on shutdown timing through a single variable (`cs.wg`)\r\n4. Fix a race condition on the API server startup/shutdown (5191ddd755928d5763cee92d7510c5999583d006)\r\n5. Fix a race condition on the metrics server startup/shutdown (c90e279b78482bea54451cbf6d0520faa432fa8d)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "repo/repo.go\n@@ -7,6 +7,7 @@ import (\n \t\"io\"\n \n \t\"github.com/bluesky-social/indigo/atproto/repo\"\n+\t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \tlexutil \"github.com/bluesky-social/indigo/lex/util\"\n \t\"github.com/bluesky-social/indigo/mst\"\n \t\"github.com/bluesky-social/indigo/util\"\n@@ -49,6 +50,8 @@ type Repo struct {\n \tmst *mst.MerkleSearchTree\n \n \tdirty bool\n+\n+\tclk *syntax.TIDClock\n }\n \n // Returns a copy of commit without the Sig field. Helpful when verifying signature.\n@@ -111,6 +114,7 @@ func ReadRepoFromCar(ctx context.Context, r io.Reader) (*Repo, error) {\n \n func NewRepo(ctx context.Context, did string, bs cbor.IpldBlockstore) *Repo {\n \tcst := util.CborStore(bs)\n+\tclk := syntax.NewTIDClock(0)\n \n \tt := mst.NewEmptyMST(cst)\n \tsc := SignedCommit{\n@@ -124,11 +128,13 @@ func NewRepo(ctx context.Context, did string, bs cbor.IpldBlockstore) *Repo {\n \t\tmst:   t,\n \t\tsc:    sc,\n \t\tdirty: true,\n+\t\tclk:   &clk,\n \t}\n }\n \n func OpenRepo(ctx context.Context, bs cbor.IpldBlockstore, root cid.Cid) (*Repo, error) {\n \tcst := util.CborStore(bs)\n+\tclk := syntax.NewTIDClock(0)\n \n \tvar sc SignedCommit\n \tif err := cst.Get(ctx, root, &sc); err != nil {\n@@ -144,6 +150,7 @@ func OpenRepo(ctx context.Context, bs cbor.IpldBlockstore, root cid.Cid) (*Repo,\n \t\tbs:      bs,\n \t\tcst:     cst,\n \t\trepoCid: root,\n+\t\tclk:     &clk,\n \t}, nil\n }\n \n@@ -191,7 +198,7 @@ func (r *Repo) CreateRecord(ctx context.Context, nsid string, rec CborMarshaler)\n \t\treturn cid.Undef, \"\", err\n \t}\n \n-\ttid := NextTID()\n+\ttid := r.clk.Next().String()\n \n \tnmst, err := t.Add(ctx, nsid+\"/\"+tid, k, -1)\n \tif err != nil {\n@@ -294,7 +301,7 @@ func (r *Repo) Commit(ctx context.Context, signer func(context.Context, string,\n \t\tDid:     r.RepoDid(),\n \t\tVersion: ATP_REPO_VERSION,\n \t\tData:    rcid,\n-\t\tRev:     NextTID(),\n+\t\tRev:     r.clk.Next().String(),\n \t}\n \n \tsb, err := ncom.BytesForSigning()\n---\nrepo/tid.go\n@@ -1,41 +0,0 @@\n-package repo\n-\n-import (\n-\t\"math/rand\"\n-\t\"sync\"\n-\t\"time\"\n-)\n-\n-const alpha = \"234567abcdefghijklmnopqrstuvwxyz\"\n-\n-func s32encode(i uint64) string {\n-\tvar s string\n-\tfor i > 0 {\n-\t\tc := i & 0x1f\n-\t\ti = i >> 5\n-\t\ts = alpha[c:c+1] + s\n-\t}\n-\treturn s\n-}\n-\n-func init() {\n-\tclockId = uint64(rand.Int() & 0x1f)\n-}\n-\n-var lastTime uint64\n-var clockId uint64\n-var ltLock sync.Mutex\n-\n-func NextTID() string {\n-\tt := uint64(time.Now().UnixMicro())\n-\n-\tltLock.Lock()\n-\tif lastTime >= t {\n-\t\tt = lastTime + 1\n-\t}\n-\n-\tlastTime = t\n-\tltLock.Unlock()\n-\n-\treturn s32encode(uint64(t)) + s32encode(clockId)\n-}\n---\nrepomgr/repomgr.go\n@@ -13,6 +13,7 @@ import (\n \n \tatproto \"github.com/bluesky-social/indigo/api/atproto\"\n \tbsky \"github.com/bluesky-social/indigo/api/bsky\"\n+\t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \t\"github.com/bluesky-social/indigo/carstore\"\n \tlexutil \"github.com/bluesky-social/indigo/lex/util\"\n \t\"github.com/bluesky-social/indigo/models\"\n@@ -39,12 +40,15 @@ func NewRepoManager(cs carstore.CarStore, kmgr KeyManager) *RepoManager {\n \t\tnoArchive = true\n \t}\n \n+\tclk := syntax.NewTIDClock(0)\n+\n \treturn &RepoManager{\n \t\tcs:        cs,\n \t\tuserLocks: make(map[models.Uid]*userLock),\n \t\tkmgr:      kmgr,\n \t\tlog:       slog.Default().With(\"system\", \"repomgr\"),\n \t\tnoArchive: noArchive,\n+\t\tclk:       &clk,\n \t}\n }\n \n@@ -70,6 +74,8 @@ type RepoManager struct {\n \n \tlog       *slog.Logger\n \tnoArchive bool\n+\n+\tclk *syntax.TIDClock\n }\n \n type ActorInfo struct {\n@@ -771,10 +777,6 @@ func (rm *RepoManager) handleExternalUserEventArchive(ctx context.Context, pdsid\n \treturn nil\n }\n \n-func rkeyForCollection(collection string) string {\n-\treturn repo.NextTID()\n-}\n-\n func (rm *RepoManager) BatchWrite(ctx context.Context, user models.Uid, writes []*atproto.RepoApplyWrites_Input_Writes_Elem) error {\n \tctx, span := otel.Tracer(\"repoman\").Start(ctx, \"BatchWrite\")\n \tdefer span.End()\n@@ -807,7 +809,7 @@ func (rm *RepoManager) BatchWrite(ctx context.Context, user models.Uid, writes [\n \t\t\tif c.Rkey != nil {\n \t\t\t\trkey = *c.Rkey\n \t\t\t} else {\n-\t\t\t\trkey = rkeyForCollection(c.Collection)\n+\t\t\t\trkey = rm.clk.Next().String()\n \t\t\t}\n \n \t\t\tnsid := c.Collection + \"/\" + rkey\n---\n"}], "ideal": "Title: switch to atproto/syntax TID generator\n\nBody: repo and repomgr packages rely on incorrect TID generation functions which do not enforce lengths properly unlike the ones in the syntax package, producing strings of 12 characters instead of 13, due to not padding the clock id, breaking lexicon validation when used in the context of atproto. This removes the `tid.go` file to use the other implementation instead."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/collectiondir/README.md\n@@ -1,31 +1,33 @@\n-# Collection Directory\n \n-Maintain a directory of which repos use which collections of records.\n+`collectiondir`: Directory of Accounts by Collection\n+====================================================\n \n-e.g. \"app.bsky.feed.post\" is used by did:alice did:bob\n+This is a small atproto microservice which maintains a directory of which accounts in the network (DIDs) have data (records) for which collections (NSIDs).\n \n-Firehose consumer and crawler of PDS via listRepos and describeRepo.\n-\n-The primary query is:\n+It primarily serves the `com.atproto.sync.listReposByCollection` API endpoint:\n \n ```\n-/v1/getDidsForCollection?collection={}&cursor={}\n+GET /xrpc/com.atproto.sync.listReposByCollection?collection=com.atproto.sync.listReposByCollection?collection=com.atproto.lexicon.schema&limit=3\n+\n+{\n+    \"repos\": [\n+        { \"did\": \"did:plc:4sm3vprfyl55ui3yhjd7w4po\" },\n+        { \"did\": \"did:plc:xhkqwjmxuo65vwbwuiz53qor\" },\n+        { \"did\": \"did:plc:w3aonw33w3mz3mwws34x5of6\" }\n+    ],\n+    \"cursor\": \"QQAAAEkAAAGVgFFLb2RpZDpwbGM6dzNhb253MzN3M216M213d3MzNHg1b2Y2AA==\"\n+}\n ```\n \n-It returns JSON:\n+Features and design points:\n \n-```json\n-{\"dids\":[\"did:A\", \"...\"],\n-\"cursor\":\"opaque text\"}\n-```\n+- persists data in a local key/value database (pebble)\n+- consumes from the firehose to stay up to date with record creation\n+- can bootstrap the full network using `com.atproto.sync.listRepos` and `com.atproto.repo.describeRepo`\n+- single golang binary for easy deployment\n \n-query parameter `collection` may be repeated up to 10 times. They must always be sent in the same order or the cursor will break.\n \n-If multiple collections are specified, the result stream is not guaranteed to be de-duplicated on Did and Dids may be repeated.\n-(A merge window is used so that the service is _likely_ to not send duplicate Dids.)\n-\n-\n-### Analytics queries\n+## Analytics Endpoint\n \n ```\n /v1/listCollections?c={}&cursor={}&limit={50<=limit<=1000}\n@@ -41,9 +43,7 @@ It may be the cached result of a computation, up to several minutes out of date.\n ```\n \n \n-## Design\n-\n-### Schema\n+## Database Schema\n \n The primary database is (collection, seen time int64 milliseconds, did)\n \n---\ncmd/collectiondir/serve.go\n@@ -297,7 +297,6 @@ func (cs *collectionServer) Shutdown() error {\n \t}()\n \tcs.log.Info(\"api shutdown start...\")\n \terr := cs.apiServer.Shutdown(context.Background())\n-\t//err := cs.esrv.Shutdown(context.Background())\n \tcs.log.Info(\"api shutdown, thread wait...\", \"err\", err)\n \tcs.wg.Wait()\n \tcs.log.Info(\"threads done, db close...\")\n@@ -465,14 +464,14 @@ func (cs *collectionServer) getDidsForCollection(c echo.Context) error {\n \tcollection := c.QueryParam(\"collection\")\n \t_, err := syntax.ParseNSID(collection)\n \tif err != nil {\n-\t\treturn c.String(http.StatusBadRequest, fmt.Sprintf(\"bad collection nsid, %s\", err.Error()))\n+\t\treturn c.JSON(http.StatusBadRequest, xrpc.XRPCError{ErrStr: \"BadRequest\", Message: fmt.Sprintf(\"bad collection nsid, %s\", err.Error())})\n \t}\n \tcursor := c.QueryParam(\"cursor\")\n \tlimit := getLimit(c, 1, 500, 10_000)\n \tthey, nextCursor, err := cs.pcd.ReadCollection(ctx, collection, cursor, limit)\n \tif err != nil {\n \t\tslog.Error(\"ReadCollection\", \"collection\", collection, \"cursor\", cursor, \"limit\", limit, \"err\", err)\n-\t\treturn c.String(http.StatusInternalServerError, \"oops\")\n+\t\treturn c.JSON(http.StatusInternalServerError, xrpc.XRPCError{ErrStr: \"DatabaseError\", Message: \"failed to read DIDs for collection\"})\n \t}\n \tcs.log.Info(\"getDidsForCollection\", \"collection\", collection, \"cursor\", cursor, \"limit\", limit, \"count\", len(they), \"nextCursor\", nextCursor)\n \tvar out comatproto.SyncListReposByCollection_Output\n@@ -620,7 +619,7 @@ func (cs *collectionServer) listCollections(c echo.Context) error {\n \tif stalesecStr != \"\" && cs.isAdmin(c) {\n \t\tstalesec, err := strconv.ParseInt(stalesecStr, 10, 64)\n \t\tif err != nil {\n-\t\t\treturn c.String(http.StatusBadRequest, \"bad stalesec\")\n+\t\t\treturn c.JSON(http.StatusBadRequest, xrpc.XRPCError{ErrStr: \"BadRequest\", Message: \"invalid 'stalesec' query parameter\"})\n \t\t}\n \t\tif stalesec == 0 {\n \t\t\tstalenessAllowed = 1\n@@ -632,7 +631,7 @@ func (cs *collectionServer) listCollections(c echo.Context) error {\n \tstats, err := cs.getStatsCache(stalenessAllowed)\n \tif err != nil {\n \t\tslog.Error(\"getStatsCache\", \"err\", err)\n-\t\treturn c.String(http.StatusInternalServerError, \"oops\")\n+\t\treturn c.JSON(http.StatusInternalServerError, xrpc.XRPCError{ErrStr: \"DatabaseError\", Message: \"failed to read stats\"})\n \t}\n \tcursor := c.QueryParam(\"cursor\")\n \tcollections, hasQueryCollections := c.QueryParams()[\"c\"]\n@@ -705,6 +704,9 @@ func (cs *collectionServer) ingestReceiver() {\n \t\t\t} else {\n \t\t\t\terrcount = 0\n \t\t\t}\n+\t\tcase <-cs.shutdown:\n+\t\t\tcs.log.Info(\"shutting down ingestReceiver\")\n+\t\t\treturn\n \t\t}\n \t\tif errcount > 10 {\n \t\t\tcs.log.Error(\"ingestReceiver too many errors\")\n@@ -852,7 +854,7 @@ func (cs *collectionServer) isAdmin(c echo.Context) bool {\n func (cs *collectionServer) crawlPds(c echo.Context) error {\n \tisAdmin := cs.isAdmin(c)\n \tif !isAdmin {\n-\t\treturn c.JSON(http.StatusForbidden, CrawlRequestResponse{Error: \"nope\"})\n+\t\treturn c.JSON(http.StatusForbidden, xrpc.XRPCError{ErrStr: \"AdminRequired\", Message: \"this endpoint requires admin auth\"})\n \t}\n \thostQ := c.QueryParam(\"host\")\n \tif hostQ != \"\" {\n@@ -864,7 +866,7 @@ func (cs *collectionServer) crawlPds(c echo.Context) error {\n \terr := c.Bind(&req)\n \tif err != nil {\n \t\tcs.log.Info(\"bad crawl bind\", \"err\", err)\n-\t\treturn c.String(http.StatusBadRequest, err.Error())\n+\t\treturn c.JSON(http.StatusBadRequest, xrpc.XRPCError{ErrStr: \"BadRequest\", Message: fmt.Sprintf(\"failed to parse body: %s\", err)})\n \t}\n \tif req.Host != \"\" {\n \t\tgo cs.crawlThread(req.Host)\n@@ -958,7 +960,7 @@ type HostCrawl struct {\n func (cs *collectionServer) crawlStatus(c echo.Context) error {\n \tauthHeader := c.Request().Header.Get(\"Authorization\")\n \tif authHeader != cs.ExepctedAuthHeader {\n-\t\treturn c.JSON(http.StatusForbidden, CrawlRequestResponse{Error: \"nope\"})\n+\t\treturn c.JSON(http.StatusBadRequest, xrpc.XRPCError{ErrStr: \"AdminAuthRequired\", Message: \"this endpoint requires admin-level auth\"})\n \t}\n \tvar out CrawlStatusResponse\n \tout.HostCrawls = make(map[string]HostCrawl)\n@@ -977,7 +979,7 @@ func (cs *collectionServer) crawlStatus(c echo.Context) error {\n \n func (cs *collectionServer) healthz(c echo.Context) error {\n \t// TODO: check database or upstream health?\n-\treturn c.String(http.StatusOK, \"ok\")\n+\treturn c.JSON(http.StatusOK, map[string]any{\"status\": \"ok\"})\n }\n \n func loadBadwords(path string) (*BadwordsRE, error) {\n---\n"}], "ideal": "Title: some collectiondir fixes\n\nBody: This isn't a full pass, just fixing some known issues:\r\n\r\n- process wasn't shutting down with Ctrl-C because of a WaitGroup. fixed the bug, but didn't clean up the (many) channels+goroutines\r\n- many API response errors were strings, not the expected XRPC JSON message format\r\n- README didn't describe the actual API endpoint"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "events/dbpersist/dbpersist.go\n@@ -171,6 +171,8 @@ func (p *DbPersistence) flushBatchLocked(ctx context.Context) error {\n \t\tswitch {\n \t\tcase e.RepoCommit != nil:\n \t\t\te.RepoCommit.Seq = int64(item.Seq)\n+\t\tcase e.RepoSync != nil:\n+\t\t\te.RepoSync.Seq = int64(item.Seq)\n \t\tcase e.RepoHandle != nil:\n \t\t\te.RepoHandle.Seq = int64(item.Seq)\n \t\tcase e.RepoIdentity != nil:\n@@ -218,6 +220,11 @@ func (p *DbPersistence) Persist(ctx context.Context, e *events.XRPCStreamEvent)\n \t\tif err != nil {\n \t\t\treturn err\n \t\t}\n+\tcase e.RepoSync != nil:\n+\t\trer, err = p.RecordFromRepoSync(ctx, e.RepoSync)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n \tcase e.RepoHandle != nil:\n \t\trer, err = p.RecordFromHandleChange(ctx, e.RepoHandle)\n \t\tif err != nil {\n@@ -371,6 +378,28 @@ func (p *DbPersistence) RecordFromRepoCommit(ctx context.Context, evt *comatprot\n \treturn &rer, nil\n }\n \n+func (p *DbPersistence) RecordFromRepoSync(ctx context.Context, evt *comatproto.SyncSubscribeRepos_Sync) (*RepoEventRecord, error) {\n+\n+\tuid, err := p.uidForDid(ctx, evt.Did)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tt, err := time.Parse(util.ISO8601, evt.Time)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trer := RepoEventRecord{\n+\t\tRepo: uid,\n+\t\tType: \"repo_sync\",\n+\t\tTime: t,\n+\t\tRev:  evt.Rev,\n+\t}\n+\n+\treturn &rer, nil\n+}\n+\n func (p *DbPersistence) Playback(ctx context.Context, since int64, cb func(*events.XRPCStreamEvent) error) error {\n \tpageSize := 1000\n \n@@ -449,6 +478,8 @@ func (p *DbPersistence) hydrateBatch(ctx context.Context, batch []*RepoEventReco\n \t\t\tswitch {\n \t\t\tcase record.Commit != nil:\n \t\t\t\tstreamEvent, err = p.hydrateCommit(ctx, record)\n+\t\t\tcase record.Type == \"repo_sync\":\n+\t\t\t\tstreamEvent, err = p.hydrateSyncEvent(ctx, record)\n \t\t\tcase record.NewHandle != nil:\n \t\t\t\tstreamEvent, err = p.hydrateHandleChange(ctx, record)\n \t\t\tcase record.Type == \"repo_identity\":\n@@ -639,6 +670,29 @@ func (p *DbPersistence) hydrateCommit(ctx context.Context, rer *RepoEventRecord)\n \treturn &events.XRPCStreamEvent{RepoCommit: out}, nil\n }\n \n+func (p *DbPersistence) hydrateSyncEvent(ctx context.Context, rer *RepoEventRecord) (*events.XRPCStreamEvent, error) {\n+\n+\tdid, err := p.didForUid(ctx, rer.Repo)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tevt := &comatproto.SyncSubscribeRepos_Sync{\n+\t\tSeq:  int64(rer.Seq),\n+\t\tDid:  did,\n+\t\tTime: rer.Time.Format(util.ISO8601),\n+\t\tRev:  rer.Rev,\n+\t}\n+\n+\tcs, err := p.readCarSlice(ctx, rer)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"read car slice: %w\", err)\n+\t}\n+\tevt.Blocks = cs\n+\n+\treturn &events.XRPCStreamEvent{RepoSync: evt}, nil\n+}\n+\n func (p *DbPersistence) readCarSlice(ctx context.Context, rer *RepoEventRecord) ([]byte, error) {\n \n \tbuf := new(bytes.Buffer)\n---\nevents/diskpersist/diskpersist.go\n@@ -282,6 +282,7 @@ const (\n \tevtKindTombstone = 3\n \tevtKindIdentity  = 4\n \tevtKindAccount   = 5\n+\tevtKindSync      = 6\n )\n \n var emptyHeader = make([]byte, headerSize)\n@@ -455,6 +456,8 @@ func (dp *DiskPersistence) doPersist(ctx context.Context, j persistJob) error {\n \tswitch {\n \tcase e.RepoCommit != nil:\n \t\te.RepoCommit.Seq = seq\n+\tcase e.RepoSync != nil:\n+\t\te.RepoSync.Seq = seq\n \tcase e.RepoHandle != nil:\n \t\te.RepoHandle.Seq = seq\n \tcase e.RepoIdentity != nil:\n@@ -509,6 +512,12 @@ func (dp *DiskPersistence) Persist(ctx context.Context, e *events.XRPCStreamEven\n \t\tif err := e.RepoCommit.MarshalCBOR(cw); err != nil {\n \t\t\treturn fmt.Errorf(\"failed to marshal: %w\", err)\n \t\t}\n+\tcase e.RepoSync != nil:\n+\t\tevtKind = evtKindSync\n+\t\tdid = e.RepoSync.Did\n+\t\tif err := e.RepoSync.MarshalCBOR(cw); err != nil {\n+\t\t\treturn fmt.Errorf(\"failed to marshal: %w\", err)\n+\t\t}\n \tcase e.RepoHandle != nil:\n \t\tevtKind = evtKindHandle\n \t\tdid = e.RepoHandle.Did\n@@ -745,6 +754,15 @@ func (dp *DiskPersistence) readEventsFrom(ctx context.Context, since int64, fn s\n \t\t\tif err := cb(&events.XRPCStreamEvent{RepoCommit: &evt}); err != nil {\n \t\t\t\treturn nil, err\n \t\t\t}\n+\t\tcase evtKindSync:\n+\t\t\tvar evt atproto.SyncSubscribeRepos_Sync\n+\t\t\tif err := evt.UnmarshalCBOR(io.LimitReader(bufr, h.Len64())); err != nil {\n+\t\t\t\treturn nil, err\n+\t\t\t}\n+\t\t\tevt.Seq = h.Seq\n+\t\t\tif err := cb(&events.XRPCStreamEvent{RepoSync: &evt}); err != nil {\n+\t\t\t\treturn nil, err\n+\t\t\t}\n \t\tcase evtKindHandle:\n \t\t\tvar evt atproto.SyncSubscribeRepos_Handle\n \t\t\tif err := evt.UnmarshalCBOR(io.LimitReader(bufr, h.Len64())); err != nil {\n---\nevents/yolopersist/yolopersist.go\n@@ -28,6 +28,8 @@ func (yp *YoloPersister) Persist(ctx context.Context, e *events.XRPCStreamEvent)\n \tswitch {\n \tcase e.RepoCommit != nil:\n \t\te.RepoCommit.Seq = yp.seq\n+\tcase e.RepoSync != nil:\n+\t\te.RepoSync.Seq = yp.seq\n \tcase e.RepoHandle != nil:\n \t\te.RepoHandle.Seq = yp.seq\n \tcase e.RepoIdentity != nil:\n---\n"}], "ideal": "Title: events: add sync event support to persist implementations\n\nBody: Adds basic support for the new `#sync` event to persister implementations. Note that the pebble persister (used in rainbow) is agnostic to event type, so didn't need any update.\r\n\r\nThis PR is a bit drive-by: the new relay work doesn't use this copy of the persist code, and these patches haven't been demonstrated to work."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/identity.go\n@@ -13,25 +13,25 @@ import (\n \n // Represents an atproto identity. Could be a regular user account, or a service account (eg, feed generator)\n type Identity struct {\n-\tDID syntax.DID\n+\tDID syntax.DID `json:\"did\"`\n \n \t// Handle/DID mapping must be bi-directionally verified. If that fails, the Handle should be the special 'handle.invalid' value\n-\tHandle syntax.Handle\n+\tHandle syntax.Handle `json:\"handle\"`\n \n \t// These fields represent a parsed subset of a DID document. They are all nullable. Note that the services and keys maps do not preserve order, so they don't exactly round-trip DID documents.\n-\tAlsoKnownAs []string\n-\tServices    map[string]Service\n-\tKeys        map[string]Key\n+\tAlsoKnownAs []string           `json:\"alsoKnownAs\"`\n+\tServices    map[string]Service `json:\"services\"`\n+\tKeys        map[string]Key     `json:\"keys\"`\n }\n \n type Key struct {\n-\tType               string\n-\tPublicKeyMultibase string\n+\tType               string `json:\"type\"`\n+\tPublicKeyMultibase string `json:\"publicKeyMultibase\"`\n }\n \n type Service struct {\n-\tType string\n-\tURL  string\n+\tType string `json:\"type\"`\n+\tURL  string `json:\"url\"`\n }\n \n // Extracts the information relevant to atproto from an arbitrary DID document.\n---\n"}], "ideal": "Title: make identity.Identity more easily JSON serializable\n\nBody: These result in cleaner JSON for things like test fixtures. Used in new relay project.\r\n\r\ncc: @whyrusleeping to check that other code isn't depending on the previous serialization. Eg, I think you have a memcache identity cache around somewhere. The redis caching stuff uses a different reflect-based serialization technique."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/repo/car.go\n@@ -11,10 +11,14 @@ import (\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \n \tblocks \"github.com/ipfs/go-block-format\"\n+\t\"github.com/ipfs/go-cid\"\n \t\"github.com/ipld/go-car\"\n )\n \n-func LoadFromCAR(ctx context.Context, r io.Reader) (*Commit, *Repo, error) {\n+var ErrNoRoot = errors.New(\"CAR file missing root CID\")\n+var ErrNoCommit = errors.New(\"no commit\")\n+\n+func LoadRepoFromCAR(ctx context.Context, r io.Reader) (*Commit, *Repo, error) {\n \n \t//bs := blockstore.NewBlockstore(datastore.NewMapDatastore())\n \tbs := NewTinyBlockstore()\n@@ -73,21 +77,18 @@ func LoadFromCAR(ctx context.Context, r io.Reader) (*Commit, *Repo, error) {\n \treturn &commit, &repo, nil\n }\n \n-var ErrNoRoot = errors.New(\"CAR file missing root CID\")\n-var ErrNoCommit = errors.New(\"no commit\")\n-\n-// LoadCARCommit is like LoadFromCAR() but filters to only return the commit object.\n-// useful for subscribeRepos/firehose `#sync` message\n-func LoadCARCommit(ctx context.Context, r io.Reader) (*Commit, error) {\n+// LoadCommitFromCAR is like LoadRepoFromCAR() but filters to only return the commit object.\n+// Also returns the commit CID.\n+func LoadCommitFromCAR(ctx context.Context, r io.Reader) (*Commit, *cid.Cid, error) {\n \tcr, err := car.NewCarReader(r)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn nil, nil, err\n \t}\n \tif cr.Header.Version != 1 {\n-\t\treturn nil, fmt.Errorf(\"unsupported CAR file version: %d\", cr.Header.Version)\n+\t\treturn nil, nil, fmt.Errorf(\"unsupported CAR file version: %d\", cr.Header.Version)\n \t}\n \tif len(cr.Header.Roots) < 1 {\n-\t\treturn nil, ErrNoRoot\n+\t\treturn nil, nil, ErrNoRoot\n \t}\n \tcommitCID := cr.Header.Roots[0]\n \tvar commitBlock blocks.Block\n@@ -97,7 +98,7 @@ func LoadCARCommit(ctx context.Context, r io.Reader) (*Commit, error) {\n \t\t\tif err == io.EOF {\n \t\t\t\tbreak\n \t\t\t}\n-\t\t\treturn nil, err\n+\t\t\treturn nil, nil, err\n \t\t}\n \n \t\tif blk.Cid().Equals(commitCID) {\n@@ -106,14 +107,14 @@ func LoadCARCommit(ctx context.Context, r io.Reader) (*Commit, error) {\n \t\t}\n \t}\n \tif commitBlock == nil {\n-\t\treturn nil, ErrNoCommit\n+\t\treturn nil, nil, ErrNoCommit\n \t}\n \tvar commit Commit\n \tif err := commit.UnmarshalCBOR(bytes.NewReader(commitBlock.RawData())); err != nil {\n-\t\treturn nil, fmt.Errorf(\"parsing commit block from CAR file: %w\", err)\n+\t\treturn nil, nil, fmt.Errorf(\"parsing commit block from CAR file: %w\", err)\n \t}\n \tif err := commit.VerifyStructure(); err != nil {\n-\t\treturn nil, fmt.Errorf(\"parsing commit block from CAR file: %w\", err)\n+\t\treturn nil, nil, fmt.Errorf(\"parsing commit block from CAR file: %w\", err)\n \t}\n-\treturn &commit, nil\n+\treturn &commit, &commitCID, nil\n }\n---\natproto/repo/cmd/repo-tool/main.go\n@@ -93,7 +93,7 @@ func runVerifyCarMst(cctx *cli.Context) error {\n \t}\n \tdefer f.Close()\n \n-\tcommit, repo, err := repo.LoadFromCAR(ctx, f)\n+\tcommit, repo, err := repo.LoadRepoFromCAR(ctx, f)\n \tif err != nil {\n \t\treturn err\n \t}\n@@ -125,7 +125,7 @@ func runVerifyCarSignature(cctx *cli.Context) error {\n \t}\n \tdefer f.Close()\n \n-\tcommit, _, err := repo.LoadFromCAR(ctx, f)\n+\tcommit, _, err := repo.LoadRepoFromCAR(ctx, f)\n \tif err != nil {\n \t\treturn err\n \t}\n---\natproto/repo/sync.go\n@@ -40,7 +40,7 @@ func VerifyCommitMessage(ctx context.Context, msg *comatproto.SyncSubscribeRepos\n \t\tlogger.Warn(\"event with rebase flag set\")\n \t}\n \n-\tcommit, repo, err := LoadFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n+\tcommit, repo, err := LoadRepoFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n \tif err != nil {\n \t\treturn nil, err\n \t}\n@@ -168,7 +168,7 @@ func parseCommitOps(ops []*comatproto.SyncSubscribeRepos_RepoOp) ([]Operation, e\n //\n // TODO: in real implementation, will want to merge this code with `VerifyCommitMessage` above, and have it hanging off some service struct with a configured `identity.Directory`\n func VerifyCommitSignature(ctx context.Context, dir identity.Directory, msg *comatproto.SyncSubscribeRepos_Commit) error {\n-\tcommit, _, err := LoadFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n+\tcommit, _, err := LoadRepoFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n \tif err != nil {\n \t\treturn err\n \t}\n---\natproto/repo/sync_test.go\n@@ -47,7 +47,7 @@ func testCommitFile(t *testing.T, p string) {\n \t_, err = VerifyCommitMessage(ctx, &msg)\n \tassert.NoError(err)\n \tif err != nil {\n-\t\t_, repo, err := LoadFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n+\t\t_, repo, err := LoadRepoFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n \t\tif err != nil {\n \t\t\tt.Fail()\n \t\t}\n---\ncmd/goat/firehose.go\n@@ -256,7 +256,7 @@ func (gfc *GoatFirehoseConsumer) handleAccountEvent(ctx context.Context, evt *co\n }\n \n func (gfc *GoatFirehoseConsumer) handleSyncEvent(ctx context.Context, evt *comatproto.SyncSubscribeRepos_Sync) error {\n-\tcommit, err := repo.LoadCARCommit(ctx, bytes.NewReader(evt.Blocks))\n+\tcommit, _, err := repo.LoadCommitFromCAR(ctx, bytes.NewReader(evt.Blocks))\n \tif err != nil {\n \t\treturn err\n \t}\n@@ -296,7 +296,7 @@ func (gfc *GoatFirehoseConsumer) handleCommitEvent(ctx context.Context, evt *com\n \t\t\treturn err\n \t\t}\n \n-\t\tcommit, err := repo.LoadCARCommit(ctx, bytes.NewReader(evt.Blocks))\n+\t\tcommit, _, err := repo.LoadCommitFromCAR(ctx, bytes.NewReader(evt.Blocks))\n \t\tif err != nil {\n \t\t\treturn err\n \t\t}\n@@ -409,7 +409,7 @@ func (gfc *GoatFirehoseConsumer) handleCommitEventOps(ctx context.Context, evt *\n \t\treturn nil\n \t}\n \n-\t_, rr, err := repo.LoadFromCAR(ctx, bytes.NewReader(evt.Blocks))\n+\t_, rr, err := repo.LoadRepoFromCAR(ctx, bytes.NewReader(evt.Blocks))\n \tif err != nil {\n \t\tlogger.Error(\"failed to read repo from car\", \"err\", err)\n \t\treturn nil\n---\ncmd/goat/repo.go\n@@ -184,7 +184,7 @@ func runRepoList(cctx *cli.Context) error {\n \t}\n \n \t// read repository tree in to memory\n-\t_, r, err := repo.LoadFromCAR(ctx, fi)\n+\t_, r, err := repo.LoadRepoFromCAR(ctx, fi)\n \tif err != nil {\n \t\treturn fmt.Errorf(\"failed to parse repo CAR file: %w\", err)\n \t}\n@@ -211,7 +211,7 @@ func runRepoInspect(cctx *cli.Context) error {\n \t}\n \n \t// read repository tree in to memory\n-\tc, _, err := repo.LoadFromCAR(ctx, fi)\n+\tc, _, err := repo.LoadRepoFromCAR(ctx, fi)\n \tif err != nil {\n \t\treturn err\n \t}\n@@ -255,7 +255,7 @@ func runRepoUnpack(cctx *cli.Context) error {\n \t\treturn err\n \t}\n \n-\tc, r, err := repo.LoadFromCAR(ctx, fi)\n+\tc, r, err := repo.LoadRepoFromCAR(ctx, fi)\n \tif err != nil {\n \t\treturn err\n \t}\n---\ncmd/relay/bgs/validator.go\n@@ -174,7 +174,7 @@ func (val *Validator) VerifyCommitMessage(ctx context.Context, host *models.PDS,\n \t\thasWarning = true\n \t}\n \n-\tcommit, repoFragment, err := atrepo.LoadFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n+\tcommit, repoFragment, err := atrepo.LoadRepoFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n \tif err != nil {\n \t\tcommitVerifyErrors.WithLabelValues(hostname, \"car\").Inc()\n \t\treturn nil, err\n@@ -326,7 +326,7 @@ func (val *Validator) HandleSync(ctx context.Context, host *models.PDS, msg *atp\n \t\treturn nil, err\n \t}\n \n-\tcommit, err := atrepo.LoadCARCommit(ctx, bytes.NewReader([]byte(msg.Blocks)))\n+\tcommit, _, err := atrepo.LoadCommitFromCAR(ctx, bytes.NewReader([]byte(msg.Blocks)))\n \tif err != nil {\n \t\tcommitVerifyErrors.WithLabelValues(hostname, \"car\").Inc()\n \t\treturn nil, err\n---\n"}], "ideal": "Title: rename `atproto/repo` CAR loading function names\n\nBody: This only touches code I am developing, so will probably self-merge"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "did/doc.go\n@@ -0,0 +1,2 @@\n+// Deprecated: use github.com/bluesky-social/indigo/atproto/identity for new projects\n+package did\n---\nhandles/doc.go\n@@ -0,0 +1,2 @@\n+// Deprecated: use github.com/bluesky-social/indigo/atproto/identity for new projects\n+package handles\n---\nplc/doc.go\n@@ -0,0 +1,2 @@\n+// Deprecated: use github.com/bluesky-social/indigo/atproto/identity for new projects\n+package plc\n---\n"}], "ideal": "Title: docs.go for did, handles, plc\n\nBody: Forgot to commit this files in an earlier cleanup PR."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/engine/engine_ozone.go\n@@ -46,6 +46,8 @@ func NewOzoneEventContext(ctx context.Context, eng *Engine, eventView *toolsozon\n \t\teventType = \"divert\"\n \t} else if eventView.Event.ModerationDefs_ModEventTag != nil {\n \t\teventType = \"tag\"\n+\t} else if eventView.Event.ModerationDefs_ModEventPriorityScore != nil {\n+\t\teventType = \"priorityScore\"\n \t} else {\n \t\treturn nil, fmt.Errorf(\"unhandled ozone event type\")\n \t}\n---\n"}], "ideal": "Title: automod: have ozone engine handle newer event types\n\nBody: We don't actually have any rules or behavior around this event type, just need to handle it here to reduce false-positive error logging.\r\n\r\nWill need to be paired with an update and deploy in another internal repo, after this is merged."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "go.mod\n@@ -1,6 +1,7 @@\n module github.com/bluesky-social/indigo\n \n go 1.23\n+toolchain go1.23.8\n \n require (\n \tcontrib.go.opencensus.io/exporter/prometheus v0.4.2\n---\n"}], "ideal": "Title: go.mod: specify full version (1.23.0)\n\nBody: For the automatic go toolchain stuff to work, we need the full version, including patch (not just minor)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/identity.go\n@@ -76,7 +76,7 @@ func ParseIdentity(doc *DIDDocument) Identity {\n \t}\n \treturn Identity{\n \t\tDID:         doc.DID,\n-\t\tHandle:      syntax.Handle(\"invalid.handle\"),\n+\t\tHandle:      syntax.HandleInvalid,\n \t\tAlsoKnownAs: doc.AlsoKnownAs,\n \t\tServices:    svc,\n \t\tKeys:        keys,\n---\natproto/syntax/handle.go\n@@ -59,7 +59,7 @@ func (h Handle) TLD() string {\n \n // Is this the special \"handle.invalid\" handle?\n func (h Handle) IsInvalidHandle() bool {\n-\treturn h.Normalize() == \"handle.invalid\"\n+\treturn h.Normalize() == HandleInvalid\n }\n \n func (h Handle) Normalize() Handle {\n---\ncmd/bluepages/handlers.go\n@@ -154,12 +154,12 @@ func (srv *Server) resolveIdentityFromDID(c echo.Context, did syntax.DID) error\n \thandle, err := ident.DeclaredHandle()\n \tif err != nil {\n \t\t// no handle declared, or invalid syntax\n-\t\thandle = syntax.Handle(\"handle.invalid\")\n+\t\thandle = syntax.HandleInvalid\n \t}\n \n \tcheckDID, err := srv.dir.ResolveHandle(ctx, handle)\n \tif err != nil || checkDID != did {\n-\t\thandle = syntax.Handle(\"handle.invalid\")\n+\t\thandle = syntax.HandleInvalid\n \t}\n \n \treturn c.JSON(200, comatproto.IdentityDefs_IdentityInfo{\n---\n"}], "ideal": "Title: use syntax.HandleInvalid instead of string (fix typo)\n\nBody: This fixes a specific typo, and also uses the declared const in more places (to avoid similar typos).\r\n\r\nthanks @rafaelbsky for reporting!"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/indexing.go\n@@ -480,7 +480,7 @@ func (idx *Indexer) indexProfiles(ctx context.Context, jobs []*ProfileIndexJob)\n \treturn nil\n }\n \n-// updateProfilePagranks uses the OpenSearch bulk API to update the pageranks for the given DIDs\n+// indexPageranks uses the OpenSearch bulk API to update the pageranks for the given DIDs\n func (idx *Indexer) indexPageranks(ctx context.Context, pageranks []*PagerankIndexJob) error {\n \tctx, span := tracer.Start(ctx, \"indexPageranks\")\n \tdefer span.End()\n---\nsearch/parse_query.go\n@@ -10,7 +10,7 @@ import (\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n )\n \n-// ParseQuery takes a query string and pulls out some facet patterns (\"from:handle.net\") as filters\n+// ParsePostQuery takes a query string and pulls out some facet patterns (\"from:handle.net\") as filters\n func ParsePostQuery(ctx context.Context, dir identity.Directory, raw string, viewer *syntax.DID) PostSearchParams {\n \tquoted := false\n \tparts := strings.FieldsFunc(raw, func(r rune) bool {\n---\n"}], "ideal": "Title: chore: make function comment match function name\n\nBody:  make function comment match function name"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "splitter/splitter.go\n@@ -75,6 +75,22 @@ func (sc *SplitterConfig) XrpcRootUrl() string {\n \treturn \"https://\" + sc.UpstreamHost\n }\n \n+func (sc *SplitterConfig) UpstreamUrl() string {\n+\tif strings.HasPrefix(sc.UpstreamHost, \"ws://\") {\n+\t\treturn \"http://\" + sc.UpstreamHost[7:]\n+\t}\n+\tif strings.HasPrefix(sc.UpstreamHost, \"wss://\") {\n+\t\treturn \"https://\" + sc.UpstreamHost[8:]\n+\t}\n+\tif strings.HasPrefix(sc.UpstreamHost, \"ws://\") {\n+\t\treturn sc.UpstreamHost\n+\t}\n+\tif strings.HasPrefix(sc.UpstreamHost, \"wss://\") {\n+\t\treturn sc.UpstreamHost\n+\t}\n+\treturn \"wss://\" + sc.UpstreamHost\n+}\n+\n func NewSplitter(conf SplitterConfig, nextCrawlers []string) (*Splitter, error) {\n \tvar nextCrawlerURLs []*url.URL\n \tlog := slog.Default().With(\"system\", \"splitter\")\n@@ -90,6 +106,11 @@ func NewSplitter(conf SplitterConfig, nextCrawlers []string) (*Splitter, error)\n \t\t}\n \t}\n \n+\t_, err := url.Parse(conf.UpstreamUrl())\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to parse upstream url %#v: %w\", conf.UpstreamUrl(), err)\n+\t}\n+\n \ts := &Splitter{\n \t\tconf:         conf,\n \t\tconsumers:    make(map[uint64]*SocketConsumer),\n@@ -153,7 +174,7 @@ func (s *Splitter) Start(addr string) error {\n \t\treturn fmt.Errorf(\"loading cursor failed: %w\", err)\n \t}\n \n-\tgo s.subscribeWithRedialer(context.Background(), s.conf.UpstreamHost, curs)\n+\tgo s.subscribeWithRedialer(context.Background(), curs)\n \n \tli, err := lc.Listen(ctx, \"tcp\", addr)\n \tif err != nil {\n@@ -570,10 +591,14 @@ func sleepForBackoff(b int) time.Duration {\n \treturn time.Second * 5\n }\n \n-func (s *Splitter) subscribeWithRedialer(ctx context.Context, host string, cursor int64) {\n+func (s *Splitter) subscribeWithRedialer(ctx context.Context, cursor int64) {\n \td := websocket.Dialer{}\n \n-\tprotocol := \"wss\"\n+\tupstreamUrl, err := url.Parse(s.conf.UpstreamUrl())\n+\tif err != nil {\n+\t\tpanic(err) // this should have been checked in NewSplitter\n+\t}\n+\tupstreamUrl = upstreamUrl.JoinPath(\"/xrpc/com.atproto.sync.subscribeRepos\")\n \n \tvar backoff int\n \tfor {\n@@ -587,15 +612,17 @@ func (s *Splitter) subscribeWithRedialer(ctx context.Context, host string, curso\n \t\t\t\"User-Agent\": []string{\"bgs-rainbow-v0\"},\n \t\t}\n \n-\t\tvar url string\n+\t\tvar uurl string\n \t\tif cursor < 0 {\n-\t\t\turl = fmt.Sprintf(\"%s://%s/xrpc/com.atproto.sync.subscribeRepos\", protocol, host)\n+\t\t\tupstreamUrl.RawQuery = \"\"\n+\t\t\tuurl = upstreamUrl.String()\n \t\t} else {\n-\t\t\turl = fmt.Sprintf(\"%s://%s/xrpc/com.atproto.sync.subscribeRepos?cursor=%d\", protocol, host, cursor)\n+\t\t\tupstreamUrl.RawQuery = fmt.Sprintf(\"cursor=%d\", cursor)\n+\t\t\tuurl = upstreamUrl.String()\n \t\t}\n-\t\tcon, res, err := d.DialContext(ctx, url, header)\n+\t\tcon, res, err := d.DialContext(ctx, uurl, header)\n \t\tif err != nil {\n-\t\t\ts.log.Warn(\"dialing failed\", \"host\", host, \"err\", err, \"backoff\", backoff)\n+\t\t\ts.log.Warn(\"dialing failed\", \"url\", uurl, \"err\", err, \"backoff\", backoff)\n \t\t\ttime.Sleep(sleepForBackoff(backoff))\n \t\t\tbackoff++\n \n@@ -604,13 +631,13 @@ func (s *Splitter) subscribeWithRedialer(ctx context.Context, host string, curso\n \n \t\ts.log.Info(\"event subscription response\", \"code\", res.StatusCode)\n \n-\t\tif err := s.handleConnection(ctx, host, con, &cursor); err != nil {\n-\t\t\ts.log.Warn(\"connection failed\", \"host\", host, \"err\", err)\n+\t\tif err := s.handleConnection(ctx, con, &cursor); err != nil {\n+\t\t\ts.log.Warn(\"connection failed\", \"url\", uurl, \"err\", err)\n \t\t}\n \t}\n }\n \n-func (s *Splitter) handleConnection(ctx context.Context, host string, con *websocket.Conn, lastCursor *int64) error {\n+func (s *Splitter) handleConnection(ctx context.Context, con *websocket.Conn, lastCursor *int64) error {\n \tctx, cancel := context.WithCancel(ctx)\n \tdefer cancel()\n \n---\n"}], "ideal": "Title: cleanup rainbow upstream url handling\n\nBody: --splitter-host should work for any http/https/ws/wss url"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/repo/mst/node.go\n@@ -291,6 +291,25 @@ func (n *Node) writeToMap(m map[string]cid.Cid) error {\n \treturn nil\n }\n \n+func (n *Node) walk(f func(key []byte, val cid.Cid) error) error {\n+\tif n == nil {\n+\t\treturn fmt.Errorf(\"nil tree pointer\")\n+\t}\n+\tfor _, e := range n.Entries {\n+\t\tif e.IsValue() {\n+\t\t\tif err := f(e.Key, *e.Value); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t}\n+\t\tif e.Child != nil {\n+\t\t\tif err := e.Child.walk(f); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\t\t}\n+\t}\n+\treturn nil\n+}\n+\n // Reads the value (CID) corresponding to the key. If key is not in the tree, returns (nil, nil).\n //\n // n: Node at top of sub-tree to operate on. Must not be nil.\n---\natproto/repo/mst/tree.go\n@@ -79,6 +79,11 @@ func (t *Tree) Get(key []byte) (*cid.Cid, error) {\n \treturn t.Root.getCID(key, -1)\n }\n \n+// Walks the Tree, invoking the callback function on each key/value pair.\n+func (t *Tree) Walk(f func(key []byte, val cid.Cid) error) error {\n+\treturn t.Root.walk(f)\n+}\n+\n // Creates a new Tree by loading key/value pairs from a map.\n func LoadTreeFromMap(m map[string]cid.Cid) (*Tree, error) {\n \tif m == nil {\n---\natproto/repo/repo.go\n@@ -48,17 +48,17 @@ func (repo *Repo) GetRecordCID(ctx context.Context, collection syntax.NSID, rkey\n \treturn c, nil\n }\n \n-func (repo *Repo) GetRecordBytes(ctx context.Context, collection syntax.NSID, rkey syntax.RecordKey) ([]byte, error) {\n+func (repo *Repo) GetRecordBytes(ctx context.Context, collection syntax.NSID, rkey syntax.RecordKey) ([]byte, *cid.Cid, error) {\n \tc, err := repo.GetRecordCID(ctx, collection, rkey)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn nil, nil, err\n \t}\n \tblk, err := repo.RecordStore.Get(ctx, *c)\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn nil, nil, err\n \t}\n \t// TODO: not verifying CID\n-\treturn blk.RawData(), nil\n+\treturn blk.RawData(), c, nil\n }\n \n // Snapshots the current state of the repository, resulting in a new (unsigned) `Commit` struct.\n---\natproto/repo/sync.go\n@@ -61,17 +61,14 @@ func VerifyCommitMessage(ctx context.Context, msg *comatproto.SyncSubscribeRepos\n \t\t\tif err != nil {\n \t\t\t\treturn nil, fmt.Errorf(\"invalid repo path in ops list: %w\", err)\n \t\t\t}\n-\t\t\tval, err := repo.GetRecordCID(ctx, nsid, rkey)\n+\t\t\t// don't use the returned bytes, but do actually read them out of store (not just CID)\n+\t\t\t_, val, err := repo.GetRecordBytes(ctx, nsid, rkey)\n \t\t\tif err != nil {\n \t\t\t\treturn nil, err\n \t\t\t}\n \t\t\tif *c != *val {\n \t\t\t\treturn nil, fmt.Errorf(\"record op doesn't match MST tree value\")\n \t\t\t}\n-\t\t\t_, err = repo.GetRecordBytes(ctx, nsid, rkey)\n-\t\t\tif err != nil {\n-\t\t\t\treturn nil, err\n-\t\t\t}\n \t\t}\n \t}\n \n---\n"}], "ideal": "Title: MST walk, and repo tweak\n\nBody: Adds a `Walk` method to `Tree` for visiting all key/value in the MST.\r\n\r\nAlso updates `GetRecordBytes` to return the CID, along with actual bytes. It needs to be looked up from the MST anyways, and this results in one less call/lookup in some cases. Code which doesn't need the CID can just ignore that return type."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "mst/diff.go\n@@ -6,7 +6,7 @@ import (\n \n \t\"github.com/bluesky-social/indigo/util\"\n \tcid \"github.com/ipfs/go-cid\"\n-\tblockstore \"github.com/ipfs/go-ipfs-blockstore\"\n+\tcbor \"github.com/ipfs/go-ipld-cbor\"\n )\n \n type DiffOp struct {\n@@ -18,7 +18,7 @@ type DiffOp struct {\n }\n \n // TODO: this code isn't great, should be rewritten on top of the baseline datastructures once functional and correct\n-func DiffTrees(ctx context.Context, bs blockstore.Blockstore, from, to cid.Cid) ([]*DiffOp, error) {\n+func DiffTrees(ctx context.Context, bs cbor.IpldBlockstore, from, to cid.Cid) ([]*DiffOp, error) {\n \tcst := util.CborStore(bs)\n \n \tif from == cid.Undef {\n@@ -185,7 +185,7 @@ func nodeEntriesEqual(a, b *nodeEntry) bool {\n \treturn false\n }\n \n-func identityDiff(ctx context.Context, bs blockstore.Blockstore, root cid.Cid) ([]*DiffOp, error) {\n+func identityDiff(ctx context.Context, bs cbor.IpldBlockstore, root cid.Cid) ([]*DiffOp, error) {\n \tcst := util.CborStore(bs)\n \ttt := LoadMST(cst, root)\n \n---\nrepo/repo.go\n@@ -43,7 +43,7 @@ type UnsignedCommit struct {\n type Repo struct {\n \tsc  SignedCommit\n \tcst cbor.IpldStore\n-\tbs  blockstore.Blockstore\n+\tbs  cbor.IpldBlockstore\n \n \trepoCid cid.Cid\n \n@@ -74,7 +74,7 @@ func (uc *UnsignedCommit) BytesForSigning() ([]byte, error) {\n \treturn buf.Bytes(), nil\n }\n \n-func IngestRepo(ctx context.Context, bs blockstore.Blockstore, r io.Reader) (cid.Cid, error) {\n+func IngestRepo(ctx context.Context, bs cbor.IpldBlockstore, r io.Reader) (cid.Cid, error) {\n \tctx, span := otel.Tracer(\"repo\").Start(ctx, \"Ingest\")\n \tdefer span.End()\n \n@@ -110,7 +110,7 @@ func ReadRepoFromCar(ctx context.Context, r io.Reader) (*Repo, error) {\n \treturn OpenRepo(ctx, bs, root)\n }\n \n-func NewRepo(ctx context.Context, did string, bs blockstore.Blockstore) *Repo {\n+func NewRepo(ctx context.Context, did string, bs cbor.IpldBlockstore) *Repo {\n \tcst := util.CborStore(bs)\n \n \tt := mst.NewEmptyMST(cst)\n@@ -128,7 +128,7 @@ func NewRepo(ctx context.Context, did string, bs blockstore.Blockstore) *Repo {\n \t}\n }\n \n-func OpenRepo(ctx context.Context, bs blockstore.Blockstore, root cid.Cid) (*Repo, error) {\n+func OpenRepo(ctx context.Context, bs cbor.IpldBlockstore, root cid.Cid) (*Repo, error) {\n \tcst := util.CborStore(bs)\n \n \tvar sc SignedCommit\n@@ -173,7 +173,7 @@ func (r *Repo) SignedCommit() SignedCommit {\n \treturn r.sc\n }\n \n-func (r *Repo) Blockstore() blockstore.Blockstore {\n+func (r *Repo) Blockstore() cbor.IpldBlockstore {\n \treturn r.bs\n }\n \n@@ -435,11 +435,11 @@ func (r *Repo) DiffSince(ctx context.Context, oldrepo cid.Cid) ([]*mst.DiffOp, e\n \treturn mst.DiffTrees(ctx, r.bs, oldTree, curptr)\n }\n \n-func (r *Repo) CopyDataTo(ctx context.Context, bs blockstore.Blockstore) error {\n+func (r *Repo) CopyDataTo(ctx context.Context, bs cbor.IpldBlockstore) error {\n \treturn copyRecCbor(ctx, r.bs, bs, r.sc.Data, make(map[cid.Cid]struct{}))\n }\n \n-func copyRecCbor(ctx context.Context, from, to blockstore.Blockstore, c cid.Cid, seen map[cid.Cid]struct{}) error {\n+func copyRecCbor(ctx context.Context, from, to cbor.IpldBlockstore, c cid.Cid, seen map[cid.Cid]struct{}) error {\n \tif _, ok := seen[c]; ok {\n \t\treturn nil\n \t}\n---\nutil/cbor.go\n@@ -1,12 +1,11 @@\n package util\n \n import (\n-\tblockstore \"github.com/ipfs/go-ipfs-blockstore\"\n \tcbor \"github.com/ipfs/go-ipld-cbor\"\n \tmh \"github.com/multiformats/go-multihash\"\n )\n \n-func CborStore(bs blockstore.Blockstore) *cbor.BasicIpldStore {\n+func CborStore(bs cbor.IpldBlockstore) *cbor.BasicIpldStore {\n \tcst := cbor.NewCborStore(bs)\n \tcst.DefaultMultihash = mh.SHA2_256\n \treturn cst\n---\n"}], "ideal": "Title: use ipld cbor Blockstore interface\n\nBody: We already used the ipld-cbor Blockstore interface in a few places, and it's a simpler smaller interface that does all we need and isn't deprecated; spread its usage around a bit to simplify some things I was working on elsewhere in relay code"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/beemo/Dockerfile\n@@ -17,7 +17,7 @@ RUN GIT_VERSION=$(git describe --tags --long --always) && \\\n ### Run stage\n FROM alpine:3.20\n \n-RUN apk add --no-cache --update dumb-init ca-certificates\n+RUN apk add --no-cache --update dumb-init ca-certificates runit\n ENTRYPOINT [\"dumb-init\", \"--\"]\n \n WORKDIR /\n---\ncmd/hepa/Dockerfile\n@@ -17,7 +17,7 @@ RUN GIT_VERSION=$(git describe --tags --long --always) && \\\n ### Run stage\n FROM alpine:3.20\n \n-RUN apk add --no-cache --update dumb-init ca-certificates\n+RUN apk add --no-cache --update dumb-init ca-certificates runit\n ENTRYPOINT [\"dumb-init\", \"--\"]\n \n WORKDIR /\n---\ncmd/palomar/Dockerfile\n@@ -17,7 +17,7 @@ RUN GIT_VERSION=$(git describe --tags --long --always) && \\\n ### Run stage\n FROM alpine:3.20\n \n-RUN apk add --no-cache --update dumb-init ca-certificates\n+RUN apk add --no-cache --update dumb-init ca-certificates runit\n ENTRYPOINT [\"dumb-init\", \"--\"]\n \n WORKDIR /\n---\n"}], "ideal": "Title: add runit to Dockerfiles (for consistency)\n\nBody: In production we use `svlogd` as part of our docker CMD. This is provided by the `runit` package."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "splitter/splitter.go\n@@ -395,6 +395,8 @@ func (s *Splitter) EventsHandler(c echo.Context) error {\n \t\treturn fmt.Errorf(\"upgrading websocket: %w\", err)\n \t}\n \n+\tdefer conn.Close()\n+\n \tlastWriteLk := sync.Mutex{}\n \tlastWrite := time.Now()\n \n---\n"}], "ideal": "Title: added missing connection close in splitter\n\nBody: I've been trying to track down an issue where in my firehose client (in Ruby) the websocket connection sometimes gets stuck, meaning that at some point events stop flowing, but the connection doesn't disconnect, so the client doesn't notice immediately that something is wrong. I've eventually added a \"heartbeat\" feature to my library Skyfall, where it has a timer that checks the time since the last event, and forces a reconnect if there haven't been any events for a while. This has been happening very occasionally until autumn last year, but started getting much more common since November. I worked around this by making the timer limits much lower.\r\n\r\nBut I started digging into this, and I got the feeling that the problem must be in the server's code, not on my side. I can trigger this consistently almost every time, when I start catching up from a bit more behind, like a few hours behind.\r\n\r\nSo I looked through the indigo code, ended up setting a test relay/splitter on a spare VPS, and I finally tracked this down to\u2026 one missing line that disconnects the connection :) It looks like `bgs.go` and `splitter.go` share a lot of the code, and specifically the beginning of this `EventsHandler` method is identical, except this one line (https://github.com/bluesky-social/indigo/blob/main/bgs/bgs.go#L548) that somehow got lost on the way.\r\n\r\nWithout this line, when the `EventManager` in `events.go` kills the consumer, it's removed from all the lists and the server forgets about it, but the connection itself is not disconnected, so the client is left hanging there, not knowing what's going on.\r\n\r\nThis is related to a second issue I'll file a separate ticket for, which is that with the right conditions (which aren't hard to meet), a catching up consumer gets dropped in this in-between phase when catching up what was added in the meantime, before switching to the live stream. So with this fix, the consumer will at least be disconnected immediately, which is better because then you aren't wasting time and falling behind again while being stuck.\r\n\r\nEDIT: issue added here https://github.com/bluesky-social/indigo/pull/975"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": ".gitignore\n@@ -26,7 +26,6 @@ test-coverage.out\n /bigsky\n /fakermaker\n /gosky\n-/laputa\n /lexgen\n /palomar\n /sonar-cli\n---\nHACKING.md\n@@ -7,7 +7,6 @@ Run with, eg, `go run ./cmd/bigsky`):\n - `cmd/palomar`: search indexer and query servcie (OpenSearch)\n - `cmd/gosky`: client CLI for talking to a PDS\n - `cmd/lexgen`: codegen tool for lexicons (Lexicon JSON to Go package)\n-- `cmd/laputa`: partial PDS daemon (not usable or under development)\n - `cmd/stress`: connects to local/default PDS and creates a ton of random posts\n - `cmd/beemo`: slack bot for moderation reporting (Bluesky Moderation Observer)\n - `cmd/fakermaker`: helper to generate fake accounts and content for testing\n---\nMakefile\n@@ -17,7 +17,6 @@ help: ## Print info about all commands\n .PHONY: build\n build: ## Build all executables\n \tgo build ./cmd/gosky\n-\tgo build ./cmd/laputa\n \tgo build ./cmd/bigsky\n \tgo build ./cmd/beemo\n \tgo build ./cmd/lexgen\n---\ncmd/fakermaker/README.md\n@@ -9,13 +9,6 @@ Configure a `.env` file for use against `atproto` Typescript PDS implementation\n \tATP_AUTH_PASSWORD=\"admin\"\n \tATP_AUTH_ADMIN_PASSWORD=\"admin\"\n \n-or, against `laputa` golang PDS implementation (in this repo; already running\n-locally):\n-\n-\tATP_PDS_HOST=http://localhost:4989\n-\tATP_AUTH_HANDLE=\"admin.test\"\n-\tATP_AUTH_PASSWORD=\"admin\"\n-\tATP_AUTH_ADMIN_PASSWORD=\"admin\"\n \n Then, from the top-level directory, run test commands:\n \n---\ncmd/laputa/main.go\n@@ -1,201 +0,0 @@\n-package main\n-\n-import (\n-\t\"os\"\n-\t\"path/filepath\"\n-\n-\t\"github.com/bluesky-social/indigo/api\"\n-\t\"github.com/bluesky-social/indigo/carstore\"\n-\t\"github.com/bluesky-social/indigo/pds\"\n-\t\"github.com/bluesky-social/indigo/plc\"\n-\t\"github.com/bluesky-social/indigo/util/cliutil\"\n-\n-\t_ \"github.com/joho/godotenv/autoload\"\n-\t_ \"go.uber.org/automaxprocs\"\n-\n-\t\"github.com/carlmjohnson/versioninfo\"\n-\t\"github.com/urfave/cli/v2\"\n-\t\"go.opentelemetry.io/otel\"\n-\t\"go.opentelemetry.io/otel/attribute\"\n-\t\"go.opentelemetry.io/otel/exporters/jaeger\"\n-\t\"go.opentelemetry.io/otel/sdk/resource\"\n-\ttracesdk \"go.opentelemetry.io/otel/sdk/trace\"\n-\tsemconv \"go.opentelemetry.io/otel/semconv/v1.4.0\"\n-\t\"gorm.io/plugin/opentelemetry/tracing\"\n-)\n-\n-func main() {\n-\trun(os.Args)\n-}\n-\n-func run(args []string) {\n-\n-\tapp := cli.App{\n-\t\tName:    \"laputa\",\n-\t\tUsage:   \"bluesky PDS in golang\",\n-\t\tVersion: versioninfo.Short(),\n-\t}\n-\n-\tapp.Flags = []cli.Flag{\n-\t\t&cli.BoolFlag{\n-\t\t\tName: \"jaeger\",\n-\t\t},\n-\t\t&cli.StringFlag{\n-\t\t\tName:    \"db-url\",\n-\t\t\tValue:   \"sqlite://./data/laputa/pds.sqlite\",\n-\t\t\tEnvVars: []string{\"DATABASE_URL\"},\n-\t\t},\n-\t\t&cli.StringFlag{\n-\t\t\tName:    \"carstore-db-url\",\n-\t\t\tValue:   \"sqlite://./data/laputa/carstore.sqlite\",\n-\t\t\tEnvVars: []string{\"CARSTORE_DATABASE_URL\"},\n-\t\t},\n-\t\t&cli.BoolFlag{\n-\t\t\tName: \"db-tracing\",\n-\t\t},\n-\t\t&cli.StringFlag{\n-\t\t\tName:  \"name\",\n-\t\t\tUsage: \"hostname of this PDS instance\",\n-\t\t\tValue: \"localhost:4989\",\n-\t\t},\n-\t\t&cli.StringFlag{\n-\t\t\tName:    \"plc-host\",\n-\t\t\tUsage:   \"method, hostname, and port of PLC registry\",\n-\t\t\tValue:   \"https://plc.directory\",\n-\t\t\tEnvVars: []string{\"ATP_PLC_HOST\"},\n-\t\t},\n-\t\t&cli.StringFlag{\n-\t\t\tName:    \"data-dir\",\n-\t\t\tUsage:   \"path of directory for CAR files and other data\",\n-\t\t\tValue:   \"data/laputa\",\n-\t\t\tEnvVars: []string{\"DATA_DIR\"},\n-\t\t},\n-\t\t&cli.StringFlag{\n-\t\t\tName:    \"jwt-secret\",\n-\t\t\tUsage:   \"secret used for authenticating JWT tokens\",\n-\t\t\tValue:   \"jwtsecretplaceholder\",\n-\t\t\tEnvVars: []string{\"ATP_JWT_SECRET\"},\n-\t\t},\n-\t\t&cli.StringFlag{\n-\t\t\tName:    \"handle-domains\",\n-\t\t\tUsage:   \"comma-separated list of domain suffixes for handle registration\",\n-\t\t\tValue:   \".test\",\n-\t\t\tEnvVars: []string{\"ATP_PDS_HANDLE_DOMAINS\"},\n-\t\t},\n-\t\t&cli.IntFlag{\n-\t\t\tName:    \"max-carstore-connections\",\n-\t\t\tEnvVars: []string{\"MAX_CARSTORE_CONNECTIONS\"},\n-\t\t\tValue:   40,\n-\t\t},\n-\t\t&cli.IntFlag{\n-\t\t\tName:    \"max-metadb-connections\",\n-\t\t\tEnvVars: []string{\"MAX_METADB_CONNECTIONS\"},\n-\t\t\tValue:   40,\n-\t\t},\n-\t}\n-\n-\tapp.Commands = []*cli.Command{\n-\t\tgenerateKeyCmd,\n-\t}\n-\n-\tapp.Action = func(cctx *cli.Context) error {\n-\n-\t\tif cctx.Bool(\"jaeger\") {\n-\t\t\turl := \"http://localhost:14268/api/traces\"\n-\t\t\texp, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(url)))\n-\t\t\tif err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t\ttp := tracesdk.NewTracerProvider(\n-\t\t\t\t// Always be sure to batch in production.\n-\t\t\t\ttracesdk.WithBatcher(exp),\n-\t\t\t\t// Record information about this application in a Resource.\n-\t\t\t\ttracesdk.WithResource(resource.NewWithAttributes(\n-\t\t\t\t\tsemconv.SchemaURL,\n-\t\t\t\t\tsemconv.ServiceNameKey.String(\"pds\"),\n-\t\t\t\t\tattribute.String(\"environment\", \"test\"),\n-\t\t\t\t\tattribute.Int64(\"ID\", 1),\n-\t\t\t\t)),\n-\t\t\t)\n-\n-\t\t\totel.SetTracerProvider(tp)\n-\t\t}\n-\n-\t\tdbtracing := cctx.Bool(\"db-tracing\")\n-\t\tdatadir := cctx.String(\"data-dir\")\n-\t\tcsdir := filepath.Join(datadir, \"carstore\")\n-\t\tkeypath := filepath.Join(datadir, \"server.key\")\n-\t\tjwtsecret := []byte(cctx.String(\"jwt-secret\"))\n-\n-\t\t// TODO(bnewbold): split this on comma, and have PDS support multiple\n-\t\t// domain suffixes that can be registered\n-\t\tpdsdomain := cctx.String(\"handle-domains\")\n-\n-\t\t// ensure data directories exist; won't error if it does\n-\t\tos.MkdirAll(csdir, os.ModePerm)\n-\n-\t\t// default postgres setup: postgresql://postgres:password@localhost:5432/pdsdb?sslmode=disable\n-\t\tdb, err := cliutil.SetupDatabase(cctx.String(\"db-url\"), cctx.Int(\"max-metadb-connections\"))\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\n-\t\t// default postgres setup: postgresql://postgres:password@localhost:5432/cardb?sslmode=disable\n-\t\tcsdb, err := cliutil.SetupDatabase(cctx.String(\"carstore-db-url\"), cctx.Int(\"max-carstore-connections\"))\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\n-\t\tif dbtracing {\n-\t\t\tif err := db.Use(tracing.NewPlugin()); err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t\tif err := csdb.Use(tracing.NewPlugin()); err != nil {\n-\t\t\t\treturn err\n-\t\t\t}\n-\t\t}\n-\n-\t\tcstore, err := carstore.NewCarStore(csdb, []string{csdir})\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\n-\t\tvar didr plc.PLCClient\n-\t\tif plchost := cctx.String(\"plc-host\"); plchost != \"\" {\n-\t\t\tdidr = &api.PLCServer{Host: plchost}\n-\t\t} else {\n-\t\t\tdidr = plc.NewFakeDid(db)\n-\t\t}\n-\n-\t\tpdshost := cctx.String(\"name\")\n-\n-\t\tkey, err := cliutil.LoadKeyFromFile(keypath)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\n-\t\tsrv, err := pds.NewServer(db, cstore, key, pdsdomain, pdshost, didr, jwtsecret)\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\n-\t\treturn srv.RunAPI(\":4989\")\n-\t}\n-\n-\tapp.RunAndExitOnError()\n-}\n-\n-var generateKeyCmd = &cli.Command{\n-\tName: \"gen-key\",\n-\tFlags: []cli.Flag{\n-\t\t&cli.StringFlag{\n-\t\t\tName:    \"output\",\n-\t\t\tAliases: []string{\"o\"},\n-\t\t\tValue:   \"data/laputa/server.key\",\n-\t\t},\n-\t},\n-\tAction: func(cctx *cli.Context) error {\n-\t\tfname := cctx.String(\"output\")\n-\t\treturn cliutil.GenerateKeyToFile(fname)\n-\t},\n-}\n---\ntesting/testscripts/cleanup.sh\n@@ -1,3 +0,0 @@\n-#!/bin/bash\n-rm -rf data/laputa/\n-mkdir -p data/laputa/carstore\n---\n"}], "ideal": "Title: remove `./cmd/laputa`\n\nBody: This was a partial/prototype PDS implementation in golang. Some of that code is still partially used in internal tests, but is very far out of data from the atproto spec.\r\n\r\nThis removes the command which references that library code. Can always pull this back out of git history if we need it."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/sonar/main.go\n@@ -15,7 +15,6 @@ import (\n \n \t\"github.com/bluesky-social/indigo/events\"\n \t\"github.com/bluesky-social/indigo/events/schedulers/sequential\"\n-\t\"github.com/bluesky-social/indigo/sonar\"\n \t\"github.com/gorilla/websocket\"\n \t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n \t_ \"go.uber.org/automaxprocs\"\n@@ -63,15 +62,15 @@ func main() {\n \t\t},\n \t}\n \n-\tapp.Action = Sonar\n+\tapp.Action = runSonar\n \n \terr := app.Run(os.Args)\n \tif err != nil {\n \t\tlog.Fatal(err)\n \t}\n }\n \n-func Sonar(cctx *cli.Context) error {\n+func runSonar(cctx *cli.Context) error {\n \tctx := cctx.Context\n \tctx, cancel := context.WithCancel(ctx)\n \tdefer cancel()\n@@ -94,7 +93,7 @@ func Sonar(cctx *cli.Context) error {\n \t\tlog.Fatalf(\"failed to parse ws-url: %+v\", err)\n \t}\n \n-\ts, err := sonar.NewSonar(logger, cctx.String(\"cursor-file\"), u.String())\n+\ts, err := NewSonar(logger, cctx.String(\"cursor-file\"), u.String())\n \tif err != nil {\n \t\tlog.Fatalf(\"failed to create sonar: %+v\", err)\n \t}\n---\ncmd/sonar/metrics.go\n@@ -1,4 +1,4 @@\n-package sonar\n+package main\n \n import (\n \t\"github.com/prometheus/client_golang/prometheus\"\n---\ncmd/sonar/sonar.go\n@@ -1,4 +1,4 @@\n-package sonar\n+package main\n \n import (\n \t\"bytes\"\n---\n"}], "ideal": "Title: move all sonar code in to ./cmd/sonar/\n\nBody: trying to tidy up the large number of top-level directories.\r\n\r\ndon't have super strong feelings on this if you think it should stay as-is."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/fedmgr.go\n@@ -569,6 +569,21 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \n \t\t\treturn nil\n \t\t},\n+\t\tRepoSync: func(evt *comatproto.SyncSubscribeRepos_Sync) error {\n+\t\t\tlog.Info(\"sync event\", \"did\", evt.Did, \"pdsHost\", host.Host, \"seq\", evt.Seq)\n+\t\t\tif err := s.cb(context.TODO(), host, &events.XRPCStreamEvent{\n+\t\t\t\tRepoSync: evt,\n+\t\t\t}); err != nil {\n+\t\t\t\tlog.Error(\"failed handling event\", \"host\", host.Host, \"seq\", evt.Seq, \"err\", err)\n+\t\t\t}\n+\t\t\t*lastCursor = evt.Seq\n+\n+\t\t\tif err := s.updateCursor(sub, *lastCursor); err != nil {\n+\t\t\t\treturn fmt.Errorf(\"updating cursor: %w\", err)\n+\t\t\t}\n+\n+\t\t\treturn nil\n+\t\t},\n \t\tRepoInfo: func(info *comatproto.SyncSubscribeRepos_Info) error {\n \t\t\tlog.Info(\"info event\", \"name\", info.Name, \"message\", info.Message, \"pdsHost\", host.Host)\n \t\t\treturn nil\n---\ncmd/gosky/debug.go\n@@ -262,6 +262,14 @@ var debugStreamCmd = &cli.Command{\n \n \t\t\t\treturn nil\n \t\t\t},\n+\t\t\tRepoSync: func(evt *comatproto.SyncSubscribeRepos_Sync) error {\n+\t\t\t\tfmt.Printf(\"\\rChecking seq: %d      \", evt.Seq)\n+\t\t\t\tif lastSeq > 0 && evt.Seq != lastSeq+1 {\n+\t\t\t\t\tfmt.Println(\"Gap in sequence numbers: \", lastSeq, evt.Seq)\n+\t\t\t\t}\n+\t\t\t\tlastSeq = evt.Seq\n+\t\t\t\treturn nil\n+\t\t\t},\n \t\t\tRepoInfo: func(evt *comatproto.SyncSubscribeRepos_Info) error {\n \t\t\t\treturn nil\n \t\t\t},\n---\ncmd/gosky/main.go\n@@ -284,6 +284,20 @@ var readRepoStreamCmd = &cli.Command{\n \n \t\t\t\treturn nil\n \t\t\t},\n+\t\t\tRepoSync: func(sync *comatproto.SyncSubscribeRepos_Sync) error {\n+\t\t\t\tif jsonfmt {\n+\t\t\t\t\tb, err := json.Marshal(sync)\n+\t\t\t\t\tif err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\t\t\t\t\tfmt.Println(string(b))\n+\t\t\t\t} else {\n+\t\t\t\t\tfmt.Printf(\"(%d) Sync: %s\\n\", sync.Seq, sync.Did)\n+\t\t\t\t}\n+\n+\t\t\t\treturn nil\n+\n+\t\t\t},\n \t\t\tRepoInfo: func(info *comatproto.SyncSubscribeRepos_Info) error {\n \t\t\t\tif jsonfmt {\n \t\t\t\t\tb, err := json.Marshal(info)\n---\ncmd/gosky/streamdiff.go\n@@ -127,6 +127,8 @@ func evtOp(evt *events.XRPCStreamEvent) string {\n \t\treturn \"ERROR\"\n \tcase evt.RepoCommit != nil:\n \t\treturn \"#commit\"\n+\tcase evt.RepoSync != nil:\n+\t\treturn \"#sync\"\n \tcase evt.RepoInfo != nil:\n \t\treturn \"#info\"\n \tdefault:\n---\ncmd/sonar/sonar.go\n@@ -109,6 +109,13 @@ func (s *Sonar) HandleStreamEvent(ctx context.Context, xe *events.XRPCStreamEven\n \tcase xe.RepoCommit != nil:\n \t\teventsProcessedCounter.WithLabelValues(\"repo_commit\", s.SocketURL).Inc()\n \t\treturn s.HandleRepoCommit(ctx, xe.RepoCommit)\n+\tcase xe.RepoSync != nil:\n+\t\teventsProcessedCounter.WithLabelValues(\"sync\", s.SocketURL).Inc()\n+\t\tnow := time.Now()\n+\t\ts.ProgMux.Lock()\n+\t\ts.Progress.LastSeq = xe.RepoSync.Seq\n+\t\ts.Progress.LastSeqProcessedAt = now\n+\t\ts.ProgMux.Unlock()\n \tcase xe.RepoIdentity != nil:\n \t\teventsProcessedCounter.WithLabelValues(\"identity\", s.SocketURL).Inc()\n \t\tnow := time.Now()\n---\ncmd/supercollider/main.go\n@@ -338,6 +338,9 @@ func Reload(cctx *cli.Context) error {\n \t\t\t\tcase evt.RepoCommit != nil:\n \t\t\t\t\theader.MsgType = \"#commit\"\n \t\t\t\t\tobj = evt.RepoCommit\n+\t\t\t\tcase evt.RepoSync != nil:\n+\t\t\t\t\theader.MsgType = \"#sync\"\n+\t\t\t\t\tobj = evt.RepoSync\n \t\t\t\tcase evt.RepoInfo != nil:\n \t\t\t\t\theader.MsgType = \"#info\"\n \t\t\t\t\tobj = evt.RepoInfo\n---\nevents/diskpersist/diskpersist.go\n@@ -278,8 +278,8 @@ func scanForLastSeq(fi *os.File, end int64) (int64, error) {\n \n const (\n \tevtKindCommit    = 1\n-\tevtKindHandle    = 2\n-\tevtKindTombstone = 3\n+\tevtKindHandle    = 2 // DEPRECATED\n+\tevtKindTombstone = 3 // DEPRECATED\n \tevtKindIdentity  = 4\n \tevtKindAccount   = 5\n \tevtKindSync      = 6\n---\nevents/persist.go\n@@ -42,6 +42,8 @@ func (mp *MemPersister) Persist(ctx context.Context, e *XRPCStreamEvent) error {\n \tswitch {\n \tcase e.RepoCommit != nil:\n \t\te.RepoCommit.Seq = mp.seq\n+\tcase e.RepoSync != nil:\n+\t\te.RepoSync.Seq = mp.seq\n \tcase e.RepoIdentity != nil:\n \t\te.RepoIdentity.Seq = mp.seq\n \tcase e.RepoAccount != nil:\n---\npds/server.go\n@@ -598,6 +598,9 @@ func (s *Server) EventsHandler(c echo.Context) error {\n \t\tcase evt.RepoCommit != nil:\n \t\t\theader.MsgType = \"#commit\"\n \t\t\tobj = evt.RepoCommit\n+\t\tcase evt.RepoSync != nil:\n+\t\t\theader.MsgType = \"#sync\"\n+\t\t\tobj = evt.RepoSync\n \t\tcase evt.RepoIdentity != nil:\n \t\t\theader.MsgType = \"#identity\"\n \t\t\tobj = evt.RepoIdentity\n@@ -651,6 +654,7 @@ func (s *Server) UpdateUserHandle(ctx context.Context, u *User, handle string) e\n \t\treturn fmt.Errorf(\"failed to update handle: %w\", err)\n \t}\n \n+\t// Push an Identity event\n \tif err := s.events.AddEvent(ctx, &events.XRPCStreamEvent{\n \t\tRepoIdentity: &comatproto.SyncSubscribeRepos_Identity{\n \t\t\tDid:  u.Did,\n---\nsearch/firehose.go\n@@ -115,6 +115,28 @@ func (idx *Indexer) RunIndexer(ctx context.Context) error {\n \t\t\treturn nil\n \n \t\t},\n+\t\t// TODO: process RepoIdentity\n+\t\tRepoIdentity: func(evt *comatproto.SyncSubscribeRepos_Identity) error {\n+\t\t\tctx := context.Background()\n+\t\t\tctx, span := tracer.Start(ctx, \"RepoIdentity\")\n+\t\t\tdefer span.End()\n+\n+\t\t\tdid, err := syntax.ParseDID(evt.Did)\n+\t\t\tif err != nil {\n+\t\t\t\tidx.logger.Error(\"bad DID in RepoIdentity event\", \"did\", evt.Did, \"seq\", evt.Seq, \"err\", err)\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t\tident, err := idx.dir.LookupDID(ctx, did)\n+\t\t\tif err != nil {\n+\t\t\t\tidx.logger.Error(\"failed identity resolution in RepoIdentity event\", \"did\", evt.Did, \"seq\", evt.Seq, \"err\", err)\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t\tif err := idx.updateUserHandle(ctx, did, ident.Handle.String()); err != nil {\n+\t\t\t\t// TODO: handle this case (instead of return nil)\n+\t\t\t\tidx.logger.Error(\"failed to update user handle\", \"did\", evt.Did, \"handle\", ident.Handle, \"seq\", evt.Seq, \"err\", err)\n+\t\t\t}\n+\t\t\treturn nil\n+\t\t},\n \t}\n \n \treturn events.HandleRepoStream(\n---\ntesting/utils.go\n@@ -666,6 +666,13 @@ func (b *TestRelay) Events(t *testing.T, since int64) *EventStream {\n \t\t\t\tes.Lk.Unlock()\n \t\t\t\treturn nil\n \t\t\t},\n+\t\t\tRepoSync: func(evt *atproto.SyncSubscribeRepos_Sync) error {\n+\t\t\t\tfmt.Println(\"received sync event: \", evt.Seq, evt.Did)\n+\t\t\t\tes.Lk.Lock()\n+\t\t\t\tes.Events = append(es.Events, &events.XRPCStreamEvent{RepoSync: evt})\n+\t\t\t\tes.Lk.Unlock()\n+\t\t\t\treturn nil\n+\t\t\t},\n \t\t\tRepoIdentity: func(evt *atproto.SyncSubscribeRepos_Identity) error {\n \t\t\t\tfmt.Println(\"received identity event: \", evt.Seq, evt.Did)\n \t\t\t\tes.Lk.Lock()\n---\n"}], "ideal": "Title: sync v1.1 event updates: add `#sync`, remove `#handle`, `#migrate`, `#tombstone`\n\nBody: This was an old branch. which I have now rebased on top of https://github.com/bluesky-social/indigo/pull/1082 (which got merged to main).\r\n\r\nIt now basically just adds `#sync` support in a few more places it was missing."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/gormstore.go\n@@ -314,6 +314,9 @@ func (j *Gormjob) SetRev(ctx context.Context, r string) error {\n \tj.rev = r\n \tj.updatedAt = time.Now()\n \n+\tj.dbj.Rev = r\n+\tj.dbj.UpdatedAt = j.updatedAt\n+\n \t// Persist the job to the database\n \n \treturn j.db.Save(j.dbj).Error\n---\n"}], "ideal": "Title: actually update revs in gormstore\n\nBody: Oop"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/backfill.go\n@@ -308,6 +308,21 @@ type recordResult struct {\n \terr        error\n }\n \n+type FetchRepoError struct {\n+\tStatusCode int\n+\tStatus     string\n+}\n+\n+func (e *FetchRepoError) Error() string {\n+\treason := \"unknown error\"\n+\tif e.StatusCode == http.StatusBadRequest {\n+\t\treason = \"repo not found\"\n+\t} else {\n+\t\treason = e.Status\n+\t}\n+\treturn fmt.Sprintf(\"failed to get repo: %s (%d)\", reason, e.StatusCode)\n+}\n+\n // Fetches a repo CAR file over HTTP from the indicated host. If successful, parses the CAR and returns repo.Repo\n func (b *Backfiller) fetchRepo(ctx context.Context, did, since, host string) (*repo.Repo, error) {\n \turl := fmt.Sprintf(\"%s/xrpc/com.atproto.sync.getRepo?did=%s\", host, did)\n@@ -340,13 +355,10 @@ func (b *Backfiller) fetchRepo(ctx context.Context, did, since, host string) (*r\n \t}\n \n \tif resp.StatusCode != http.StatusOK {\n-\t\treason := \"unknown error\"\n-\t\tif resp.StatusCode == http.StatusBadRequest {\n-\t\t\treason = \"repo not found\"\n-\t\t} else {\n-\t\t\treason = resp.Status\n+\t\treturn nil, &FetchRepoError{\n+\t\t\tStatusCode: resp.StatusCode,\n+\t\t\tStatus:     resp.Status,\n \t\t}\n-\t\treturn nil, fmt.Errorf(\"failed to get repo: %s\", reason)\n \t}\n \n \tinstrumentedReader := instrumentedReader{\n@@ -401,7 +413,11 @@ func (b *Backfiller) BackfillRepo(ctx context.Context, job Job) (string, error)\n \t\tr, err = b.fetchRepo(ctx, repoDID, job.Rev(), pdsHost)\n \t\tif err != nil {\n \t\t\tslog.Warn(\"repo CAR fetch from PDS failed\", \"did\", repoDID, \"since\", job.Rev(), \"pdsHost\", pdsHost, \"err\", err)\n-\t\t\treturn \"repo CAR fetch from PDS failed\", err\n+\t\t\trfe, ok := err.(*FetchRepoError)\n+\t\t\tif ok {\n+\t\t\t\treturn fmt.Sprintf(\"failed to fetch repo CAR from PDS (http %d:%s)\", rfe.StatusCode, rfe.Status), err\n+\t\t\t}\n+\t\t\treturn \"failed to fetch repo CAR from PDS\", err\n \t\t}\n \t}\n \n---\n"}], "ideal": "Title: better handling of backfill errors on pds fetch\n\nBody: Have a fair amount of random missing data coming from my consumer. Some of it i've found is that the initial repo fetch errorred for some reason and then we just drop all future events (which kinda makes sense i guess)\r\n\r\nHowever its useful to distinguish why the fetch failed, distinguishing between a rate limit and 'this repo does not exist' is important for recovery situations."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/collectiondir/crawl.go\n@@ -135,6 +135,7 @@ func (cr *Crawler) CrawlPDSRepoCollections() error {\n \t\tif err != nil {\n \t\t\treturn fmt.Errorf(\"%s: sync repos: %w\", cr.RpcClient.Host, err)\n \t\t}\n+\t\tpdsRepoPages.Inc()\n \t\tslog.Debug(\"got repo list\", \"count\", len(repos.Repos))\n \t\tfor _, xr := range repos.Repos {\n \t\t\tlimiter.Wait(cr.Ctx)\n@@ -148,6 +149,7 @@ func (cr *Crawler) CrawlPDSRepoCollections() error {\n \t\t\t\t}\n \t\t\t\tcontinue\n \t\t\t}\n+\t\t\tpdsReposDescribed.Inc()\n \t\t\tfor _, collection := range desc.Collections {\n \t\t\t\tcr.Results <- DidCollection{Did: xr.Did, Collection: collection}\n \t\t\t}\n---\ncmd/collectiondir/metrics.go\n@@ -39,6 +39,20 @@ var pdsCrawledCounter = promauto.NewCounter(prometheus.CounterOpts{\n \tName: \"collectiondir_pds_crawled_total\",\n })\n \n+var pdsRepoPages = promauto.NewCounter(prometheus.CounterOpts{\n+\tName: \"collectiondir_pds_repo_pages\",\n+})\n+\n+var pdsReposDescribed = promauto.NewCounter(prometheus.CounterOpts{\n+\tName: \"collectiondir_pds_repos_described\",\n+})\n+\n+var statsCalculations = promauto.NewHistogram(prometheus.HistogramOpts{\n+\tName:    \"collectiondir_stats_calculations\",\n+\tHelp:    \"how long it takes to calculate total stats\",\n+\tBuckets: prometheus.ExponentialBuckets(0.01, 2, 13),\n+})\n+\n var reqDur = promauto.NewHistogramVec(prometheus.HistogramOpts{\n \tName:    \"http_request_duration_seconds\",\n \tHelp:    \"A histogram of latencies for requests.\",\n---\ncmd/collectiondir/serve.go\n@@ -580,6 +580,7 @@ func (cs *collectionServer) statsBuilder() {\n \t\tstats, err := cs.pcd.GetCollectionStats()\n \t\tdt := time.Since(start)\n \t\tif err == nil {\n+\t\t\tstatsCalculations.Observe(dt.Seconds())\n \t\t\tcountsum := uint64(0)\n \t\t\tfor _, v := range stats.CollectionCounts {\n \t\t\t\tcountsum += v\n---\n"}], "ideal": "Title: collectiondir more metrics\n\nBody: add metrics: number of listRepos pages fetched, number of repos described, time taken calculating total stats"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/base_directory.go\n@@ -33,6 +33,8 @@ type BaseDirectory struct {\n \t//\n \t// The intended use-case for this flag is as an optimization for services which do not care about handles, but still want to use the `Directory` interface (instead of `ResolveDID`). For example, relay implementations, or services validating inter-service auth requests.\n \tSkipHandleVerification bool\n+\t// User-Agent header for HTTP requests. Optional (ignored if empty string).\n+\tUserAgent string\n }\n \n var _ Directory = (*BaseDirectory)(nil)\n@@ -107,7 +109,7 @@ func (d *BaseDirectory) Lookup(ctx context.Context, a syntax.AtIdentifier) (*Ide\n \treturn nil, fmt.Errorf(\"at-identifier neither a Handle nor a DID\")\n }\n \n-func (d *BaseDirectory) Purge(ctx context.Context, a syntax.AtIdentifier) error {\n+func (d *BaseDirectory) Purge(ctx context.Context, atid syntax.AtIdentifier) error {\n \t// BaseDirectory itself does not implement caching\n \treturn nil\n }\n---\natproto/identity/cache_directory.go\n@@ -250,14 +250,14 @@ func (d *CacheDirectory) Lookup(ctx context.Context, a syntax.AtIdentifier) (*Id\n \treturn nil, fmt.Errorf(\"at-identifier neither a Handle nor a DID\")\n }\n \n-func (d *CacheDirectory) Purge(ctx context.Context, a syntax.AtIdentifier) error {\n-\thandle, err := a.AsHandle()\n+func (d *CacheDirectory) Purge(ctx context.Context, atid syntax.AtIdentifier) error {\n+\thandle, err := atid.AsHandle()\n \tif nil == err { // if not an error, is a handle\n \t\thandle = handle.Normalize()\n \t\td.handleCache.Remove(handle)\n \t\treturn nil\n \t}\n-\tdid, err := a.AsDID()\n+\tdid, err := atid.AsDID()\n \tif nil == err { // if not an error, is a DID\n \t\td.identityCache.Remove(did)\n \t\treturn nil\n---\natproto/identity/did.go\n@@ -98,6 +98,10 @@ func (d *BaseDirectory) resolveDIDWeb(ctx context.Context, did syntax.DID) ([]by\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"constructing HTTP request for did:web resolution: %w\", err)\n \t}\n+\tif d.UserAgent != \"\" {\n+\t\treq.Header.Set(\"User-Agent\", d.UserAgent)\n+\t}\n+\n \tresp, err := d.HTTPClient.Do(req)\n \n \t// look for NXDOMAIN\n@@ -112,9 +116,11 @@ func (d *BaseDirectory) resolveDIDWeb(ctx context.Context, did syntax.DID) ([]by\n \t}\n \tdefer resp.Body.Close()\n \tif resp.StatusCode == http.StatusNotFound {\n+\t\tio.Copy(io.Discard, resp.Body)\n \t\treturn nil, fmt.Errorf(\"%w: did:web HTTP status 404\", ErrDIDNotFound)\n \t}\n \tif resp.StatusCode != http.StatusOK {\n+\t\tio.Copy(io.Discard, resp.Body)\n \t\treturn nil, fmt.Errorf(\"%w: did:web HTTP status %d\", ErrDIDResolutionFailed, resp.StatusCode)\n \t}\n \n@@ -141,15 +147,21 @@ func (d *BaseDirectory) resolveDIDPLC(ctx context.Context, did syntax.DID) ([]by\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"constructing HTTP request for did:plc resolution: %w\", err)\n \t}\n+\tif d.UserAgent != \"\" {\n+\t\treq.Header.Set(\"User-Agent\", d.UserAgent)\n+\t}\n+\n \tresp, err := d.HTTPClient.Do(req)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"%w: PLC directory lookup: %w\", ErrDIDResolutionFailed, err)\n \t}\n \tdefer resp.Body.Close()\n \tif resp.StatusCode == http.StatusNotFound {\n+\t\tio.Copy(io.Discard, resp.Body)\n \t\treturn nil, fmt.Errorf(\"%w: PLC directory 404\", ErrDIDNotFound)\n \t}\n \tif resp.StatusCode != http.StatusOK {\n+\t\tio.Copy(io.Discard, resp.Body)\n \t\treturn nil, fmt.Errorf(\"%w: PLC directory status %d\", ErrDIDResolutionFailed, resp.StatusCode)\n \t}\n \n---\natproto/identity/directory.go\n@@ -8,6 +8,8 @@ import (\n \t\"time\"\n \n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n+\n+\t\"github.com/carlmjohnson/versioninfo\"\n )\n \n // Ergonomic interface for atproto identity lookup, by DID or handle.\n@@ -27,7 +29,7 @@ type Directory interface {\n \tLookup(ctx context.Context, atid syntax.AtIdentifier) (*Identity, error)\n \n \t// Flushes any cache of the indicated identifier. If directory is not using caching, can ignore this.\n-\tPurge(ctx context.Context, i syntax.AtIdentifier) error\n+\tPurge(ctx context.Context, atid syntax.AtIdentifier) error\n }\n \n // Indicates that handle resolution failed. A wrapped error may provide more context. This is only returned when looking up a handle, not when looking up a DID.\n@@ -80,6 +82,7 @@ func DefaultDirectory() Directory {\n \t\tTryAuthoritativeDNS: true,\n \t\t// primary Bluesky PDS instance only supports HTTP resolution method\n \t\tSkipDNSDomainSuffixes: []string{\".bsky.social\"},\n+\t\tUserAgent:             \"indigo-identity/\" + versioninfo.Short(),\n \t}\n \tcached := NewCacheDirectory(&base, 250_000, time.Hour*24, time.Minute*2, time.Minute*5)\n \treturn &cached\n---\natproto/identity/handle.go\n@@ -131,6 +131,9 @@ func (d *BaseDirectory) ResolveHandleWellKnown(ctx context.Context, handle synta\n \tif err != nil {\n \t\treturn \"\", fmt.Errorf(\"constructing HTTP request for handle resolution: %w\", err)\n \t}\n+\tif d.UserAgent != \"\" {\n+\t\treq.Header.Set(\"User-Agent\", d.UserAgent)\n+\t}\n \n \tresp, err := d.HTTPClient.Do(req)\n \tif err != nil {\n@@ -144,17 +147,19 @@ func (d *BaseDirectory) ResolveHandleWellKnown(ctx context.Context, handle synta\n \t\treturn \"\", fmt.Errorf(\"%w: HTTP well-known request error: %w\", ErrHandleResolutionFailed, err)\n \t}\n \tdefer resp.Body.Close()\n+\tif resp.ContentLength > 2048 {\n+\t\t// NOTE: intentionally not draining body\n+\t\treturn \"\", fmt.Errorf(\"%w: HTTP well-known body too large for %s\", ErrHandleResolutionFailed, handle)\n+\t}\n \tif resp.StatusCode == http.StatusNotFound {\n+\t\tio.Copy(io.Discard, resp.Body)\n \t\treturn \"\", fmt.Errorf(\"%w: HTTP 404 for %s\", ErrHandleNotFound, handle)\n \t}\n \tif resp.StatusCode != http.StatusOK {\n+\t\tio.Copy(io.Discard, resp.Body)\n \t\treturn \"\", fmt.Errorf(\"%w: HTTP well-known status %d for %s\", ErrHandleResolutionFailed, resp.StatusCode, handle)\n \t}\n \n-\tif resp.ContentLength > 2048 {\n-\t\treturn \"\", fmt.Errorf(\"%w: HTTP well-known body too large for %s\", ErrHandleResolutionFailed, handle)\n-\t}\n-\n \tb, err := io.ReadAll(io.LimitReader(resp.Body, 2048))\n \tif err != nil {\n \t\treturn \"\", fmt.Errorf(\"%w: HTTP well-known body read for %s: %w\", ErrHandleResolutionFailed, handle, err)\n---\n"}], "ideal": "Title: identity package tweaks\n\nBody: - add user-agent\r\n- ensure we drain HTTP requests in more code paths (allows connections/streams to be re-used more efficiently)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/fedmgr.go\n@@ -561,9 +561,8 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\t}); err != nil {\n \t\t\t\tlog.Error(\"failed handling event\", \"host\", host.Host, \"seq\", evt.Seq, \"err\", err)\n \t\t\t}\n-\t\t\t*lastCursor = evt.Seq\n \n-\t\t\tif err := s.updateCursor(sub, *lastCursor); err != nil {\n+\t\t\tif err := s.updateCursor(sub, lastCursor, evt.Seq); err != nil {\n \t\t\t\treturn fmt.Errorf(\"updating cursor: %w\", err)\n \t\t\t}\n \n@@ -576,9 +575,8 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\t}); err != nil {\n \t\t\t\tlog.Error(\"failed handling event\", \"host\", host.Host, \"seq\", evt.Seq, \"err\", err)\n \t\t\t}\n-\t\t\t*lastCursor = evt.Seq\n \n-\t\t\tif err := s.updateCursor(sub, *lastCursor); err != nil {\n+\t\t\tif err := s.updateCursor(sub, lastCursor, evt.Seq); err != nil {\n \t\t\t\treturn fmt.Errorf(\"updating cursor: %w\", err)\n \t\t\t}\n \n@@ -591,9 +589,8 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\t}); err != nil {\n \t\t\t\tlog.Error(\"failed handling event\", \"host\", host.Host, \"seq\", evt.Seq, \"err\", err)\n \t\t\t}\n-\t\t\t*lastCursor = evt.Seq\n \n-\t\t\tif err := s.updateCursor(sub, *lastCursor); err != nil {\n+\t\t\tif err := s.updateCursor(sub, lastCursor, evt.Seq); err != nil {\n \t\t\t\treturn fmt.Errorf(\"updating cursor: %w\", err)\n \t\t\t}\n \n@@ -606,9 +603,8 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\t}); err != nil {\n \t\t\t\tlog.Error(\"failed handling event\", \"host\", host.Host, \"seq\", evt.Seq, \"err\", err)\n \t\t\t}\n-\t\t\t*lastCursor = evt.Seq\n \n-\t\t\tif err := s.updateCursor(sub, *lastCursor); err != nil {\n+\t\t\tif err := s.updateCursor(sub, lastCursor, evt.Seq); err != nil {\n \t\t\t\treturn fmt.Errorf(\"updating cursor: %w\", err)\n \t\t\t}\n \n@@ -625,9 +621,8 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\t}); err != nil {\n \t\t\t\tlog.Error(\"failed handling event\", \"host\", host.Host, \"seq\", ident.Seq, \"err\", err)\n \t\t\t}\n-\t\t\t*lastCursor = ident.Seq\n \n-\t\t\tif err := s.updateCursor(sub, *lastCursor); err != nil {\n+\t\t\tif err := s.updateCursor(sub, lastCursor, ident.Seq); err != nil {\n \t\t\t\treturn fmt.Errorf(\"updating cursor: %w\", err)\n \t\t\t}\n \n@@ -640,9 +635,8 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\t}); err != nil {\n \t\t\t\tlog.Error(\"failed handling event\", \"host\", host.Host, \"seq\", acct.Seq, \"err\", err)\n \t\t\t}\n-\t\t\t*lastCursor = acct.Seq\n \n-\t\t\tif err := s.updateCursor(sub, *lastCursor); err != nil {\n+\t\t\tif err := s.updateCursor(sub, lastCursor, acct.Seq); err != nil {\n \t\t\t\treturn fmt.Errorf(\"updating cursor: %w\", err)\n \t\t\t}\n \n@@ -657,7 +651,10 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\t\t\treturn err\n \t\t\t\t}\n \n+\t\t\t\tsub.lk.Lock()\n \t\t\t\t*lastCursor = 0\n+\t\t\t\tsub.lk.Unlock()\n+\n \t\t\t\treturn fmt.Errorf(\"got FutureCursor frame, reset cursor tracking for host\")\n \t\t\tdefault:\n \t\t\t\treturn fmt.Errorf(\"error frame: %s: %s\", errf.Error, errf.Message)\n@@ -684,10 +681,11 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \treturn events.HandleRepoStream(ctx, con, pool, nil)\n }\n \n-func (s *Slurper) updateCursor(sub *activeSub, curs int64) error {\n+func (s *Slurper) updateCursor(sub *activeSub, curs *int64, newCurs int64) error {\n \tsub.lk.Lock()\n \tdefer sub.lk.Unlock()\n-\tsub.pds.Cursor = curs\n+\t*curs = newCurs\n+\tsub.pds.Cursor = *curs\n \treturn nil\n }\n \n---\n"}], "ideal": "Title: Fix Race Conditions In All Slurper.handleConnection Callbacks\n\nBody: Hi there!\r\n\r\nI was curious about your code and pulled it down to take a look. When I went to run the tests, I noticed that there was a single race condition, which is resolved with this commit.\r\n\r\nThe idea is that the cursor's value should only be updated after acquiring `activeSub`'s lock.\r\n\r\nAlso, a small suggestion, it might be a good idea to add the race detector to CI? Didn't want to push that up to y'all in a PR out of the blue though since that feels like bad open source form :smile: "}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "events/cbor_gen.go\n@@ -25,32 +25,40 @@ func (t *EventHeader) MarshalCBOR(w io.Writer) error {\n \t}\n \n \tcw := cbg.NewCborWriter(w)\n+\tfieldCount := 2\n \n-\tif _, err := cw.Write([]byte{162}); err != nil {\n+\tif t.MsgType == \"\" {\n+\t\tfieldCount--\n+\t}\n+\n+\tif _, err := cw.Write(cbg.CborEncodeMajorType(cbg.MajMap, uint64(fieldCount))); err != nil {\n \t\treturn err\n \t}\n \n \t// t.MsgType (string) (string)\n-\tif len(\"t\") > 1000000 {\n-\t\treturn xerrors.Errorf(\"Value in field \\\"t\\\" was too long\")\n-\t}\n+\tif t.MsgType != \"\" {\n \n-\tif err := cw.WriteMajorTypeHeader(cbg.MajTextString, uint64(len(\"t\"))); err != nil {\n-\t\treturn err\n-\t}\n-\tif _, err := cw.WriteString(string(\"t\")); err != nil {\n-\t\treturn err\n-\t}\n+\t\tif len(\"t\") > 1000000 {\n+\t\t\treturn xerrors.Errorf(\"Value in field \\\"t\\\" was too long\")\n+\t\t}\n \n-\tif len(t.MsgType) > 1000000 {\n-\t\treturn xerrors.Errorf(\"Value in field t.MsgType was too long\")\n-\t}\n+\t\tif err := cw.WriteMajorTypeHeader(cbg.MajTextString, uint64(len(\"t\"))); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tif _, err := cw.WriteString(string(\"t\")); err != nil {\n+\t\t\treturn err\n+\t\t}\n \n-\tif err := cw.WriteMajorTypeHeader(cbg.MajTextString, uint64(len(t.MsgType))); err != nil {\n-\t\treturn err\n-\t}\n-\tif _, err := cw.WriteString(string(t.MsgType)); err != nil {\n-\t\treturn err\n+\t\tif len(t.MsgType) > 1000000 {\n+\t\t\treturn xerrors.Errorf(\"Value in field t.MsgType was too long\")\n+\t\t}\n+\n+\t\tif err := cw.WriteMajorTypeHeader(cbg.MajTextString, uint64(len(t.MsgType))); err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tif _, err := cw.WriteString(string(t.MsgType)); err != nil {\n+\t\t\treturn err\n+\t\t}\n \t}\n \n \t// t.Op (int64) (int64)\n---\nevents/events.go\n@@ -152,7 +152,7 @@ const (\n \n type EventHeader struct {\n \tOp      int64  `cborgen:\"op\"`\n-\tMsgType string `cborgen:\"t\"`\n+\tMsgType string `cborgen:\"t,omitempty\"`\n }\n \n var (\n---\n"}], "ideal": "Title: events: omitempty on 't' in header\n\nBody: I'm not sure what the timeline would be on getting this deployed; we are in the middle of refactoring the relay.\r\n\r\nOn the other hand it is a pretty small/simple change.\r\n\r\ncloses: [#3086](https://github.com/bluesky-social/atproto/issues/3086)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "carstore/scylla.go\n@@ -1,3 +1,5 @@\n+//go:build scylla\n+\n package carstore\n \n import (\n---\ncarstore/scylla_stub.go\n@@ -0,0 +1,9 @@\n+//go:build !scylla\n+\n+package carstore\n+\n+import \"errors\"\n+\n+func NewScyllaStore(addrs []string, keyspace string) (CarStore, error) {\n+\treturn nil, errors.New(\"scylla compiled out\")\n+}\n---\ncmd/bigsky/Dockerfile\n@@ -12,7 +12,9 @@ WORKDIR /dockerbuild\n # timezone data for alpine builds\n ENV GOEXPERIMENT=loopvar\n RUN GIT_VERSION=$(git describe --tags --long --always) && \\\n-    go build -tags timetzdata -o /bigsky ./cmd/bigsky\n+    echo \"replace github.com/gocql/gocql => github.com/scylladb/gocql v1.14.4\" >> go.mod && \\\n+    go mod tidy && \\\n+    go build -tags timetzdata,scylla -o /bigsky ./cmd/bigsky\n \n ### Build Frontend stage\n FROM node:18-alpine as web-builder\n---\ngo.mod\n@@ -16,7 +16,6 @@ require (\n \tgithub.com/flosch/pongo2/v6 v6.0.0\n \tgithub.com/go-redis/cache/v9 v9.0.0\n \tgithub.com/goccy/go-json v0.10.2\n-\tgithub.com/gocql/gocql v0.0.0-00010101000000-000000000000\n \tgithub.com/golang-jwt/jwt v3.2.2+incompatible\n \tgithub.com/gorilla/websocket v1.5.1\n \tgithub.com/hashicorp/go-retryablehttp v0.7.5\n@@ -191,5 +190,3 @@ require (\n \tgopkg.in/yaml.v3 v3.0.1 // indirect\n \tlukechampine.com/blake3 v1.2.1 // indirect\n )\n-\n-replace github.com/gocql/gocql => github.com/scylladb/gocql v1.14.4\n---\nmodels/dbcid.go\n@@ -4,8 +4,6 @@ import (\n \t\"database/sql/driver\"\n \t\"encoding/json\"\n \t\"fmt\"\n-\t\"github.com/gocql/gocql\"\n-\n \t\"github.com/ipfs/go-cid\"\n )\n \n@@ -63,15 +61,3 @@ func (dbc *DbCID) UnmarshalJSON(b []byte) error {\n func (dbc *DbCID) GormDataType() string {\n \treturn \"bytes\"\n }\n-\n-func (dbc *DbCID) MarshalCQL(info gocql.TypeInfo) ([]byte, error) {\n-\treturn dbc.CID.Bytes(), nil\n-}\n-func (dbc *DbCID) UnmarshalCQL(info gocql.TypeInfo, data []byte) error {\n-\txcid, err := cid.Cast(data)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tdbc.CID = xcid\n-\treturn nil\n-}\n---\n"}], "ideal": "Title: only depend on scylla in bigsky build\n\nBody: importing scylla via replace doesn't work when indigo is imported as a library.\r\nerase dependency on scylla except when building bigsky"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "api/agnostic/repoputRecord.go\n@@ -23,7 +23,7 @@ type RepoPutRecord_Input struct {\n \t// swapCommit: Compare and swap with the previous commit by CID.\n \tSwapCommit *string `json:\"swapCommit,omitempty\" cborgen:\"swapCommit,omitempty\"`\n \t// swapRecord: Compare and swap with the previous record by CID. WARNING: nullable and optional field; may cause problems with golang implementation\n-\tSwapRecord *string `json:\"swapRecord\" cborgen:\"swapRecord\"`\n+\tSwapRecord *string `json:\"swapRecord,omitempty\" cborgen:\"swapRecord,omitempty\"`\n \t// validate: Can be set to 'false' to skip Lexicon schema validation of record data, 'true' to require it, or leave unset to validate only for known Lexicons.\n \tValidate *bool `json:\"validate,omitempty\" cborgen:\"validate,omitempty\"`\n }\n---\n"}], "ideal": "Title: agnostic: default putRecord to not include swapRecord field\n\nBody: The root issue here is \"nullable and optional\" not being easy to express with default golang struct marshaling. The result is this swap field getting set, but as null, which prevents actual updates (only allows creation).\r\n\r\nThis PR swaps to omitting the field. Makes it impossible to do a forced swap check of nil... but can just use create for that?"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/consumer/firehose.go\n@@ -80,14 +80,14 @@ func (fc *FirehoseConsumer) Run(ctx context.Context) error {\n \t\t},\n \t\tRepoIdentity: func(evt *comatproto.SyncSubscribeRepos_Identity) error {\n \t\t\tatomic.StoreInt64(&fc.lastSeq, evt.Seq)\n-\t\t\tif err := fc.Engine.ProcessIdentityEvent(ctx, *evt); err != nil {\n+\t\t\tif err := fc.Engine.ProcessIdentityEvent(context.Background(), *evt); err != nil {\n \t\t\t\tfc.Logger.Error(\"processing repo identity failed\", \"did\", evt.Did, \"seq\", evt.Seq, \"err\", err)\n \t\t\t}\n \t\t\treturn nil\n \t\t},\n \t\tRepoAccount: func(evt *comatproto.SyncSubscribeRepos_Account) error {\n \t\t\tatomic.StoreInt64(&fc.lastSeq, evt.Seq)\n-\t\t\tif err := fc.Engine.ProcessAccountEvent(ctx, *evt); err != nil {\n+\t\t\tif err := fc.Engine.ProcessAccountEvent(context.Background(), *evt); err != nil {\n \t\t\t\tfc.Logger.Error(\"processing repo account failed\", \"did\", evt.Did, \"seq\", evt.Seq, \"err\", err)\n \t\t\t}\n \t\t\treturn nil\n@@ -182,7 +182,7 @@ func (fc *FirehoseConsumer) HandleRepoCommit(ctx context.Context, evt *comatprot\n \t\t\t\tCID:        &recCID,\n \t\t\t\tRecordCBOR: *recCBOR,\n \t\t\t}\n-\t\t\terr = fc.Engine.ProcessRecordOp(ctx, op)\n+\t\t\terr = fc.Engine.ProcessRecordOp(context.Background(), op)\n \t\t\tif err != nil {\n \t\t\t\tlogger.Error(\"engine failed to process record\", \"err\", err)\n \t\t\t\tcontinue\n@@ -196,7 +196,7 @@ func (fc *FirehoseConsumer) HandleRepoCommit(ctx context.Context, evt *comatprot\n \t\t\t\tCID:        nil,\n \t\t\t\tRecordCBOR: nil,\n \t\t\t}\n-\t\t\terr = fc.Engine.ProcessRecordOp(ctx, op)\n+\t\t\terr = fc.Engine.ProcessRecordOp(context.Background(), op)\n \t\t\tif err != nil {\n \t\t\t\tlogger.Error(\"engine failed to process record\", \"err\", err)\n \t\t\t\tcontinue\n---\nautomod/consumer/ozone.go\n@@ -118,7 +118,7 @@ func (oc *OzoneConsumer) HandleOzoneEvent(ctx context.Context, eventView *toolso\n \n \toc.Logger.Debug(\"received ozone event\", \"eventID\", eventView.Id, \"createdAt\", eventView.CreatedAt)\n \n-\tif err := oc.Engine.ProcessOzoneEvent(ctx, eventView); err != nil {\n+\tif err := oc.Engine.ProcessOzoneEvent(context.Background(), eventView); err != nil {\n \t\toc.Logger.Error(\"engine failed to process ozone event\", \"err\", err)\n \t}\n \treturn nil\n---\n"}], "ideal": "Title: automod: give each event a separate ctx\n\nBody: This didn't fix the problem we were seeing at the time, but might still be the best practice here?"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/bigsky/main.go\n@@ -482,7 +482,7 @@ func runBigsky(cctx *cli.Context) error {\n \t\tif err := ix.HandleRepoEvent(ctx, evt); err != nil {\n \t\t\tslog.Error(\"failed to handle repo event\", \"err\", err)\n \t\t}\n-\t}, false)\n+\t}, true)\n \n \tprodHR, err := api.NewProdHandleResolver(100_000, cctx.String(\"resolve-address\"), cctx.Bool(\"force-dns-udp\"))\n \tif err != nil {\n---\nrepomgr/repomgr.go\n@@ -312,6 +312,23 @@ func (rm *RepoManager) DeleteRecord(ctx context.Context, user models.Uid, collec\n \t}\n \n \trpath := collection + \"/\" + rkey\n+\n+\top := RepoOp{\n+\t\tKind:       EvtKindDeleteRecord,\n+\t\tCollection: collection,\n+\t\tRkey:       rkey,\n+\t}\n+\n+\tif rm.hydrateRecords && rm.events != nil {\n+\t\tocid, rec, err := r.GetRecord(ctx, rpath)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\n+\t\top.Record = rec\n+\t\top.RecCid = &ocid\n+\t}\n+\n \tif err := r.DeleteRecord(ctx, rpath); err != nil {\n \t\treturn err\n \t}\n@@ -333,16 +350,12 @@ func (rm *RepoManager) DeleteRecord(ctx context.Context, user models.Uid, collec\n \n \tif rm.events != nil {\n \t\trm.events(ctx, &RepoEvent{\n-\t\t\tUser:    user,\n-\t\t\tOldRoot: oldroot,\n-\t\t\tNewRoot: nroot,\n-\t\t\tRev:     nrev,\n-\t\t\tSince:   &rev,\n-\t\t\tOps: []RepoOp{{\n-\t\t\t\tKind:       EvtKindDeleteRecord,\n-\t\t\t\tCollection: collection,\n-\t\t\t\tRkey:       rkey,\n-\t\t\t}},\n+\t\t\tUser:      user,\n+\t\t\tOldRoot:   oldroot,\n+\t\t\tNewRoot:   nroot,\n+\t\t\tRev:       nrev,\n+\t\t\tSince:     &rev,\n+\t\t\tOps:       []RepoOp{op},\n \t\t\tRepoSlice: rslice,\n \t\t})\n \t}\n@@ -615,11 +628,23 @@ func (rm *RepoManager) handleExternalUserEventNoArchive(ctx context.Context, pds\n \n \t\t\tevtops = append(evtops, rop)\n \t\tcase EvtKindDeleteRecord:\n-\t\t\tevtops = append(evtops, RepoOp{\n+\t\t\trop := RepoOp{\n \t\t\t\tKind:       EvtKindDeleteRecord,\n \t\t\t\tCollection: parts[0],\n \t\t\t\tRkey:       parts[1],\n-\t\t\t})\n+\t\t\t}\n+\n+\t\t\tif rm.hydrateRecords {\n+\t\t\t\tcid, rec, err := r.GetRecord(ctx, op.Path)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn fmt.Errorf(\"reading changed record from car slice: %w\", err)\n+\t\t\t\t}\n+\n+\t\t\t\trop.RecCid = &cid\n+\t\t\t\trop.Record = rec\n+\t\t\t}\n+\n+\t\t\tevtops = append(evtops, rop)\n \t\tdefault:\n \t\t\treturn fmt.Errorf(\"unrecognized external user event kind: %q\", op.Action)\n \t\t}\n@@ -738,11 +763,23 @@ func (rm *RepoManager) handleExternalUserEventArchive(ctx context.Context, pdsid\n \n \t\t\tevtops = append(evtops, rop)\n \t\tcase EvtKindDeleteRecord:\n-\t\t\tevtops = append(evtops, RepoOp{\n+\t\t\trop := RepoOp{\n \t\t\t\tKind:       EvtKindDeleteRecord,\n \t\t\t\tCollection: parts[0],\n \t\t\t\tRkey:       parts[1],\n-\t\t\t})\n+\t\t\t}\n+\n+\t\t\tif rm.hydrateRecords {\n+\t\t\t\tcid, rec, err := r.GetRecord(ctx, op.Path)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn fmt.Errorf(\"reading changed record from car slice: %w\", err)\n+\t\t\t\t}\n+\n+\t\t\t\trop.RecCid = &cid\n+\t\t\t\trop.Record = rec\n+\t\t\t}\n+\n+\t\t\tevtops = append(evtops, rop)\n \t\tdefault:\n \t\t\treturn fmt.Errorf(\"unrecognized external user event kind: %q\", op.Action)\n \t\t}\n@@ -851,15 +888,27 @@ func (rm *RepoManager) BatchWrite(ctx context.Context, user models.Uid, writes [\n \t\tcase w.RepoApplyWrites_Delete != nil:\n \t\t\td := w.RepoApplyWrites_Delete\n \n+\t\t\top := RepoOp{\n+\t\t\t\tKind:       EvtKindDeleteRecord,\n+\t\t\t\tCollection: d.Collection,\n+\t\t\t\tRkey:       d.Rkey,\n+\t\t\t}\n+\n+\t\t\tif rm.hydrateRecords {\n+\t\t\t\tcc, rec, err := r.GetRecord(ctx, d.Collection+\"/\"+d.Rkey)\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn err\n+\t\t\t\t}\n+\n+\t\t\t\top.RecCid = &cc\n+\t\t\t\top.Record = rec\n+\t\t\t}\n+\n \t\t\tif err := r.DeleteRecord(ctx, d.Collection+\"/\"+d.Rkey); err != nil {\n \t\t\t\treturn err\n \t\t\t}\n \n-\t\t\tops = append(ops, RepoOp{\n-\t\t\t\tKind:       EvtKindDeleteRecord,\n-\t\t\t\tCollection: d.Collection,\n-\t\t\t\tRkey:       d.Rkey,\n-\t\t\t})\n+\t\t\tops = append(ops, op)\n \t\tdefault:\n \t\t\treturn fmt.Errorf(\"no operation set in write enum\")\n \t\t}\n@@ -1028,12 +1077,32 @@ func (rm *RepoManager) processOp(ctx context.Context, bs blockstore.Blockstore,\n \n \t\treturn outop, nil\n \tcase \"del\":\n-\t\treturn &RepoOp{\n+\t\toutop := &RepoOp{\n \t\t\tKind:       EvtKindDeleteRecord,\n \t\t\tCollection: parts[0],\n \t\t\tRkey:       parts[1],\n-\t\t\tRecCid:     nil,\n-\t\t}, nil\n+\t\t\tRecCid:     &op.OldCid,\n+\t\t}\n+\n+\t\tif hydrateRecords {\n+\t\t\tblk, err := bs.Get(ctx, op.OldCid)\n+\t\t\tif err != nil {\n+\t\t\t\treturn nil, err\n+\t\t\t}\n+\n+\t\t\trec, err := lexutil.CborDecodeValue(blk.RawData())\n+\t\t\tif err != nil {\n+\t\t\t\tif !errors.Is(err, lexutil.ErrUnrecognizedType) {\n+\t\t\t\t\treturn nil, err\n+\t\t\t\t}\n+\n+\t\t\t\trm.log.Warn(\"failed processing repo diff\", \"err\", err)\n+\t\t\t} else {\n+\t\t\t\toutop.Record = rec\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn outop, nil\n \n \tdefault:\n \t\treturn nil, fmt.Errorf(\"diff returned invalid op type: %q\", op.Op)\n---\n"}], "ideal": "Title: Hydrate DeleteRecords events with deleted Record\n\nBody: To enable Firehose users to action deleted records without necessarily storing the records being deleted (e.g. by decrementing counters, etc.), we include the record being deleted in the Firehose.\r\n\r\nThis is only enabled when `hydrateRecords` is enabled, as per `UpdateRecords`.\r\n\r\nCurrently, BigSky has `hydrateRecords` set to `false`. We set this to `true` so that the Firehose provided by BigSky hydrates records for `update` and `delete` events.\r\n\r\nCloses #927"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/goat/repo.go\n@@ -185,21 +185,21 @@ func runRepoList(cctx *cli.Context) error {\n \t}\n \tfi, err := os.Open(carPath)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"failed to open CAR file: %w\", err)\n \t}\n \n \t// read repository tree in to memory\n \tr, err := repo.ReadRepoFromCar(ctx, fi)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"failed to parse repo CAR file: %w\", err)\n \t}\n \n \terr = r.ForEach(ctx, \"\", func(k string, v cid.Cid) error {\n \t\tfmt.Printf(\"%s\\t%s\\n\", k, v.String())\n \t\treturn nil\n \t})\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"failed to read records from repo CAR file: %w\", err)\n \t}\n \treturn nil\n }\n---\n"}], "ideal": "Title: goat: small error improvements\n\nBody: simple"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "repo/repo.go\n@@ -80,7 +80,7 @@ func IngestRepo(ctx context.Context, bs blockstore.Blockstore, r io.Reader) (cid\n \n \tbr, err := car.NewBlockReader(r)\n \tif err != nil {\n-\t\treturn cid.Undef, fmt.Errorf(\"IngestRepo:NewBlockReader: %w\", err)\n+\t\treturn cid.Undef, fmt.Errorf(\"opening CAR block reader: %w\", err)\n \t}\n \n \tfor {\n@@ -89,11 +89,11 @@ func IngestRepo(ctx context.Context, bs blockstore.Blockstore, r io.Reader) (cid\n \t\t\tif err == io.EOF {\n \t\t\t\tbreak\n \t\t\t}\n-\t\t\treturn cid.Undef, fmt.Errorf(\"IngestRepo:Next: %w\", err)\n+\t\t\treturn cid.Undef, fmt.Errorf(\"reading block from CAR: %w\", err)\n \t\t}\n \n \t\tif err := bs.Put(ctx, blk); err != nil {\n-\t\t\treturn cid.Undef, fmt.Errorf(\"IngestRepo:Put: %w\", err)\n+\t\t\treturn cid.Undef, fmt.Errorf(\"copying block to store: %w\", err)\n \t\t}\n \t}\n \n---\n"}], "ideal": "Title: improve some repo error messages\n\nBody: I had these in my local working tree; @brianolson also added some error messages in between. I think mine might be clearer?"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/engine/context.go\n@@ -91,22 +91,6 @@ type OzoneEvent struct {\n \tEvent toolsozone.ModerationDefs_ModEventView_Event\n }\n \n-// Originally intended for push notifications, but can also work for any inter-account notification.\n-type NotificationContext struct {\n-\tAccountContext\n-\n-\tRecipient    AccountMeta\n-\tNotification NotificationMeta\n-}\n-\n-// Additional notification metadata, with fields aligning with the `app.bsky.notification.listNotifications` Lexicon schemas\n-type NotificationMeta struct {\n-\t// Expected values are 'like', 'repost', 'follow', 'mention', 'reply', and 'quote'; arbitrary values may be added in the future.\n-\tReason string\n-\t// The content (atproto record) which was the cause of this notification. Could be a post with a mention, or a like, follow, or repost record.\n-\tSubject syntax.ATURI\n-}\n-\n // Checks that op has expected fields, based on the action type\n func (op *RecordOp) Validate() error {\n \tswitch op.Action {\n@@ -198,19 +182,6 @@ func NewRecordContext(ctx context.Context, eng *Engine, meta AccountMeta, op Rec\n \t}\n }\n \n-func NewNotificationContext(ctx context.Context, eng *Engine, sender, recipient AccountMeta, reason string, subject syntax.ATURI) NotificationContext {\n-\tac := NewAccountContext(ctx, eng, sender)\n-\tac.BaseContext.Logger = ac.BaseContext.Logger.With(\"recipient\", recipient.Identity.DID, \"reason\", reason, \"subject\", subject.String())\n-\treturn NotificationContext{\n-\t\tAccountContext: ac,\n-\t\tRecipient:      recipient,\n-\t\tNotification: NotificationMeta{\n-\t\t\tReason:  reason,\n-\t\t\tSubject: subject,\n-\t\t},\n-\t}\n-}\n-\n // fetch relationship metadata between this account and another account\n func (c *AccountContext) GetAccountRelationship(other syntax.DID) AccountRelationship {\n \trel, err := c.engine.GetAccountRelationship(c.Ctx, c.Account.Identity.DID, other)\n@@ -322,7 +293,3 @@ func (c *RecordContext) AcknowledgeRecord() {\n func (c *RecordContext) TakedownBlob(cid string) {\n \tc.effects.TakedownBlob(cid)\n }\n-\n-func (c *NotificationContext) Reject() {\n-\tc.effects.Reject()\n-}\n---\nautomod/engine/engine.go\n@@ -296,66 +296,6 @@ func (eng *Engine) ProcessRecordOp(ctx context.Context, op RecordOp) error {\n \treturn nil\n }\n \n-// returns a boolean indicating \"block the event\"\n-// NOTE: this code is unused and should be removed\n-func (eng *Engine) ProcessNotificationEvent(ctx context.Context, senderDID, recipientDID syntax.DID, reason string, subject syntax.ATURI) (bool, error) {\n-\teventProcessCount.WithLabelValues(\"notif\").Inc()\n-\tstart := time.Now()\n-\tdefer func() {\n-\t\tduration := time.Since(start)\n-\t\teventProcessDuration.WithLabelValues(\"notif\").Observe(duration.Seconds())\n-\t}()\n-\n-\t// similar to an HTTP server, we want to recover any panics from rule execution\n-\tdefer func() {\n-\t\tif r := recover(); r != nil {\n-\t\t\teng.Logger.Error(\"automod event execution exception\", \"err\", r, \"sender\", senderDID, \"recipient\", recipientDID)\n-\t\t}\n-\t}()\n-\tvar cancel context.CancelFunc\n-\tctx, cancel = context.WithTimeout(ctx, time.Second*5)\n-\tdefer cancel()\n-\n-\tsenderIdent, err := eng.Directory.LookupDID(ctx, senderDID)\n-\tif err != nil {\n-\t\teventErrorCount.WithLabelValues(\"notif\").Inc()\n-\t\treturn false, fmt.Errorf(\"resolving identity: %w\", err)\n-\t}\n-\tif senderIdent == nil {\n-\t\teventErrorCount.WithLabelValues(\"notif\").Inc()\n-\t\treturn false, fmt.Errorf(\"identity not found for sender DID: %s\", senderDID.String())\n-\t}\n-\n-\trecipientIdent, err := eng.Directory.LookupDID(ctx, recipientDID)\n-\tif err != nil {\n-\t\teventErrorCount.WithLabelValues(\"notif\").Inc()\n-\t\treturn false, fmt.Errorf(\"resolving identity: %w\", err)\n-\t}\n-\tif recipientIdent == nil {\n-\t\teventErrorCount.WithLabelValues(\"notif\").Inc()\n-\t\treturn false, fmt.Errorf(\"identity not found for sender DID: %s\", recipientDID.String())\n-\t}\n-\n-\tsenderMeta, err := eng.GetAccountMeta(ctx, senderIdent)\n-\tif err != nil {\n-\t\teventErrorCount.WithLabelValues(\"notif\").Inc()\n-\t\treturn false, fmt.Errorf(\"failed to fetch account metadata: %w\", err)\n-\t}\n-\trecipientMeta, err := eng.GetAccountMeta(ctx, recipientIdent)\n-\tif err != nil {\n-\t\teventErrorCount.WithLabelValues(\"notif\").Inc()\n-\t\treturn false, fmt.Errorf(\"failed to fetch account metadata: %w\", err)\n-\t}\n-\n-\tnc := NewNotificationContext(ctx, eng, *senderMeta, *recipientMeta, reason, subject)\n-\tif err := eng.Rules.CallNotificationRules(&nc); err != nil {\n-\t\teventErrorCount.WithLabelValues(\"notif\").Inc()\n-\t\treturn false, fmt.Errorf(\"rule execution failed: %w\", err)\n-\t}\n-\teng.CanonicalLogLineNotification(&nc)\n-\treturn nc.effects.RejectEvent, nil\n-}\n-\n // Purge metadata caches for a specific account.\n func (e *Engine) PurgeAccountCaches(ctx context.Context, did syntax.DID) error {\n \te.Logger.Debug(\"purging account caches\", \"did\", did.String())\n@@ -391,14 +331,3 @@ func (e *Engine) CanonicalLogLineRecord(c *RecordContext) {\n \t\t\"recordReports\", len(c.effects.RecordReports),\n \t)\n }\n-\n-func (e *Engine) CanonicalLogLineNotification(c *NotificationContext) {\n-\tc.Logger.Info(\"canonical-event-line\",\n-\t\t\"accountLabels\", c.effects.AccountLabels,\n-\t\t\"accountFlags\", c.effects.AccountFlags,\n-\t\t\"accountTags\", c.effects.AccountTags,\n-\t\t\"accountTakedown\", c.effects.AccountTakedown,\n-\t\t\"accountReports\", len(c.effects.AccountReports),\n-\t\t\"reject\", c.effects.RejectEvent,\n-\t)\n-}\n---\nautomod/engine/ruleset.go\n@@ -18,7 +18,6 @@ type RuleSet struct {\n \tIdentityRules     []IdentityRuleFunc\n \tAccountRules      []AccountRuleFunc\n \tBlobRules         []BlobRuleFunc\n-\tNotificationRules []NotificationRuleFunc\n \tOzoneEventRules   []OzoneEventRuleFunc\n }\n \n@@ -101,16 +100,6 @@ func (r *RuleSet) CallAccountRules(c *AccountContext) error {\n \treturn nil\n }\n \n-func (r *RuleSet) CallNotificationRules(c *NotificationContext) error {\n-\tfor _, f := range r.NotificationRules {\n-\t\terr := f(c)\n-\t\tif err != nil {\n-\t\t\tc.Logger.Error(\"notification rule execution failed\", \"err\", err)\n-\t\t}\n-\t}\n-\treturn nil\n-}\n-\n func (r *RuleSet) CallOzoneEventRules(c *OzoneEventContext) error {\n \tfor _, f := range r.OzoneEventRules {\n \t\terr := f(c)\n---\nautomod/engine/ruletypes.go\n@@ -11,5 +11,4 @@ type RecordRuleFunc = func(c *RecordContext) error\n type PostRuleFunc = func(c *RecordContext, post *appbsky.FeedPost) error\n type ProfileRuleFunc = func(c *RecordContext, profile *appbsky.ActorProfile) error\n type BlobRuleFunc = func(c *RecordContext, blob lexutil.LexBlob, data []byte) error\n-type NotificationRuleFunc = func(c *NotificationContext) error\n type OzoneEventRuleFunc = func(c *OzoneEventContext) error\n---\nautomod/pkg.go\n@@ -18,15 +18,13 @@ type SlackNotifier = engine.SlackNotifier\n type AccountContext = engine.AccountContext\n type RecordContext = engine.RecordContext\n type OzoneEventContext = engine.OzoneEventContext\n-type NotificationContext = engine.NotificationContext\n type RecordOp = engine.RecordOp\n \n type IdentityRuleFunc = engine.IdentityRuleFunc\n type RecordRuleFunc = engine.RecordRuleFunc\n type PostRuleFunc = engine.PostRuleFunc\n type ProfileRuleFunc = engine.ProfileRuleFunc\n type BlobRuleFunc = engine.BlobRuleFunc\n-type NotificationRuleFunc = engine.NotificationRuleFunc\n type OzoneEventRuleFunc = engine.OzoneEventRuleFunc\n \n var (\n---\nautomod/rules/all.go\n@@ -56,9 +56,6 @@ func DefaultRules() automod.RuleSet {\n \t\tBlobRules: []automod.BlobRuleFunc{\n \t\t\t//BlobVerifyRule,\n \t\t},\n-\t\tNotificationRules: []automod.NotificationRuleFunc{\n-\t\t\t// none\n-\t\t},\n \t\tOzoneEventRules: []automod.OzoneEventRuleFunc{\n \t\t\tHarassmentProtectionOzoneEventRule,\n \t\t},\n---\n"}], "ideal": "Title: remove automod \"notifications event\" support\n\nBody: The idea was to integrate the automod framework with other services\r\nwhich do push notifications. This never happened, and this code is\r\ndead/untested, so removing for now.\r\n\r\nThis kind of functionality might be useful (we have lots of interaction\r\nspam!) and could be pulled back in from git history if we ever need it."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "carstore/nonarchive.go\n@@ -75,10 +75,13 @@ func (cs *NonArchivalCarstore) putLastShardCache(ls *commitRefInfo) {\n \n func (cs *NonArchivalCarstore) loadCommitRefInfo(ctx context.Context, user models.Uid) (*commitRefInfo, error) {\n \tvar out commitRefInfo\n-\tif err := cs.db.Find(&out, \"uid = ?\", user).Error; err != nil {\n-\t\treturn nil, err\n+\twat := cs.db.Find(&out, \"uid = ?\", user)\n+\tif wat.Error != nil {\n+\t\treturn nil, wat.Error\n+\t}\n+\tif wat.RowsAffected == 0 {\n+\t\treturn nil, nil\n \t}\n-\n \treturn &out, nil\n }\n \n@@ -95,6 +98,9 @@ func (cs *NonArchivalCarstore) getCommitRefInfo(ctx context.Context, user models\n \tif err != nil {\n \t\treturn nil, err\n \t}\n+\tif lastShard == nil {\n+\t\treturn nil, nil\n+\t}\n \n \tcs.putLastShardCache(lastShard)\n \treturn lastShard, nil\n@@ -119,6 +125,8 @@ func (cs *NonArchivalCarstore) updateLastCommit(ctx context.Context, uid models.\n \treturn nil\n }\n \n+var commitRefZero = commitRefInfo{}\n+\n func (cs *NonArchivalCarstore) NewDeltaSession(ctx context.Context, user models.Uid, since *string) (*DeltaSession, error) {\n \tctx, span := otel.Tracer(\"carstore\").Start(ctx, \"NewSession\")\n \tdefer span.End()\n@@ -130,7 +138,10 @@ func (cs *NonArchivalCarstore) NewDeltaSession(ctx context.Context, user models.\n \t\treturn nil, err\n \t}\n \n-\tif since != nil && *since != lastShard.Rev {\n+\tif lastShard == nil {\n+\t\t// ok, no previous user state to refer to\n+\t\tlastShard = &commitRefZero\n+\t} else if since != nil && *since != lastShard.Rev {\n \t\tcs.log.Warn(\"revision mismatch\", \"commitSince\", since, \"lastRev\", lastShard.Rev, \"err\", ErrRepoBaseMismatch)\n \t}\n \n@@ -213,7 +224,7 @@ func (cs *NonArchivalCarstore) GetUserRepoHead(ctx context.Context, user models.\n \tif err != nil {\n \t\treturn cid.Undef, err\n \t}\n-\tif lastShard.ID == 0 {\n+\tif lastShard == nil || lastShard.ID == 0 {\n \t\treturn cid.Undef, nil\n \t}\n \n@@ -225,7 +236,7 @@ func (cs *NonArchivalCarstore) GetUserRepoRev(ctx context.Context, user models.U\n \tif err != nil {\n \t\treturn \"\", err\n \t}\n-\tif lastShard.ID == 0 {\n+\tif lastShard == nil || lastShard.ID == 0 {\n \t\treturn \"\", nil\n \t}\n \n---\ntesting/integ_test.go\n@@ -3,8 +3,6 @@ package testing\n import (\n \t\"bytes\"\n \t\"context\"\n-\t\"encoding/json\"\n-\t\"fmt\"\n \t\"math/rand\"\n \t\"strings\"\n \t\"testing\"\n@@ -52,13 +50,13 @@ func testRelayBasic(t *testing.T, archive bool) {\n \tdefer evts.Cancel()\n \n \tbob := p1.MustNewUser(t, \"bob.tpds\")\n-\tfmt.Println(\"event 1\")\n+\tt.Log(\"event 1\")\n \te1 := evts.Next()\n \tassert.NotNil(e1.RepoCommit)\n \tassert.Equal(e1.RepoCommit.Repo, bob.DID())\n \n \talice := p1.MustNewUser(t, \"alice.tpds\")\n-\tfmt.Println(\"event 2\")\n+\tt.Log(\"event 2\")\n \te2 := evts.Next()\n \tassert.NotNil(e2.RepoCommit)\n \tassert.Equal(e2.RepoCommit.Repo, alice.DID())\n@@ -69,14 +67,14 @@ func testRelayBasic(t *testing.T, archive bool) {\n \t_ = bp1\n \t_ = ap1\n \n-\tfmt.Println(\"bob:\", bob.DID())\n-\tfmt.Println(\"event 3\")\n+\tt.Log(\"bob:\", bob.DID())\n+\tt.Log(\"event 3\")\n \te3 := evts.Next()\n \tassert.Equal(e3.RepoCommit.Repo, bob.DID())\n \t//assert.Equal(e3.RepoCommit.Ops[0].Kind, \"createRecord\")\n \n-\tfmt.Println(\"alice:\", alice.DID())\n-\tfmt.Println(\"event 4\")\n+\tt.Log(\"alice:\", alice.DID())\n+\tt.Log(\"event 4\")\n \te4 := evts.Next()\n \tassert.Equal(e4.RepoCommit.Repo, alice.DID())\n \t//assert.Equal(e4.RepoCommit.Ops[0].Kind, \"createRecord\")\n@@ -85,7 +83,7 @@ func testRelayBasic(t *testing.T, archive bool) {\n \tpbevts := b1.Events(t, 2)\n \tdefer pbevts.Cancel()\n \n-\tfmt.Println(\"event 5\")\n+\tt.Log(\"event 5\")\n \tpbe1 := pbevts.Next()\n \tassert.Equal(*e3, *pbe1)\n }\n@@ -294,11 +292,11 @@ func TestHandleChange(t *testing.T) {\n \ttime.Sleep(time.Millisecond * 100)\n \n \tinitevt := evts.Next()\n-\tfmt.Println(initevt.RepoCommit)\n+\tt.Log(initevt.RepoCommit)\n \thcevt := evts.Next()\n-\tfmt.Println(hcevt.RepoHandle)\n+\tt.Log(hcevt.RepoHandle)\n \tidevt := evts.Next()\n-\tfmt.Println(idevt.RepoIdentity)\n+\tt.Log(idevt.RepoIdentity)\n }\n \n func TestAccountEvent(t *testing.T) {\n@@ -336,46 +334,46 @@ func TestAccountEvent(t *testing.T) {\n \ttime.Sleep(time.Millisecond * 100)\n \n \tinitevt := evts.Next()\n-\tfmt.Println(initevt.RepoCommit)\n+\tt.Log(initevt.RepoCommit)\n \n \t// Takedown\n \tacevt := evts.Next()\n-\tfmt.Println(acevt.RepoAccount)\n+\tt.Log(acevt.RepoAccount)\n \tassert.Equal(acevt.RepoAccount.Did, u.DID())\n \tassert.Equal(acevt.RepoAccount.Active, false)\n \tassert.Equal(*acevt.RepoAccount.Status, events.AccountStatusTakendown)\n \n \t// Reactivate\n \tacevt = evts.Next()\n-\tfmt.Println(acevt.RepoAccount)\n+\tt.Log(acevt.RepoAccount)\n \tassert.Equal(acevt.RepoAccount.Did, u.DID())\n \tassert.Equal(acevt.RepoAccount.Active, true)\n \tassert.Equal(*acevt.RepoAccount.Status, events.AccountStatusActive)\n \n \t// Deactivate\n \tacevt = evts.Next()\n-\tfmt.Println(acevt.RepoAccount)\n+\tt.Log(acevt.RepoAccount)\n \tassert.Equal(acevt.RepoAccount.Did, u.DID())\n \tassert.Equal(acevt.RepoAccount.Active, false)\n \tassert.Equal(*acevt.RepoAccount.Status, events.AccountStatusDeactivated)\n \n \t// Reactivate\n \tacevt = evts.Next()\n-\tfmt.Println(acevt.RepoAccount)\n+\tt.Log(acevt.RepoAccount)\n \tassert.Equal(acevt.RepoAccount.Did, u.DID())\n \tassert.Equal(acevt.RepoAccount.Active, true)\n \tassert.Equal(*acevt.RepoAccount.Status, events.AccountStatusActive)\n \n \t// Suspend\n \tacevt = evts.Next()\n-\tfmt.Println(acevt.RepoAccount)\n+\tt.Log(acevt.RepoAccount)\n \tassert.Equal(acevt.RepoAccount.Did, u.DID())\n \tassert.Equal(acevt.RepoAccount.Active, false)\n \tassert.Equal(*acevt.RepoAccount.Status, events.AccountStatusSuspended)\n \n \t// Reactivate\n \tacevt = evts.Next()\n-\tfmt.Println(acevt.RepoAccount)\n+\tt.Log(acevt.RepoAccount)\n \tassert.Equal(acevt.RepoAccount.Did, u.DID())\n \tassert.Equal(acevt.RepoAccount.Active, true)\n \tassert.Equal(*acevt.RepoAccount.Status, events.AccountStatusActive)\n@@ -387,7 +385,7 @@ func TestAccountEvent(t *testing.T) {\n \ttime.Sleep(time.Millisecond * 20)\n \n \tacevt = evts.Next()\n-\tfmt.Println(acevt.RepoAccount)\n+\tt.Log(acevt.RepoAccount)\n \tassert.Equal(acevt.RepoAccount.Did, u.DID())\n \tassert.Equal(acevt.RepoAccount.Active, false)\n \tassert.Equal(*acevt.RepoAccount.Status, events.AccountStatusTakendown)\n@@ -399,7 +397,7 @@ func TestAccountEvent(t *testing.T) {\n \ttime.Sleep(time.Millisecond * 20)\n \n \tacevt = evts.Next()\n-\tfmt.Println(acevt.RepoAccount)\n+\tt.Log(acevt.RepoAccount)\n \tassert.Equal(acevt.RepoAccount.Did, u.DID())\n \tassert.Equal(acevt.RepoAccount.Active, true)\n \tassert.Equal(*acevt.RepoAccount.Status, events.AccountStatusActive)\n@@ -469,11 +467,6 @@ func testRelayTakedown(t *testing.T, archive bool) {\n \tassert.Equal(alice.did, last.RepoCommit.Repo)\n }\n \n-func jsonPrint(v any) {\n-\tb, _ := json.Marshal(v)\n-\tfmt.Println(string(b))\n-}\n-\n func commitFromSlice(t *testing.T, slice []byte, rcid cid.Cid) *repo.SignedCommit {\n \tcarr, err := car.NewCarReader(bytes.NewReader(slice))\n \tif err != nil {\n@@ -560,11 +553,11 @@ func TestRelayHandleEmptyEvent(t *testing.T) {\n \tdefer evts.Cancel()\n \n \tbob := p1.MustNewUser(t, \"bob.tpds\")\n-\tfmt.Println(\"event 1\")\n+\tt.Log(\"event 1\")\n \te1 := evts.Next()\n \tassert.NotNil(e1.RepoCommit)\n \tassert.Equal(e1.RepoCommit.Repo, bob.DID())\n-\tfmt.Println(e1.RepoCommit.Ops[0])\n+\tt.Log(e1.RepoCommit.Ops[0])\n \n \tctx := context.TODO()\n \trm := p1.server.Repoman()\n@@ -573,7 +566,7 @@ func TestRelayHandleEmptyEvent(t *testing.T) {\n \t}\n \n \te2 := evts.Next()\n-\t//fmt.Println(e2.RepoCommit.Ops[0])\n+\t//t.Log(e2.RepoCommit.Ops[0])\n \tassert.Equal(len(e2.RepoCommit.Ops), 0)\n \tassert.Equal(e2.RepoCommit.Repo, bob.DID())\n }\n---\n"}], "ideal": "Title: narelay: drop noisy warning on no prior user data\n\nBody: this fixed like 90% of WARN messages on a narelay I was running"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/bgs.go\n@@ -140,7 +140,14 @@ func DefaultBGSConfig() *BGSConfig {\n }\n \n func NewBGS(db *gorm.DB, ix *indexer.Indexer, repoman *repomgr.RepoManager, evtman *events.EventManager, didr did.Resolver, rf *indexer.RepoFetcher, hr api.HandleResolver, config *BGSConfig) (*BGS, error) {\n-\n+\tlogger := slog.Default().With(\"system\", \"bgs\")\n+\t// TODO: 2025-02-04 hopefully about a month from now this migration will have run everywhere and it can be deleted.\n+\terr := db.Transaction(func(tx *gorm.DB) error {\n+\t\treturn fixupDupPDSRows(tx, logger)\n+\t})\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n \tif config == nil {\n \t\tconfig = DefaultBGSConfig()\n \t}\n@@ -169,7 +176,7 @@ func NewBGS(db *gorm.DB, ix *indexer.Indexer, repoman *repomgr.RepoManager, evtm\n \n \t\tuserCache: uc,\n \n-\t\tlog: slog.Default().With(\"system\", \"bgs\"),\n+\t\tlog: logger,\n \t}\n \n \tix.CreateExternalUser = bgs.createExternalUser\n@@ -202,6 +209,70 @@ func NewBGS(db *gorm.DB, ix *indexer.Indexer, repoman *repomgr.RepoManager, evtm\n \treturn bgs, nil\n }\n \n+// TODO: 2025-02-04 hopefully about a month from now this migration will have run everywhere and it can be deleted.\n+// TODO: check for INFO \"no pds dup rows found\" on all deploys\n+func fixupDupPDSRows(db *gorm.DB, logger *slog.Logger) error {\n+\trows, err := db.Raw(\"SELECT id, host FROM pds\").Rows()\n+\tif err != nil {\n+\t\tlogger.Warn(\"could not list PDS rows; assume blank db\", \"err\", err)\n+\t\treturn nil\n+\t}\n+\thostCounts := make(map[string][]uint)\n+\tmaxPDSId := uint(0)\n+\tmaxHostCount := 0\n+\tfor rows.Next() {\n+\t\tvar pdsId uint\n+\t\tvar host string\n+\t\tif err := rows.Scan(&pdsId, &host); err != nil {\n+\t\t\treturn fmt.Errorf(\"pds sql row err, %w\", err)\n+\t\t}\n+\t\tidlist := hostCounts[host]\n+\t\tidlist = append(idlist, pdsId)\n+\t\tcount := len(idlist)\n+\t\tif count > maxHostCount {\n+\t\t\tmaxHostCount = count\n+\t\t}\n+\t\thostCounts[host] = idlist\n+\t\tif pdsId > maxPDSId {\n+\t\t\tmaxPDSId = pdsId\n+\t\t}\n+\t}\n+\tif maxHostCount <= 1 {\n+\t\tlogger.Info(\"no pds dup rows found\")\n+\t\treturn nil\n+\t}\n+\tfor host, idlist := range hostCounts {\n+\t\tif len(idlist) > 1 {\n+\t\t\tlogger.Info(\"dup PDS\", \"host\", host, \"count\", len(idlist))\n+\t\t\tminPDSId := idlist[0]\n+\t\t\tfor _, otherid := range idlist[1:] {\n+\t\t\t\tif otherid < minPDSId {\n+\t\t\t\t\tminPDSId = otherid\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tfor _, xPDSId := range idlist {\n+\t\t\t\tif xPDSId == minPDSId {\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tlogger.Info(\"dup PDS\", \"host\", host, \"from\", xPDSId, \"to\", minPDSId)\n+\t\t\t\terr = db.Exec(\"UPDATE users SET pds = ? WHERE pds = ?\", minPDSId, xPDSId).Error\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn fmt.Errorf(\"failed to update user pds %d -> %d: %w\", xPDSId, minPDSId, err)\n+\t\t\t\t}\n+\t\t\t\terr = db.Exec(\"UPDATE actor_infos SET pds = ? WHERE pds = ?\", minPDSId, xPDSId).Error\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn fmt.Errorf(\"failed to update actor_infos pds %d -> %d: %w\", xPDSId, minPDSId, err)\n+\t\t\t\t}\n+\t\t\t\terr = db.Exec(\"DELETE FROM pds WHERE id = ?\", xPDSId).Error\n+\t\t\t\tif err != nil {\n+\t\t\t\t\treturn fmt.Errorf(\"failed to delete pds %d: %w\", xPDSId, err)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\treturn nil\n+}\n+\n func (bgs *BGS) StartMetrics(listen string) error {\n \thttp.Handle(\"/metrics\", promhttp.Handler())\n \treturn http.ListenAndServe(listen, nil)\n---\nmodels/models.go\n@@ -104,7 +104,7 @@ type FollowRecord struct {\n type PDS struct {\n \tgorm.Model\n \n-\tHost       string\n+\tHost       string `gorm:\"unique\"`\n \tDid        string\n \tSSL        bool\n \tCursor     int64\n---\n"}], "ideal": "Title: make PDS table unique on host name\n\nBody: fix old data that had dups on PDS host name"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/hepa/main.go\n@@ -261,7 +261,6 @@ var runCmd = &cli.Command{\n \t\t\tdir,\n \t\t\tConfig{\n \t\t\t\tLogger:              logger,\n-\t\t\t\tRelayHost:           cctx.String(\"atp-relay-host\"), // DEPRECATED\n \t\t\t\tBskyHost:            cctx.String(\"atp-bsky-host\"),\n \t\t\t\tOzoneHost:           cctx.String(\"atp-ozone-host\"),\n \t\t\t\tOzoneDID:            cctx.String(\"ozone-did\"),\n@@ -276,7 +275,6 @@ var runCmd = &cli.Command{\n \t\t\t\tAbyssPassword:       cctx.String(\"abyss-password\"),\n \t\t\t\tRatelimitBypass:     cctx.String(\"ratelimit-bypass\"),\n \t\t\t\tRulesetName:         cctx.String(\"ruleset\"),\n-\t\t\t\tFirehoseParallelism: cctx.Int(\"firehose-parallelism\"), // DEPRECATED\n \t\t\t\tPreScreenHost:       cctx.String(\"prescreen-host\"),\n \t\t\t\tPreScreenToken:      cctx.String(\"prescreen-token\"),\n \t\t\t\tReportDupePeriod:    cctx.Duration(\"report-dupe-period\"),\n@@ -360,24 +358,22 @@ func configEphemeralServer(cctx *cli.Context) (*Server, error) {\n \treturn NewServer(\n \t\tdir,\n \t\tConfig{\n-\t\t\tLogger:              logger,\n-\t\t\tRelayHost:           cctx.String(\"atp-relay-host\"),\n-\t\t\tBskyHost:            cctx.String(\"atp-bsky-host\"),\n-\t\t\tOzoneHost:           cctx.String(\"atp-ozone-host\"),\n-\t\t\tOzoneDID:            cctx.String(\"ozone-did\"),\n-\t\t\tOzoneAdminToken:     cctx.String(\"ozone-admin-token\"),\n-\t\t\tPDSHost:             cctx.String(\"atp-pds-host\"),\n-\t\t\tPDSAdminToken:       cctx.String(\"pds-admin-token\"),\n-\t\t\tSetsFileJSON:        cctx.String(\"sets-json-path\"),\n-\t\t\tRedisURL:            cctx.String(\"redis-url\"),\n-\t\t\tHiveAPIToken:        cctx.String(\"hiveai-api-token\"),\n-\t\t\tAbyssHost:           cctx.String(\"abyss-host\"),\n-\t\t\tAbyssPassword:       cctx.String(\"abyss-password\"),\n-\t\t\tRatelimitBypass:     cctx.String(\"ratelimit-bypass\"),\n-\t\t\tRulesetName:         cctx.String(\"ruleset\"),\n-\t\t\tFirehoseParallelism: cctx.Int(\"firehose-parallelism\"),\n-\t\t\tPreScreenHost:       cctx.String(\"prescreen-host\"),\n-\t\t\tPreScreenToken:      cctx.String(\"prescreen-token\"),\n+\t\t\tLogger:          logger,\n+\t\t\tBskyHost:        cctx.String(\"atp-bsky-host\"),\n+\t\t\tOzoneHost:       cctx.String(\"atp-ozone-host\"),\n+\t\t\tOzoneDID:        cctx.String(\"ozone-did\"),\n+\t\t\tOzoneAdminToken: cctx.String(\"ozone-admin-token\"),\n+\t\t\tPDSHost:         cctx.String(\"atp-pds-host\"),\n+\t\t\tPDSAdminToken:   cctx.String(\"pds-admin-token\"),\n+\t\t\tSetsFileJSON:    cctx.String(\"sets-json-path\"),\n+\t\t\tRedisURL:        cctx.String(\"redis-url\"),\n+\t\t\tHiveAPIToken:    cctx.String(\"hiveai-api-token\"),\n+\t\t\tAbyssHost:       cctx.String(\"abyss-host\"),\n+\t\t\tAbyssPassword:   cctx.String(\"abyss-password\"),\n+\t\t\tRatelimitBypass: cctx.String(\"ratelimit-bypass\"),\n+\t\t\tRulesetName:     cctx.String(\"ruleset\"),\n+\t\t\tPreScreenHost:   cctx.String(\"prescreen-host\"),\n+\t\t\tPreScreenToken:  cctx.String(\"prescreen-token\"),\n \t\t},\n \t)\n }\n---\ncmd/hepa/server.go\n@@ -6,7 +6,6 @@ import (\n \t\"log/slog\"\n \t\"net/http\"\n \t\"os\"\n-\t\"strings\"\n \t\"time\"\n \n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n@@ -30,14 +29,11 @@ type Server struct {\n \tEngine      *automod.Engine\n \tRedisClient *redis.Client\n \n-\trelayHost           string // DEPRECATED\n-\tfirehoseParallelism int    // DEPRECATED\n-\tlogger              *slog.Logger\n+\tlogger *slog.Logger\n }\n \n type Config struct {\n \tLogger              *slog.Logger\n-\tRelayHost           string // DEPRECATED\n \tBskyHost            string\n \tOzoneHost           string\n \tOzoneDID            string\n@@ -52,7 +48,6 @@ type Config struct {\n \tAbyssPassword       string\n \tRulesetName         string\n \tRatelimitBypass     string\n-\tFirehoseParallelism int // DEPRECATED\n \tPreScreenHost       string\n \tPreScreenToken      string\n \tReportDupePeriod    time.Duration\n@@ -69,11 +64,6 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\t}))\n \t}\n \n-\trelayws := config.RelayHost\n-\tif !strings.HasPrefix(relayws, \"ws\") {\n-\t\treturn nil, fmt.Errorf(\"specified relay host must include 'ws://' or 'wss://'\")\n-\t}\n-\n \tvar ozoneClient *xrpc.Client\n \tif config.OzoneAdminToken != \"\" && config.OzoneDID != \"\" {\n \t\tozoneClient = &xrpc.Client{\n@@ -211,7 +201,7 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\tbskyClient.Headers[\"x-ratelimit-bypass\"] = config.RatelimitBypass\n \t}\n \tblobClient := util.RobustHTTPClient()\n-\tengine := automod.Engine{\n+\teng := automod.Engine{\n \t\tLogger:      logger,\n \t\tDirectory:   dir,\n \t\tCounters:    counters,\n@@ -233,11 +223,9 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t}\n \n \ts := &Server{\n-\t\trelayHost:           config.RelayHost,\n-\t\tfirehoseParallelism: config.FirehoseParallelism,\n-\t\tlogger:              logger,\n-\t\tEngine:              &engine,\n-\t\tRedisClient:         rdb,\n+\t\tlogger:      logger,\n+\t\tEngine:      &eng,\n+\t\tRedisClient: rdb,\n \t}\n \n \treturn s, nil\n---\n"}], "ideal": "Title: hepa: remove deprecated/unused config vars\n\nBody: this is cleanup from an earlier refactor to move firehose consumption over to a separate package."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/admin.go\n@@ -116,6 +116,51 @@ func (bgs *BGS) handleAdminReverseTakedown(e echo.Context) error {\n \treturn nil\n }\n \n+type ListTakedownsResponse struct {\n+\tDids   []string `json:\"dids\"`\n+\tCursor int64    `json:\"cursor,omitempty\"`\n+}\n+\n+func (bgs *BGS) handleAdminListRepoTakeDowns(e echo.Context) error {\n+\tctx := e.Request().Context()\n+\thaveMinId := false\n+\tminId := int64(-1)\n+\tqmin := e.QueryParam(\"cursor\")\n+\tif qmin != \"\" {\n+\t\ttmin, err := strconv.ParseInt(qmin, 10, 64)\n+\t\tif err != nil {\n+\t\t\treturn &echo.HTTPError{Code: 400, Message: \"bad cursor\"}\n+\t\t}\n+\t\tminId = tmin\n+\t\thaveMinId = true\n+\t}\n+\tlimit := 1000\n+\twat := bgs.db.Model(User{}).WithContext(ctx).Select(\"id\", \"did\").Where(\"taken_down = TRUE\")\n+\tif haveMinId {\n+\t\twat = wat.Where(\"id > ?\", minId)\n+\t}\n+\t//var users []User\n+\trows, err := wat.Order(\"id\").Limit(limit).Rows()\n+\tif err != nil {\n+\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"oops\").WithInternal(err)\n+\t}\n+\tvar out ListTakedownsResponse\n+\tfor rows.Next() {\n+\t\tvar id int64\n+\t\tvar did string\n+\t\terr := rows.Scan(&id, &did)\n+\t\tif err != nil {\n+\t\t\treturn echo.NewHTTPError(http.StatusInternalServerError, \"oops\").WithInternal(err)\n+\t\t}\n+\t\tout.Dids = append(out.Dids, did)\n+\t\tout.Cursor = id\n+\t}\n+\tif len(out.Dids) < limit {\n+\t\tout.Cursor = 0\n+\t}\n+\treturn e.JSON(200, out)\n+}\n+\n func (bgs *BGS) handleAdminGetUpstreamConns(e echo.Context) error {\n \treturn e.JSON(200, bgs.slurper.GetActiveList())\n }\n---\nbgs/bgs.go\n@@ -395,6 +395,7 @@ func (bgs *BGS) StartWithListener(listen net.Listener) error {\n \t// Repo-related Admin API\n \tadmin.POST(\"/repo/takeDown\", bgs.handleAdminTakeDownRepo)\n \tadmin.POST(\"/repo/reverseTakedown\", bgs.handleAdminReverseTakedown)\n+\tadmin.GET(\"/repo/takedowns\", bgs.handleAdminListRepoTakeDowns)\n \tadmin.POST(\"/repo/compact\", bgs.handleAdminCompactRepo)\n \tadmin.POST(\"/repo/compactAll\", bgs.handleAdminCompactAllRepos)\n \tadmin.POST(\"/repo/reset\", bgs.handleAdminResetRepo)\n---\n"}], "ideal": "Title: add GET /admin/repo/takedowns\n\nBody: API gap, we could add a repo takedown, and repeal it, but we couldn't list what was active"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/admin.go\n@@ -264,6 +264,9 @@ func (bgs *BGS) handleBlockPDS(e echo.Context) error {\n \t\treturn err\n \t}\n \n+\t// don't care if this errors, but we should try to disconnect something we just blocked\n+\t_ = bgs.slurper.KillUpstreamConnection(host, false)\n+\n \treturn e.JSON(200, map[string]any{\n \t\t\"success\": \"true\",\n \t})\n---\nbgs/fedmgr.go\n@@ -745,6 +745,7 @@ func (s *Slurper) KillUpstreamConnection(host string, block bool) error {\n \t\treturn fmt.Errorf(\"killing connection %q: %w\", host, ErrNoActiveConnection)\n \t}\n \tac.cancel()\n+\t// cleanup in the run thread subscribeWithRedialer() will delete(s.active, host)\n \n \tif block {\n \t\tif err := s.db.Model(models.PDS{}).Where(\"id = ?\", ac.pds.ID).UpdateColumn(\"blocked\", true).Error; err != nil {\n---\n"}], "ideal": "Title: disconnect a pds when we block it\n\nBody: when we /admin/pds/block a PDS, also try to disconnect from it at that time"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/goat/repo.go\n@@ -18,6 +18,7 @@ import (\n \t\"github.com/bluesky-social/indigo/repo\"\n \t\"github.com/bluesky-social/indigo/util\"\n \t\"github.com/bluesky-social/indigo/xrpc\"\n+\n \t\"github.com/ipfs/go-cid\"\n \tcbor \"github.com/ipfs/go-ipld-cbor\"\n \tipld \"github.com/ipfs/go-ipld-format\"\n@@ -117,6 +118,10 @@ func runRepoExport(cctx *cli.Context) error {\n \t\treturn fmt.Errorf(\"no PDS endpoint for identity\")\n \t}\n \n+\t// set longer timeout, for large CAR files\n+\txrpcc.Client = util.RobustHTTPClient()\n+\txrpcc.Client.Timeout = 600 * time.Second\n+\n \tcarPath := cctx.String(\"output\")\n \tif carPath == \"\" {\n \t\t// NOTE: having the rev in the the path might be nice\n---\n"}], "ideal": "Title: goat: longer timeout for CAR export\n\nBody: Closes: https://github.com/bluesky-social/indigo/issues/896\r\n\r\nSuspect repo exports to crop up in other places, but can start with this here."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": ".github/workflows/golang.yml\n@@ -19,7 +19,7 @@ jobs:\n       - name: Set up Go tooling\n         uses: actions/setup-go@v4\n         with:\n-          go-version: \"1.22\"\n+          go-version: \"1.23\"\n       - name: Build\n         run: make build\n       - name: Test\n@@ -32,6 +32,6 @@ jobs:\n       - name: Set up Go tooling\n         uses: actions/setup-go@v4\n         with:\n-          go-version: \"1.22\"\n+          go-version: \"1.23\"\n       - name: Lint\n         run: make lint\n---\nbgs/bgs.go\n@@ -662,7 +662,7 @@ func (bgs *BGS) EventsHandler(c echo.Context) error {\n \t\t\t\t}\n \n \t\t\t\tif err := conn.WriteControl(websocket.PingMessage, []byte{}, time.Now().Add(5*time.Second)); err != nil {\n-\t\t\t\t\tbgs.log.Warn(\"failed to ping client: %s\", err)\n+\t\t\t\t\tbgs.log.Warn(\"failed to ping client\", \"err\", err)\n \t\t\t\t\tcancel()\n \t\t\t\t\treturn\n \t\t\t\t}\n@@ -687,7 +687,7 @@ func (bgs *BGS) EventsHandler(c echo.Context) error {\n \t\tfor {\n \t\t\t_, _, err := conn.ReadMessage()\n \t\t\tif err != nil {\n-\t\t\t\tbgs.log.Warn(\"failed to read message from client: %s\", err)\n+\t\t\t\tbgs.log.Warn(\"failed to read message from client\", \"err\", err)\n \t\t\t\tcancel()\n \t\t\t\treturn\n \t\t\t}\n---\ncarstore/nonarchive.go\n@@ -131,7 +131,7 @@ func (cs *NonArchivalCarstore) NewDeltaSession(ctx context.Context, user models.\n \t}\n \n \tif since != nil && *since != lastShard.Rev {\n-\t\tcs.log.Warn(\"revision mismatch: %s != %s: %s\", *since, lastShard.Rev, ErrRepoBaseMismatch)\n+\t\tcs.log.Warn(\"revision mismatch\", \"commitSince\", since, \"lastRev\", lastShard.Rev, \"err\", ErrRepoBaseMismatch)\n \t}\n \n \treturn &DeltaSession{\n---\ncmd/beemo/Dockerfile\n@@ -3,7 +3,7 @@\n #   podman build -f ./cmd/beemo/Dockerfile -t beemo .\n \n ### Compile stage\n-FROM golang:1.22-alpine3.19 AS build-env\n+FROM golang:1.23-alpine3.20 AS build-env\n RUN apk add --no-cache build-base make git\n \n ADD . /dockerbuild\n@@ -15,7 +15,7 @@ RUN GIT_VERSION=$(git describe --tags --long --always) && \\\n     go build -tags timetzdata -o /beemo ./cmd/beemo\n \n ### Run stage\n-FROM alpine:3.19\n+FROM alpine:3.20\n \n RUN apk add --no-cache --update dumb-init ca-certificates\n ENTRYPOINT [\"dumb-init\", \"--\"]\n---\ncmd/bigsky/Dockerfile\n@@ -3,7 +3,7 @@\n #   podman build -f ./cmd/bigsky/Dockerfile -t bigsky .\n \n ### Compile stage\n-FROM golang:1.22-alpine3.19 AS build-env\n+FROM golang:1.23-alpine3.20 AS build-env\n RUN apk add --no-cache build-base make git\n \n ADD . /dockerbuild\n@@ -26,7 +26,7 @@ RUN yarn install --frozen-lockfile\n RUN yarn build\n \n ### Run stage\n-FROM alpine:3.19\n+FROM alpine:3.20\n \n RUN apk add --no-cache --update dumb-init ca-certificates runit\n ENTRYPOINT [\"dumb-init\", \"--\"]\n---\ncmd/hepa/Dockerfile\n@@ -3,7 +3,7 @@\n #   podman build -f ./cmd/hepa/Dockerfile -t hepa .\n \n ### Compile stage\n-FROM golang:1.22-alpine3.19 AS build-env\n+FROM golang:1.23-alpine3.20 AS build-env\n RUN apk add --no-cache build-base make git\n \n ADD . /dockerbuild\n@@ -15,7 +15,7 @@ RUN GIT_VERSION=$(git describe --tags --long --always) && \\\n     go build -tags timetzdata -o /hepa ./cmd/hepa\n \n ### Run stage\n-FROM alpine:3.19\n+FROM alpine:3.20\n \n RUN apk add --no-cache --update dumb-init ca-certificates\n ENTRYPOINT [\"dumb-init\", \"--\"]\n---\ncmd/palomar/Dockerfile\n@@ -3,7 +3,7 @@\n #   podman build -f ./cmd/palomar/Dockerfile -t palomar .\n \n ### Compile stage\n-FROM golang:1.22-alpine3.19 AS build-env\n+FROM golang:1.23-alpine3.20 AS build-env\n RUN apk add --no-cache build-base make git\n \n ADD . /dockerbuild\n@@ -15,7 +15,7 @@ RUN GIT_VERSION=$(git describe --tags --long --always) && \\\n     go build -tags timetzdata -o /palomar ./cmd/palomar\n \n ### Run stage\n-FROM alpine:3.19\n+FROM alpine:3.20\n \n RUN apk add --no-cache --update dumb-init ca-certificates\n ENTRYPOINT [\"dumb-init\", \"--\"]\n---\ncmd/rainbow/Dockerfile\n@@ -1,4 +1,4 @@\n-FROM golang:1.22-bullseye AS build-env\n+FROM golang:1.23-bullseye AS build-env\n \n ENV DEBIAN_FRONTEND=noninteractive\n ENV TZ=Etc/UTC\n---\ncmd/sonar/Dockerfile\n@@ -1,5 +1,5 @@\n # Stage 1: Build the Go binary\n-FROM golang:1.22-alpine3.19 AS builder\n+FROM golang:1.23-alpine3.20 AS builder\n \n # Install SSL ca certificates.\n RUN apk update && apk add --no-cache ca-certificates && update-ca-certificates\n---\ncmd/supercollider/Dockerfile\n@@ -1,5 +1,5 @@\n # Stage 1: Build the Go binary\n-FROM golang:1.22-alpine3.18 AS builder\n+FROM golang:1.23-alpine3.20 AS builder\n \n # Create a directory for the application\n WORKDIR /app\n---\ngo.mod\n@@ -1,6 +1,6 @@\n module github.com/bluesky-social/indigo\n \n-go 1.22\n+go 1.23\n \n require (\n \tcontrib.go.opencensus.io/exporter/prometheus v0.4.2\n---\n"}], "ideal": "Title: bump golang version to 1.23; fix slog syntax issues\n\nBody: This is just periodic maintenance, there isn't anything specific in 1.23 we want/need.\r\n\r\ngo v1.24 is expected in February 2025; we usually wait a month or two before upgrading (though we didn't get around to 1.23 until now).\r\n\r\nThe newer `go vet` turned up some slog syntax issues."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/consumer/firehose.go\n@@ -144,9 +144,9 @@ func (fc *FirehoseConsumer) HandleRepoCommit(ctx context.Context, evt *comatprot\n \n \tfor _, op := range evt.Ops {\n \t\tlogger = logger.With(\"eventKind\", op.Action, \"path\", op.Path)\n-\t\tcollection, rkey, err := splitRepoPath(op.Path)\n+\t\tcollection, rkey, err := syntax.ParseRepoPath(op.Path)\n \t\tif err != nil {\n-\t\t\tlogger.Error(\"invalid path in repo op\")\n+\t\t\tlogger.Error(\"invalid path in repo op\", \"err\", err)\n \t\t\treturn nil\n \t\t}\n \n---\nautomod/consumer/util.go\n@@ -1,25 +0,0 @@\n-package consumer\n-\n-import (\n-\t\"fmt\"\n-\t\"strings\"\n-\n-\t\"github.com/bluesky-social/indigo/atproto/syntax\"\n-)\n-\n-// TODO: move this to a \"ParsePath\" helper in syntax package?\n-func splitRepoPath(path string) (syntax.NSID, syntax.RecordKey, error) {\n-\tparts := strings.SplitN(path, \"/\", 3)\n-\tif len(parts) != 2 {\n-\t\treturn \"\", \"\", fmt.Errorf(\"invalid record path: %s\", path)\n-\t}\n-\tcollection, err := syntax.ParseNSID(parts[0])\n-\tif err != nil {\n-\t\treturn \"\", \"\", err\n-\t}\n-\trkey, err := syntax.ParseRecordKey(parts[1])\n-\tif err != nil {\n-\t\treturn \"\", \"\", err\n-\t}\n-\treturn collection, rkey, nil\n-}\n---\ncmd/beemo/firehose_consumer.go\n@@ -7,7 +7,6 @@ import (\n \t\"log/slog\"\n \t\"net/http\"\n \t\"net/url\"\n-\t\"strings\"\n \n \tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n@@ -60,23 +59,6 @@ func RunFirehoseConsumer(ctx context.Context, logger *slog.Logger, relayHost str\n \treturn events.HandleRepoStream(ctx, con, scheduler, logger)\n }\n \n-// TODO: move this to a \"ParsePath\" helper in syntax package?\n-func splitRepoPath(path string) (syntax.NSID, syntax.RecordKey, error) {\n-\tparts := strings.SplitN(path, \"/\", 3)\n-\tif len(parts) != 2 {\n-\t\treturn \"\", \"\", fmt.Errorf(\"invalid record path: %s\", path)\n-\t}\n-\tcollection, err := syntax.ParseNSID(parts[0])\n-\tif err != nil {\n-\t\treturn \"\", \"\", err\n-\t}\n-\trkey, err := syntax.ParseRecordKey(parts[1])\n-\tif err != nil {\n-\t\treturn \"\", \"\", err\n-\t}\n-\treturn collection, rkey, nil\n-}\n-\n // NOTE: for now, this function basically never errors, just logs and returns nil. Should think through error processing better.\n func HandleRepoCommit(ctx context.Context, logger *slog.Logger, evt *comatproto.SyncSubscribeRepos_Commit, postCallback func(context.Context, syntax.DID, syntax.RecordKey, appbsky.FeedPost) error) error {\n \n@@ -102,7 +84,7 @@ func HandleRepoCommit(ctx context.Context, logger *slog.Logger, evt *comatproto.\n \n \tfor _, op := range evt.Ops {\n \t\tlogger = logger.With(\"eventKind\", op.Action, \"path\", op.Path)\n-\t\tcollection, rkey, err := splitRepoPath(op.Path)\n+\t\tcollection, rkey, err := syntax.ParseRepoPath(op.Path)\n \t\tif err != nil {\n \t\t\tlogger.Error(\"invalid path in repo op\")\n \t\t\treturn nil\n---\ncmd/goat/firehose.go\n@@ -133,23 +133,6 @@ func runFirehose(cctx *cli.Context) error {\n \treturn events.HandleRepoStream(ctx, con, scheduler, nil)\n }\n \n-// TODO: move this to a \"ParsePath\" helper in syntax package?\n-func splitRepoPath(path string) (syntax.NSID, syntax.RecordKey, error) {\n-\tparts := strings.SplitN(path, \"/\", 3)\n-\tif len(parts) != 2 {\n-\t\treturn \"\", \"\", fmt.Errorf(\"invalid record path: %s\", path)\n-\t}\n-\tcollection, err := syntax.ParseNSID(parts[0])\n-\tif err != nil {\n-\t\treturn \"\", \"\", err\n-\t}\n-\trkey, err := syntax.ParseRecordKey(parts[1])\n-\tif err != nil {\n-\t\treturn \"\", \"\", err\n-\t}\n-\treturn collection, rkey, nil\n-}\n-\n func (gfc *GoatFirehoseConsumer) handleIdentityEvent(ctx context.Context, evt *comatproto.SyncSubscribeRepos_Identity) error {\n \tout := make(map[string]interface{})\n \tout[\"type\"] = \"identity\"\n@@ -229,7 +212,7 @@ func (gfc *GoatFirehoseConsumer) handleCommitEventOps(ctx context.Context, evt *\n \t}\n \n \tfor _, op := range evt.Ops {\n-\t\tcollection, rkey, err := splitRepoPath(op.Path)\n+\t\tcollection, rkey, err := syntax.ParseRepoPath(op.Path)\n \t\tif err != nil {\n \t\t\tlogger.Error(\"invalid path in repo op\", \"eventKind\", op.Action, \"path\", op.Path)\n \t\t\treturn nil\n---\n"}], "ideal": "Title: use syntax.ParseRepoPath when appropriate\n\nBody: This helper was added recently. Rip out old copy-pasta versions and start actually using it."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/goat/blob.go\n@@ -28,6 +28,10 @@ var cmdBlob = &cli.Command{\n \t\t\t\t\tAliases: []string{\"o\"},\n \t\t\t\t\tUsage:   \"directory to store blobs in\",\n \t\t\t\t},\n+\t\t\t\t&cli.StringFlag{\n+\t\t\t\t\tName:    \"pds-host\",\n+\t\t\t\t\tUsage:   \"URL of the PDS to export blobs from (overrides DID doc)\",\n+\t\t\t\t},\n \t\t\t},\n \t\t\tAction: runBlobExport,\n \t\t},\n@@ -73,9 +77,14 @@ func runBlobExport(cctx *cli.Context) error {\n \t\treturn err\n \t}\n \n+\tpdsHost := cctx.String(\"pds-host\")\n+\tif pdsHost == \"\" {\n+\t\tpdsHost = ident.PDSEndpoint()\n+\t}\n+\n \t// create a new API client to connect to the account's PDS\n \txrpcc := xrpc.Client{\n-\t\tHost: ident.PDSEndpoint(),\n+\t\tHost: pdsHost,\n \t}\n \tif xrpcc.Host == \"\" {\n \t\treturn fmt.Errorf(\"no PDS endpoint for identity\")\n---\n"}], "ideal": "Title: Add PDS host argument to blob export\n\nBody: This PR introduces the `--pds-host` argument to the `blob export` command chain.\r\n\r\nThis was needed in order to export the blobs from an old PDS when by DID document was pointing to the new one already."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/goat/account.go\n@@ -37,6 +37,11 @@ var cmdAccount = &cli.Command{\n \t\t\t\t\tUsage:    \"password (app password recommended)\",\n \t\t\t\t\tEnvVars:  []string{\"ATP_AUTH_PASSWORD\"},\n \t\t\t\t},\n+\t\t\t\t&cli.StringFlag{\n+\t\t\t\t\tName:    \"auth-factor-token\",\n+\t\t\t\t\tUsage:   \"token required if password is used and 2fa is required\",\n+\t\t\t\t\tEnvVars: []string{\"ATP_AUTH_FACTOR_TOKEN\"},\n+\t\t\t\t},\n \t\t\t\t&cli.StringFlag{\n \t\t\t\t\tName:    \"pds-host\",\n \t\t\t\t\tUsage:   \"URL of the PDS to create account on (overrides DID doc)\",\n@@ -163,7 +168,7 @@ func runAccountLogin(cctx *cli.Context) error {\n \t\treturn err\n \t}\n \n-\t_, err = refreshAuthSession(ctx, *username, cctx.String(\"app-password\"), cctx.String(\"pds-host\"))\n+\t_, err = refreshAuthSession(ctx, *username, cctx.String(\"app-password\"), cctx.String(\"pds-host\"), cctx.String(\"auth-factor-token\"))\n \treturn err\n }\n \n---\ncmd/goat/auth.go\n@@ -77,9 +77,9 @@ func loadAuthClient(ctx context.Context) (*xrpc.Client, error) {\n \t}\n \tresp, err := comatproto.ServerRefreshSession(ctx, &client)\n \tif err != nil {\n-\t\t// TODO: if failure, try creating a new session from password\n+\t\t// TODO: if failure, try creating a new session from password (2fa tokens are only valid once, so not reused)\n \t\tfmt.Println(\"trying to refresh auth from password...\")\n-\t\tas, err := refreshAuthSession(ctx, sess.DID.AtIdentifier(), sess.Password, sess.PDS)\n+\t\tas, err := refreshAuthSession(ctx, sess.DID.AtIdentifier(), sess.Password, sess.PDS, \"\")\n \t\tif err != nil {\n \t\t\treturn nil, err\n \t\t}\n@@ -96,7 +96,7 @@ func loadAuthClient(ctx context.Context) (*xrpc.Client, error) {\n \treturn &client, nil\n }\n \n-func refreshAuthSession(ctx context.Context, username syntax.AtIdentifier, password, pdsURL string) (*AuthSession, error) {\n+func refreshAuthSession(ctx context.Context, username syntax.AtIdentifier, password, pdsURL, authFactorToken string) (*AuthSession, error) {\n \n \tvar did syntax.DID\n \tif pdsURL == \"\" {\n@@ -120,9 +120,14 @@ func refreshAuthSession(ctx context.Context, username syntax.AtIdentifier, passw\n \tclient := xrpc.Client{\n \t\tHost: pdsURL,\n \t}\n+\tvar token *string\n+\tif authFactorToken != \"\" {\n+\t\ttoken = &authFactorToken\n+\t}\n \tsess, err := comatproto.ServerCreateSession(ctx, &client, &comatproto.ServerCreateSession_Input{\n-\t\tIdentifier: username.String(),\n-\t\tPassword:   password,\n+\t\tIdentifier:      username.String(),\n+\t\tPassword:        password,\n+\t\tAuthFactorToken: token,\n \t})\n \tif err != nil {\n \t\treturn nil, err\n---\n"}], "ideal": "Title: feat(cmd/goat): allow specifying authFactorToken\n\nBody: Supports using goat account login with [email 2fa enabled](https://github.com/bluesky-social/atproto/discussions/2435) so that users do not need to first disable 2fa to then get an email token anyways to obtain plc signing tokens."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "carstore/nonarchive.go\n@@ -100,7 +100,7 @@ func (cs *NonArchivalCarstore) updateLastCommit(ctx context.Context, uid models.\n \tcri := &commitRefInfo{\n \t\tUid:  uid,\n \t\tRev:  rev,\n-\t\tRoot: models.DbCID{cid},\n+\t\tRoot: models.DbCID{CID: cid},\n \t}\n \n \tif err := cs.db.Clauses(clause.OnConflict{\n---\n"}], "ideal": "Title: Use keyed field in DbCID initialization.\n\nBody: fixes \"struct literal uses unkeyed fields\" in lint."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/syntax/path.go\n@@ -0,0 +1,26 @@\n+package syntax\n+\n+import (\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"strings\"\n+)\n+\n+// Parses an atproto repo path string in to \"collection\" (NSID) and record key parts.\n+//\n+// Does not return partial success: either both collection and record key are complete (and error is nil), or both are empty string (and error is not nil)\n+func ParseRepoPath(raw string) (NSID, RecordKey, error) {\n+\tparts := strings.SplitN(raw, \"/\", 3)\n+\tif len(parts) != 2 {\n+\t\treturn \"\", \"\", errors.New(\"expected path to have two parts, separated by single slash\")\n+\t}\n+\tnsid, err := ParseNSID(parts[0])\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"collection part of path not a valid NSID: %w\", err)\n+\t}\n+\trkey, err := ParseRecordKey(parts[1])\n+\tif err != nil {\n+\t\treturn \"\", \"\", fmt.Errorf(\"record key part of path not valid: %w\", err)\n+\t}\n+\treturn nsid, rkey, nil\n+}\n---\natproto/syntax/path_test.go\n@@ -0,0 +1,41 @@\n+package syntax\n+\n+import (\n+\t\"testing\"\n+\n+\t\"github.com/stretchr/testify/assert\"\n+)\n+\n+func TestRepoPath(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\ttestValid := [][]string{\n+\t\t{\"app.bsky.feed.post/asdf\", \"app.bsky.feed.post\", \"asdf\"},\n+\t}\n+\n+\ttestErr := []string{\n+\t\t\"\",\n+\t\t\"/\",\n+\t\t\"/app.bsky.feed.post/asdf\",\n+\t\t\"/asdf\",\n+\t\t\"./app.bsky.feed.post\",\n+\t\t\"blob/asdf\",\n+\t\t\"app.bsky.feed.post/\",\n+\t\t\"app.bsky.feed.post/.\",\n+\t\t\"app.bsky.feed.post/!\",\n+\t}\n+\n+\tfor _, parts := range testValid {\n+\t\tnsid, rkey, err := ParseRepoPath(parts[0])\n+\t\tassert.NoError(err)\n+\t\tassert.Equal(parts[1], nsid.String())\n+\t\tassert.Equal(parts[2], rkey.String())\n+\t}\n+\n+\tfor _, raw := range testErr {\n+\t\tnsid, rkey, err := ParseRepoPath(raw)\n+\t\tassert.Error(err)\n+\t\tassert.Equal(\"\", nsid.String())\n+\t\tassert.Equal(\"\", rkey.String())\n+\t}\n+}\n---\n"}], "ideal": "Title: syntax: path parsing helper\n\nBody: helper for parsing a repo path (combination of collection and rkey) in to separate NSID and RecordKey"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/rainbow/main.go\n@@ -91,7 +91,7 @@ func run(args []string) {\n \t}\n \n \t// TODO: slog.SetDefault and set module `var log *slog.Logger` based on flags and env\n-\t\n+\n \tapp.Action = Splitter\n \terr := app.Run(os.Args)\n \tif err != nil {\n---\n"}], "ideal": "Title: make fmt\n\nBody: cc: @brianolson "}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/lexicon/language.go\n@@ -296,7 +296,7 @@ type SchemaRecord struct {\n \n func (s *SchemaRecord) CheckSchema() error {\n \tswitch s.Key {\n-\tcase \"tid\", \"any\":\n+\tcase \"tid\", \"nsid\", \"any\":\n \t\t// pass\n \tdefault:\n \t\tif !strings.HasPrefix(s.Key, \"literal:\") {\n---\n"}], "ideal": "Title: lexicon: nsid rkey type\n\nBody: https://github.com/bluesky-social/atproto-website/pull/374"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "indexer/repofetch.go\n@@ -50,8 +50,8 @@ func (rf *RepoFetcher) GetLimiter(pdsID uint) *rate.Limiter {\n }\n \n func (rf *RepoFetcher) GetOrCreateLimiter(pdsID uint, pdsrate float64) *rate.Limiter {\n-\trf.LimitMux.RLock()\n-\tdefer rf.LimitMux.RUnlock()\n+\trf.LimitMux.Lock()\n+\tdefer rf.LimitMux.Unlock()\n \n \tlim, ok := rf.Limiters[pdsID]\n \tif !ok {\n---\n"}], "ideal": "Title: fix RWLock usage\n\nBody: this needs to be a full lock, not just an R-lock because _sometimes_ it writes to the value"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/backfill.go\n@@ -12,8 +12,11 @@ import (\n \t\"time\"\n \n \t\"github.com/bluesky-social/indigo/api/atproto\"\n+\t\"github.com/bluesky-social/indigo/atproto/identity\"\n+\t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \t\"github.com/bluesky-social/indigo/repo\"\n \t\"github.com/bluesky-social/indigo/repomgr\"\n+\n \t\"github.com/ipfs/go-cid\"\n \t\"go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\"\n \t\"go.opentelemetry.io/otel\"\n@@ -71,15 +74,17 @@ type Backfiller struct {\n \tParallelRecordCreates int\n \t// Prefix match for records to backfill i.e. app.bsky.feed.app/\n \t// If empty, all records will be backfilled\n-\tNSIDFilter   string\n-\tCheckoutPath string\n+\tNSIDFilter string\n+\tRelayHost  string\n \n \tsyncLimiter *rate.Limiter\n \n \tmagicHeaderKey string\n \tmagicHeaderVal string\n \n \tstop chan chan struct{}\n+\n+\tDirectory identity.Directory\n }\n \n var (\n@@ -110,7 +115,7 @@ type BackfillOptions struct {\n \tParallelRecordCreates int\n \tNSIDFilter            string\n \tSyncRequestsPerSecond int\n-\tCheckoutPath          string\n+\tRelayHost             string\n }\n \n func DefaultBackfillOptions() *BackfillOptions {\n@@ -119,7 +124,7 @@ func DefaultBackfillOptions() *BackfillOptions {\n \t\tParallelRecordCreates: 100,\n \t\tNSIDFilter:            \"\",\n \t\tSyncRequestsPerSecond: 2,\n-\t\tCheckoutPath:          \"https://bsky.network/xrpc/com.atproto.sync.getRepo\",\n+\t\tRelayHost:             \"https://bsky.network\",\n \t}\n }\n \n@@ -145,8 +150,9 @@ func NewBackfiller(\n \t\tParallelRecordCreates: opts.ParallelRecordCreates,\n \t\tNSIDFilter:            opts.NSIDFilter,\n \t\tsyncLimiter:           rate.NewLimiter(rate.Limit(opts.SyncRequestsPerSecond), 1),\n-\t\tCheckoutPath:          opts.CheckoutPath,\n+\t\tRelayHost:             opts.RelayHost,\n \t\tstop:                  make(chan chan struct{}, 1),\n+\t\tDirectory:             identity.DefaultDirectory(),\n \t}\n }\n \n@@ -292,25 +298,12 @@ type recordResult struct {\n \terr        error\n }\n \n-// BackfillRepo backfills a repo\n-func (b *Backfiller) BackfillRepo(ctx context.Context, job Job) (string, error) {\n-\tctx, span := tracer.Start(ctx, \"BackfillRepo\")\n-\tdefer span.End()\n-\n-\tstart := time.Now()\n-\n-\trepoDid := job.Repo()\n+// Fetches a repo CAR file over HTTP from the indicated host. If successful, parses the CAR and returns repo.Repo\n+func (b *Backfiller) fetchRepo(ctx context.Context, did, since, host string) (*repo.Repo, error) {\n+\turl := fmt.Sprintf(\"%s/xrpc/com.atproto.sync.getRepo?did=%s\", host, did)\n \n-\tlog := slog.With(\"source\", \"backfiller_backfill_repo\", \"repo\", repoDid)\n-\tif job.RetryCount() > 0 {\n-\t\tlog = log.With(\"retry_count\", job.RetryCount())\n-\t}\n-\tlog.Info(fmt.Sprintf(\"processing backfill for %s\", repoDid))\n-\n-\turl := fmt.Sprintf(\"%s?did=%s\", b.CheckoutPath, repoDid)\n-\n-\tif job.Rev() != \"\" {\n-\t\turl = url + fmt.Sprintf(\"&since=%s\", job.Rev())\n+\tif since != \"\" {\n+\t\turl = url + fmt.Sprintf(\"&since=%s\", since)\n \t}\n \n \t// GET and CAR decode the body\n@@ -320,8 +313,7 @@ func (b *Backfiller) BackfillRepo(ctx context.Context, job Job) (string, error)\n \t}\n \treq, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n \tif err != nil {\n-\t\tstate := fmt.Sprintf(\"failed (create request: %s)\", err.Error())\n-\t\treturn state, fmt.Errorf(\"failed to create request: %w\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to create request: %w\", err)\n \t}\n \n \treq.Header.Set(\"Accept\", \"application/vnd.ipld.car\")\n@@ -334,8 +326,7 @@ func (b *Backfiller) BackfillRepo(ctx context.Context, job Job) (string, error)\n \n \tresp, err := client.Do(req)\n \tif err != nil {\n-\t\tstate := fmt.Sprintf(\"failed (do request: %s)\", err.Error())\n-\t\treturn state, fmt.Errorf(\"failed to send request: %w\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to send request: %w\", err)\n \t}\n \n \tif resp.StatusCode != http.StatusOK {\n@@ -345,8 +336,7 @@ func (b *Backfiller) BackfillRepo(ctx context.Context, job Job) (string, error)\n \t\t} else {\n \t\t\treason = resp.Status\n \t\t}\n-\t\tstate := fmt.Sprintf(\"failed (%s)\", reason)\n-\t\treturn state, fmt.Errorf(\"failed to get repo: %s\", reason)\n+\t\treturn nil, fmt.Errorf(\"failed to get repo: %s\", reason)\n \t}\n \n \tinstrumentedReader := instrumentedReader{\n@@ -356,10 +346,47 @@ func (b *Backfiller) BackfillRepo(ctx context.Context, job Job) (string, error)\n \n \tdefer instrumentedReader.Close()\n \n-\tr, err := repo.ReadRepoFromCar(ctx, instrumentedReader)\n+\trepo, err := repo.ReadRepoFromCar(ctx, instrumentedReader)\n \tif err != nil {\n-\t\tstate := \"failed (couldn't read repo CAR from response body)\"\n-\t\treturn state, fmt.Errorf(\"failed to read repo from car: %w\", err)\n+\t\treturn nil, fmt.Errorf(\"failed to parse repo from CAR file: %w\", err)\n+\t}\n+\treturn repo, nil\n+}\n+\n+// BackfillRepo backfills a repo\n+func (b *Backfiller) BackfillRepo(ctx context.Context, job Job) (string, error) {\n+\tctx, span := tracer.Start(ctx, \"BackfillRepo\")\n+\tdefer span.End()\n+\n+\tstart := time.Now()\n+\n+\trepoDID := job.Repo()\n+\n+\tlog := slog.With(\"source\", \"backfiller_backfill_repo\", \"repo\", repoDID)\n+\tif job.RetryCount() > 0 {\n+\t\tlog = log.With(\"retry_count\", job.RetryCount())\n+\t}\n+\tlog.Info(fmt.Sprintf(\"processing backfill for %s\", repoDID))\n+\n+\t// first try with Relay endpoint\n+\tr, err := b.fetchRepo(ctx, repoDID, job.Rev(), b.RelayHost)\n+\tif err != nil {\n+\t\tslog.Warn(\"repo CAR fetch from relay failed\", \"did\", repoDID, \"since\", job.Rev(), \"relayHost\", b.RelayHost, \"err\", err)\n+\t\t// fallback to direct PDS fetch\n+\t\tident, err := b.Directory.LookupDID(ctx, syntax.DID(repoDID))\n+\t\tif err != nil {\n+\t\t\treturn \"failed resolving DID to PDS repo\", fmt.Errorf(\"resolving DID for PDS repo fetch: %w\", err)\n+\t\t}\n+\t\tpdsHost := ident.PDSEndpoint()\n+\t\tif pdsHost == \"\" {\n+\t\t\treturn \"DID document missing PDS endpoint\", fmt.Errorf(\"no PDS endpoint for DID: %s\", repoDID)\n+\t\t}\n+\t\tr, err = b.fetchRepo(ctx, repoDID, job.Rev(), pdsHost)\n+\t\tif err != nil {\n+\t\t\tslog.Warn(\"repo CAR fetch from PDS failed\", \"did\", repoDID, \"since\", job.Rev(), \"pdsHost\", pdsHost, \"err\", err)\n+\t\t\treturn \"repo CAR fetch from PDS failed\", err\n+\t\t}\n+\t\tslog.Info(\"repo CAR fetch from PDS successful\", \"did\", repoDID, \"since\", job.Rev(), \"pdsHost\", pdsHost, \"err\", err)\n \t}\n \n \tnumRecords := 0\n@@ -396,7 +423,7 @@ func (b *Backfiller) BackfillRepo(ctx context.Context, job Job) (string, error)\n \n \t\t\t\traw := blk.RawData()\n \n-\t\t\t\terr = b.HandleCreateRecord(ctx, repoDid, rev, item.recordPath, &raw, &item.nodeCid)\n+\t\t\t\terr = b.HandleCreateRecord(ctx, repoDID, rev, item.recordPath, &raw, &item.nodeCid)\n \t\t\t\tif err != nil {\n \t\t\t\t\trecordResults <- recordResult{recordPath: item.recordPath, err: fmt.Errorf(\"failed to handle create record: %w\", err)}\n \t\t\t\t\tcontinue\n---\nsearch/indexing.go\n@@ -130,7 +130,7 @@ func NewIndexer(db *gorm.DB, escli *es.Client, dir identity.Directory, config In\n \t\topts.SyncRequestsPerSecond = 8\n \t}\n \n-\topts.CheckoutPath = fmt.Sprintf(\"%s/xrpc/com.atproto.sync.getRepo\", relayHTTP)\n+\topts.RelayHost = relayHTTP\n \tif config.IndexMaxConcurrency > 0 {\n \t\topts.ParallelRecordCreates = config.IndexMaxConcurrency\n \t} else {\n@@ -145,6 +145,8 @@ func NewIndexer(db *gorm.DB, escli *es.Client, dir identity.Directory, config In\n \t\tidx.handleDelete,\n \t\topts,\n \t)\n+\t// reuse identity directory (for efficient caching)\n+\tbf.Directory = dir\n \n \tidx.bfs = bfstore\n \tidx.bf = bf\n---\n"}], "ideal": "Title: backfill: add failback to fetch CAR file from PDS (if relay errors)\n\nBody: The main motivation here is that non-archival relay is returning a 4xx error for fetching repos, and we want to try fetching those from the actual PDS when that happens. This code adds a new code branch when a relay CAR fetch fails to do an identity lookup to find the account's PDS instance, and fetches the CAR from there.\r\n\r\nFor the search code specifically, it re-uses an existing identity directory, to reduce double-resolution.\r\n\r\nThis also refactors how fetch URLs are constructed to use just hostnames.\r\n\r\nUPDATE: should probably *not* merge this to `main` until Jaz can review"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/base_directory.go\n@@ -29,6 +29,8 @@ type BaseDirectory struct {\n \tSkipDNSDomainSuffixes []string\n \t// set of fallback DNS servers (eg, domain registrars) to try as a fallback. each entry should be \"ip:port\", eg \"8.8.8.8:53\"\n \tFallbackDNSServers []string\n+\t// Hack to skip handle resolution as part of overall identity resolution, when starting with a DID (aka, LookupDID). Always returns invalid handle in this case. This flag is only relevant to services doing things like PDS lookup, or service auth validation (neither involve handles). Longer-term plan is to refactor the directory interface/API to allow more granular DID-only (and handle-only) resolution.\n+\tSkipHandleResolution bool\n }\n \n var _ Directory = (*BaseDirectory)(nil)\n@@ -62,6 +64,10 @@ func (d *BaseDirectory) LookupDID(ctx context.Context, did syntax.DID) (*Identit\n \t\treturn nil, err\n \t}\n \tident := ParseIdentity(doc)\n+\tif d.SkipHandleResolution {\n+\t\tident.Handle = syntax.HandleInvalid\n+\t\treturn &ident, nil\n+\t}\n \tdeclared, err := ident.DeclaredHandle()\n \tif errors.Is(err, ErrHandleNotDeclared) {\n \t\tident.Handle = syntax.HandleInvalid\n---\n"}], "ideal": "Title: identity: hack flag to skip handle resolution\n\nBody: Motivation here is to slash DNS lookups as part of cached DID resolution. As noted in the doc comment, we should loop back around and update the \"Directory\" interface/API to support this usecase better.\r\n\r\nTo actually deploy this in discover, we should:\r\n\r\n- confirm that we don't actually use handle resolution anywhere in discover. this will always return DID lookups with \"invalid handle\"\r\n- configure the redis directory \"invalid handle TTL\" to have the same duration as \"hit\" TTL\r\n- set this flag to \"true\" on the inner/wrapped base directory\r\n\r\nThis will only impact the \"resolve identity by DID\" path, not any \"resolve identity by handle\" paths.\r\n\r\n"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/syntax/cmd/atp-syntax/main.go\n@@ -22,6 +22,12 @@ func main() {\n \t\t\tArgsUsage: \"<tid>\",\n \t\t\tAction:    runParseTID,\n \t\t},\n+\t\t&cli.Command{\n+\t\t\tName:      \"parse-did\",\n+\t\t\tUsage:     \"parse a DID\",\n+\t\t\tArgsUsage: \"<did>\",\n+\t\t\tAction:    runParseDID,\n+\t\t},\n \t}\n \th := slog.NewTextHandler(os.Stderr, &slog.HandlerOptions{Level: slog.LevelDebug})\n \tslog.SetDefault(slog.New(h))\n@@ -43,3 +49,18 @@ func runParseTID(cctx *cli.Context) error {\n \n \treturn nil\n }\n+\n+func runParseDID(cctx *cli.Context) error {\n+\ts := cctx.Args().First()\n+\tif s == \"\" {\n+\t\treturn fmt.Errorf(\"need to provide identifier as an argument\")\n+\t}\n+\n+\tdid, err := syntax.ParseDID(s)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfmt.Printf(\"%s\\n\", did)\n+\n+\treturn nil\n+}\n---\natproto/syntax/did.go\n@@ -14,8 +14,30 @@ import (\n type DID string\n \n var didRegex = regexp.MustCompile(`^did:[a-z]+:[a-zA-Z0-9._:%-]*[a-zA-Z0-9._-]$`)\n+var plcChars = \"\"\n+\n+func isASCIIAlphaNum(c rune) bool {\n+\tif (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || (c >= '0' && c <= '9') {\n+\t\treturn true\n+\t}\n+\treturn false\n+}\n \n func ParseDID(raw string) (DID, error) {\n+\t// fast-path for did:plc, avoiding regex\n+\tif len(raw) == 32 && strings.HasPrefix(raw, \"did:plc:\") {\n+\t\t// NOTE: this doesn't really check base32, just broader alphanumberic. might pass invalid PLC DIDs, but they still have overall valid DID syntax\n+\t\tisPlc := true\n+\t\tfor _, c := range raw[8:32] {\n+\t\t\tif !isASCIIAlphaNum(c) {\n+\t\t\t\tisPlc = false\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t}\n+\t\tif isPlc {\n+\t\t\treturn DID(raw), nil\n+\t\t}\n+\t}\n \tif raw == \"\" {\n \t\treturn \"\", errors.New(\"expected DID, got empty string\")\n \t}\n---\n"}], "ideal": "Title: syntax: ParseDID performance\n\nBody: we are apparently burning a bunch of CPU on this regex in prod, so let's bypass for the most common case (valid did:plc).\r\n\r\nWould be nice to have a benchmark demonstrating perf gains (or not).\r\n\r\nI did some manually testing with the CLI helper and inserted `panic()` statements to confirm that valid DID PLC stays on fast path, and other DIDs don't.\r\n\r\nFeedback welcome if there is a more idiomatic/performant golang way to do this... this is still doing unicode stuff, I assume, and maybe casting to bytes would be faster? though probably doesn't impact the actual hot path much. `strings.ContainsAny` or `strings.ContainsFunc` could be used here I guess but :shrug: "}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/handlers.go\n@@ -198,11 +198,12 @@ func (s *BGS) handleComAtprotoSyncRequestCrawl(ctx context.Context, body *comatp\n \t\t\t\t\tpu := rpu.JoinPath(\"/xrpc/com.atproto.sync.requestCrawl\")\n \t\t\t\t\tresponse, err := s.httpClient.Post(pu.String(), \"application/json\", bytes.NewReader(bodyBlob))\n \t\t\t\t\tif err != nil {\n-\t\t\t\t\t\tlog.Warnw(\"requestCrawl forward failed\", \"err\", err)\n+\t\t\t\t\t\tlog.Warnw(\"requestCrawl forward failed\", \"host\", rpu, \"err\", err)\n \t\t\t\t\t} else if response.StatusCode != http.StatusOK {\n-\t\t\t\t\t\tlog.Warnw(\"requestCrawl forward failed\", \"status\", response.Status)\n+\t\t\t\t\t\tlog.Warnw(\"requestCrawl forward failed\", \"host\", rpu, \"status\", response.Status)\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tlog.Infow(\"requestCrawl forward successful\", \"host\", rpu)\n \t\t\t\t\t}\n-\t\t\t\t\tlog.Infow(\"requestCrawl forward successful\", \"host\", rpu, \"status\", response.Status)\n \t\t\t\t}\n \t\t\t}(blob)\n \t\t}\n---\n"}], "ideal": "Title: fix a segfault when passing on requestCrawl fails\n\nBody: my bad! had snuck in that recently, `response` is nil if there is an error."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/bigsky/main.go\n@@ -190,6 +190,10 @@ func run(args []string) error {\n \t\t\tEnvVars: []string{\"RELAY_DID_CACHE_SIZE\"},\n \t\t\tValue:   5_000_000,\n \t\t},\n+\t\t&cli.StringSliceFlag{\n+\t\t\tName:    \"did-memcached\",\n+\t\t\tEnvVars: []string{\"RELAY_DID_MEMCACHED\"},\n+\t\t},\n \t\t&cli.DurationFlag{\n \t\t\tName:    \"event-playback-ttl\",\n \t\t\tUsage:   \"time to live for event playback buffering (only applies to disk persister)\",\n@@ -339,18 +343,33 @@ func runBigsky(cctx *cli.Context) error {\n \t\treturn err\n \t}\n \n-\tmr := did.NewMultiResolver()\n+\t// DID RESOLUTION\n+\t// 1. the outside world, PLCSerever or Web\n+\t// 2. (maybe memcached)\n+\t// 3. in-process cache\n+\tvar cachedidr did.Resolver\n+\t{\n+\t\tmr := did.NewMultiResolver()\n \n-\tdidr := &api.PLCServer{Host: cctx.String(\"plc-host\")}\n-\tmr.AddHandler(\"plc\", didr)\n+\t\tdidr := &api.PLCServer{Host: cctx.String(\"plc-host\")}\n+\t\tmr.AddHandler(\"plc\", didr)\n \n-\twebr := did.WebResolver{}\n-\tif cctx.Bool(\"crawl-insecure-ws\") {\n-\t\twebr.Insecure = true\n-\t}\n-\tmr.AddHandler(\"web\", &webr)\n+\t\twebr := did.WebResolver{}\n+\t\tif cctx.Bool(\"crawl-insecure-ws\") {\n+\t\t\twebr.Insecure = true\n+\t\t}\n+\t\tmr.AddHandler(\"web\", &webr)\n \n-\tcachedidr := plc.NewCachingDidResolver(mr, time.Hour*24, cctx.Int(\"did-cache-size\"))\n+\t\tvar prevResolver did.Resolver\n+\t\tmemcachedServers := cctx.StringSlice(\"did-memcached\")\n+\t\tif len(memcachedServers) > 0 {\n+\t\t\tprevResolver = plc.NewMemcachedDidResolver(mr, time.Hour*24, memcachedServers)\n+\t\t} else {\n+\t\t\tprevResolver = mr\n+\t\t}\n+\n+\t\tcachedidr = plc.NewCachingDidResolver(prevResolver, time.Hour*24, cctx.Int(\"did-cache-size\"))\n+\t}\n \n \tkmgr := indexer.NewKeyManager(cachedidr, nil)\n \n---\ngo.mod\n@@ -8,6 +8,7 @@ require (\n \tgithub.com/RussellLuo/slidingwindow v0.0.0-20200528002341-535bb99d338b\n \tgithub.com/adrg/xdg v0.5.0\n \tgithub.com/araddon/dateparse v0.0.0-20210429162001-6b43995a97de\n+\tgithub.com/bradfitz/gomemcache v0.0.0-20230905024940-24af94b03874\n \tgithub.com/brianvoe/gofakeit/v6 v6.25.0\n \tgithub.com/carlmjohnson/versioninfo v0.22.5\n \tgithub.com/cockroachdb/pebble v1.1.2\n---\ngo.sum\n@@ -73,6 +73,8 @@ github.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24\n github.com/beorn7/perks v1.0.0/go.mod h1:KWe93zE9D1o94FZ5RNwFwVgaQK1VOXiVxmqh+CedLV8=\n github.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\n github.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\n+github.com/bradfitz/gomemcache v0.0.0-20230905024940-24af94b03874 h1:N7oVaKyGp8bttX0bfZGmcGkjz7DLQXhAn3DNd3T0ous=\n+github.com/bradfitz/gomemcache v0.0.0-20230905024940-24af94b03874/go.mod h1:r5xuitiExdLAJ09PR7vBVENGvp4ZuTBeWTGtxuX3K+c=\n github.com/brianvoe/gofakeit/v6 v6.25.0 h1:ZpFjktOpLZUeF8q223o0rUuXtA+m5qW5srjvVi+JkXk=\n github.com/brianvoe/gofakeit/v6 v6.25.0/go.mod h1:Xj58BMSnFqcn/fAQeSK+/PLtC5kSb7FJIq4JyGa8vEs=\n github.com/bsm/ginkgo/v2 v2.12.0 h1:Ny8MWAHyOepLGlLKYmXG4IEkioBysk6GpaRTLC8zwWs=\n---\nplc/memcached.go\n@@ -0,0 +1,90 @@\n+package plc\n+\n+import (\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"github.com/bradfitz/gomemcache/memcache\"\n+\t\"go.opentelemetry.io/otel/attribute\"\n+\t\"time\"\n+\n+\t\"github.com/bluesky-social/indigo/did\"\n+\t\"go.opentelemetry.io/otel\"\n+)\n+\n+type MemcachedDidResolver struct {\n+\tmcd    *memcache.Client\n+\tres    did.Resolver\n+\tmaxAge int32\n+}\n+\n+func NewMemcachedDidResolver(res did.Resolver, maxAge time.Duration, servers []string) *MemcachedDidResolver {\n+\texpiry := int32(0)\n+\tif maxAge.Seconds() > (30 * 24 * 60 * 60) {\n+\t\t// clamp expiry at 30 days minus a minute for memcached\n+\t\texpiry = (30 * 24 * 60 * 60) - 60\n+\t} else {\n+\t\texpiry = int32(maxAge.Seconds())\n+\t}\n+\tclient := memcache.New(servers...)\n+\treturn &MemcachedDidResolver{\n+\t\tmcd:    client,\n+\t\tres:    res,\n+\t\tmaxAge: expiry,\n+\t}\n+}\n+\n+func (r *MemcachedDidResolver) FlushCacheFor(didstr string) {\n+\tr.mcd.Delete(didstr)\n+\tr.res.FlushCacheFor(didstr)\n+}\n+\n+func (r *MemcachedDidResolver) tryCache(didstr string) (*did.Document, bool) {\n+\tob, err := r.mcd.Get(didstr)\n+\tif (ob == nil) || (err != nil) {\n+\t\treturn nil, false\n+\t}\n+\tvar doc did.Document\n+\terr = json.Unmarshal(ob.Value, &doc)\n+\tif err != nil {\n+\t\t// TODO: log error?\n+\t\treturn nil, false\n+\t}\n+\n+\treturn &doc, true\n+}\n+\n+func (r *MemcachedDidResolver) putCache(did string, doc *did.Document) {\n+\tblob, err := json.Marshal(doc)\n+\tif err != nil {\n+\t\t// TODO: log error\n+\t\treturn\n+\t}\n+\titem := memcache.Item{\n+\t\tKey:        did,\n+\t\tValue:      blob,\n+\t\tExpiration: int32(r.maxAge),\n+\t}\n+\tr.mcd.Set(&item)\n+}\n+\n+func (r *MemcachedDidResolver) GetDocument(ctx context.Context, didstr string) (*did.Document, error) {\n+\tctx, span := otel.Tracer(\"cacheResolver\").Start(ctx, \"getDocument\")\n+\tdefer span.End()\n+\n+\tdoc, ok := r.tryCache(didstr)\n+\tif ok {\n+\t\tspan.SetAttributes(attribute.Bool(\"cache\", true))\n+\t\tcacheHitsTotal.Inc()\n+\t\treturn doc, nil\n+\t}\n+\tcacheMissesTotal.Inc()\n+\tspan.SetAttributes(attribute.Bool(\"cache\", false))\n+\n+\tdoc, err := r.res.GetDocument(ctx, didstr)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tr.putCache(didstr, doc)\n+\treturn doc, nil\n+}\n---\n"}], "ideal": "Title: add memcached for did cache to relay\n\nBody: tired of waiting for the did cache to warm up when relay restarts? wait no longer! put the cache in memcached (still also have local in-process cache, but backed by \"L2\" cache in memcached)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "indexer/crawler.go\n@@ -89,46 +89,15 @@ type crawlWork struct {\n }\n \n func (c *CrawlDispatcher) mainLoop() {\n-\tvar nextDispatchedJob *crawlWork\n-\tvar jobsAwaitingDispatch []*crawlWork\n-\n-\t// dispatchQueue represents the repoSync worker channel to which we dispatch crawl work\n-\tvar dispatchQueue chan *crawlWork\n-\n \tfor {\n+\t\tvar crawlJob *crawlWork = nil\n \t\tselect {\n \t\tcase actorToCrawl := <-c.ingest:\n \t\t\t// TODO: max buffer size\n-\t\t\tcrawlJob := c.enqueueJobForActor(actorToCrawl)\n-\t\t\tif crawlJob == nil {\n-\t\t\t\tbreak\n-\t\t\t}\n-\n-\t\t\tif nextDispatchedJob == nil {\n-\t\t\t\tnextDispatchedJob = crawlJob\n-\t\t\t\tdispatchQueue = c.repoSync\n-\t\t\t} else {\n-\t\t\t\tjobsAwaitingDispatch = append(jobsAwaitingDispatch, crawlJob)\n-\t\t\t}\n-\t\tcase dispatchQueue <- nextDispatchedJob:\n-\t\t\tc.dequeueJob(nextDispatchedJob)\n-\n-\t\t\tif len(jobsAwaitingDispatch) > 0 {\n-\t\t\t\tnextDispatchedJob = jobsAwaitingDispatch[0]\n-\t\t\t\tjobsAwaitingDispatch = jobsAwaitingDispatch[1:]\n-\t\t\t} else {\n-\t\t\t\tnextDispatchedJob = nil\n-\t\t\t\tdispatchQueue = nil\n-\t\t\t}\n-\t\tcase catchupJob := <-c.catchup:\n+\t\t\tcrawlJob = c.enqueueJobForActor(actorToCrawl)\n+\t\tcase crawlJob = <-c.catchup:\n \t\t\t// CatchupJobs are for processing events that come in while a crawl is in progress\n \t\t\t// They are lower priority than new crawls so we only add them to the queue if there isn't already a job in progress\n-\t\t\tif nextDispatchedJob == nil {\n-\t\t\t\tnextDispatchedJob = catchupJob\n-\t\t\t\tdispatchQueue = c.repoSync\n-\t\t\t} else {\n-\t\t\t\tjobsAwaitingDispatch = append(jobsAwaitingDispatch, catchupJob)\n-\t\t\t}\n \t\tcase uid := <-c.complete:\n \t\t\tc.maplk.Lock()\n \n@@ -145,15 +114,15 @@ func (c *CrawlDispatcher) mainLoop() {\n \t\t\t\tjob.initScrape = false\n \t\t\t\tjob.catchup = job.next\n \t\t\t\tjob.next = nil\n-\t\t\t\tif nextDispatchedJob == nil {\n-\t\t\t\t\tnextDispatchedJob = job\n-\t\t\t\t\tdispatchQueue = c.repoSync\n-\t\t\t\t} else {\n-\t\t\t\t\tjobsAwaitingDispatch = append(jobsAwaitingDispatch, job)\n-\t\t\t\t}\n+\t\t\t\tcrawlJob = job\n \t\t\t}\n \t\t\tc.maplk.Unlock()\n \t\t}\n+\t\tif crawlJob != nil {\n+\t\t\tc.repoSync <- crawlJob\n+\t\t\tc.dequeueJob(crawlJob)\n+\t\t\tcrawlJob = nil\n+\t\t}\n \t}\n }\n \n---\n"}], "ideal": "Title: simplify CrawlDispatcher.mainLoop()\n\nBody: I am pretty sure that this is the same operation, but much simpler, so we don't confuse ourselves every time we try to read this code"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "events/pebblepersist.go\n@@ -118,7 +118,8 @@ func eventFromPebbleIter(iter *pebble.Iterator) (*XRPCStreamEvent, error) {\n \n func (pp *PebblePersist) Playback(ctx context.Context, since int64, cb func(*XRPCStreamEvent) error) error {\n \tvar key [8]byte\n-\tbinary.BigEndian.PutUint64(key[:], uint64(since))\n+\t// Add 1 to the cursor because IterOptions.LowerBound is inclusive.\n+\tbinary.BigEndian.PutUint64(key[:], uint64(since+1))\n \n \titer, err := pp.db.NewIterWithContext(ctx, &pebble.IterOptions{LowerBound: key[:]})\n \tif err != nil {\n---\nevents/persist.go\n@@ -11,6 +11,8 @@ import (\n // Note that this interface looks generic, but some persisters might only work with RepoAppend or LabelLabels\n type EventPersistence interface {\n \tPersist(ctx context.Context, e *XRPCStreamEvent) error\n+\n+\t// Playback calls cb on persisted events with sequence number > since.\n \tPlayback(ctx context.Context, since int64, cb func(*XRPCStreamEvent) error) error\n \tTakeDownRepo(ctx context.Context, usr models.Uid) error\n \tFlush(context.Context) error\n---\n"}], "ideal": "Title: events: document EventPersistence.Playback behavior for since parameter, fix PebblePersist accordingly\n\nBody: This fixes #837 "}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/bgs.go\n@@ -1646,13 +1646,15 @@ func (bgs *BGS) ResyncPDS(ctx context.Context, pds models.PDS) error {\n \tlog.Warnw(\"listed all repos, checking roots\", \"num_repos\", len(repos), \"took\", repolistDone.Sub(start))\n \tresync = bgs.SetResyncStatus(pds.ID, \"checking revs\")\n \n-\t// run loop over repos with some concurrency\n+\t// Create a buffered channel for collecting results\n+\tresults := make(chan revCheckResult, len(repos))\n \tsem := semaphore.NewWeighted(40)\n \n \t// Check repo revs against our local copy and enqueue crawls for any that are out of date\n-\tfor i, r := range repos {\n+\tfor _, r := range repos {\n \t\tif err := sem.Acquire(ctx, 1); err != nil {\n \t\t\tlog.Errorw(\"failed to acquire semaphore\", \"error\", err)\n+\t\t\tresults <- revCheckResult{err: err}\n \t\t\tcontinue\n \t\t}\n \t\tgo func(r comatproto.SyncListRepos_Repo) {\n@@ -1662,41 +1664,56 @@ func (bgs *BGS) ResyncPDS(ctx context.Context, pds models.PDS) error {\n \t\t\tai, err := bgs.Index.GetUserOrMissing(ctx, r.Did)\n \t\t\tif err != nil {\n \t\t\t\tlog.Errorw(\"failed to get user while resyncing PDS, we can't recrawl it\", \"error\", err)\n+\t\t\t\tresults <- revCheckResult{err: err}\n \t\t\t\treturn\n \t\t\t}\n \n \t\t\trev, err := bgs.repoman.GetRepoRev(ctx, ai.Uid)\n \t\t\tif err != nil {\n \t\t\t\tlog.Warnw(\"recrawling because we failed to get the local repo root\", \"err\", err, \"uid\", ai.Uid)\n-\t\t\t\terr := bgs.Index.Crawler.Crawl(ctx, ai)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tlog.Errorw(\"failed to enqueue crawl for repo during resync\", \"error\", err, \"uid\", ai.Uid, \"did\", ai.Did)\n-\t\t\t\t}\n+\t\t\t\tresults <- revCheckResult{ai: ai}\n \t\t\t\treturn\n \t\t\t}\n \n \t\t\tif rev == \"\" || rev < r.Rev {\n \t\t\t\tlog.Warnw(\"recrawling because the repo rev from the PDS is newer than our local repo rev\", \"local_rev\", rev)\n-\t\t\t\terr := bgs.Index.Crawler.Crawl(ctx, ai)\n-\t\t\t\tif err != nil {\n-\t\t\t\t\tlog.Errorw(\"failed to enqueue crawl for repo during resync\", \"error\", err, \"uid\", ai.Uid, \"did\", ai.Did)\n-\t\t\t\t}\n+\t\t\t\tresults <- revCheckResult{ai: ai}\n \t\t\t\treturn\n \t\t\t}\n+\n+\t\t\tresults <- revCheckResult{}\n \t\t}(r)\n+\t}\n+\n+\tvar numReposToResync int\n+\tfor i := 0; i < len(repos); i++ {\n+\t\tres := <-results\n+\t\tif res.err != nil {\n+\t\t\tlog.Errorw(\"failed to process repo during resync\", \"error\", res.err)\n+\n+\t\t}\n+\t\tif res.ai != nil {\n+\t\t\tnumReposToResync++\n+\t\t\terr := bgs.Index.Crawler.Crawl(ctx, res.ai)\n+\t\t\tif err != nil {\n+\t\t\t\tlog.Errorw(\"failed to enqueue crawl for repo during resync\", \"error\", err, \"uid\", res.ai.Uid, \"did\", res.ai.Did)\n+\t\t\t}\n+\t\t}\n \t\tif i%100 == 0 {\n \t\t\tif i%10_000 == 0 {\n-\t\t\t\tlog.Warnw(\"checked revs during resync\", \"num_repos_checked\", i, \"num_repos_to_crawl\", -1, \"took\", time.Now().Sub(resync.StatusChangedAt))\n+\t\t\t\tlog.Warnw(\"checked revs during resync\", \"num_repos_checked\", i, \"num_repos_to_crawl\", numReposToResync, \"took\", time.Now().Sub(resync.StatusChangedAt))\n \t\t\t}\n \t\t\tresync.NumReposChecked = i\n+\t\t\tresync.NumReposToResync = numReposToResync\n \t\t\tbgs.UpdateResync(resync)\n \t\t}\n \t}\n \n \tresync.NumReposChecked = len(repos)\n+\tresync.NumReposToResync = numReposToResync\n \tbgs.UpdateResync(resync)\n \n-\tlog.Warnw(\"enqueued all crawls, exiting resync\", \"took\", time.Now().Sub(start), \"num_repos_to_crawl\", -1)\n+\tlog.Warnw(\"enqueued all crawls, exiting resync\", \"took\", time.Now().Sub(start), \"num_repos_to_crawl\", numReposToResync)\n \n \treturn nil\n }\n---\n"}], "ideal": "Title: Revert \"stream resync to indexer crawler\"\n\nBody: Reverts bluesky-social/indigo#826\r\n\r\n(I pressed merge on the wrong PR)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/fedmgr.go\n@@ -468,6 +468,11 @@ func (s *Slurper) subscribeWithRedialer(ctx context.Context, host *models.PDS, s\n \t\tprotocol = \"wss\"\n \t}\n \n+\t// Special case `.host.bsky.network` PDSs to rewind cursor by 200 events to smooth over unclean shutdowns\n+\tif strings.HasSuffix(host.Host, \".host.bsky.network\") && host.Cursor > 200 {\n+\t\thost.Cursor -= 200\n+\t}\n+\n \tcursor := host.Cursor\n \n \tvar backoff int\n---\n"}], "ideal": "Title: Rewind cursor a bit before reconnection for some relay hosts to smooth over reconnection\n\nBody: We see some jerk when the Relay restarts caused by high concurrency of event processing for some high traffic hosts, where some in-progress event handlers die while the cursor is advanced ahead of them and the next event for that repo triggers a catch-up/resync of the repo. This change rewinds the cursor a bit on reconnect to smooth out that process."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "HACKING.md\n@@ -14,6 +14,7 @@ Run with, eg, `go run ./cmd/bigsky`):\n - `cmd/supercollider`: event stream load generation tool\n - `cmd/sonar`: event stream monitoring tool\n - `cmd/hepa`: auto-moderation rule engine service\n+- `cmd/rainbow`: firehose fanout service\n - `gen`: dev tool to run CBOR type codegen\n \n Packages:\n---\ncmd/rainbow/README.md\n@@ -0,0 +1,32 @@\n+\n+`rainbow`: atproto Firehose Fanout Service\n+==========================================\n+\n+This is an atproto service which consumes from a firehose (eg, from a relay or PDS) and fans out events to many subscribers.\n+\n+Features and design points:\n+\n+- retains \"backfill window\" on local disk (using [pebble](https://github.com/cockroachdb/pebble))\n+- serves the `com.atproto.sync.subscribeRepos` endpoint (WebSocket)\n+- retains upstream firehose \"sequence numbers\"\n+- does not validate events (signatures, repo tree, hashes, etc), just passes through\n+- does not archive or mirror individual records or entire repositories (or implement related API endpoints)\n+- disk I/O intensive: fast NVMe disks are recommended, and RAM is helpful for caching\n+- single golang binary for easy deployment\n+- observability: logging, prometheus metrics, OTEL traces\n+\n+## Running \n+\n+This is a simple, single-binary Go program. You can also build and run it as a docker container (see `./Dockerfile`).\n+\n+From the top level of this repo, you can build:\n+\n+```shell\n+go build ./cmd/rainbow -o rainbow-bin\n+```\n+\n+or just run it, and see configuration options:\n+\n+```shell\n+go run ./cmd/rainbow --help\n+```\n---\n"}], "ideal": "Title: Bnewbold/readme rainbow\n\nBody: going to self-merge this"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/rainbow/Dockerfile\n@@ -39,5 +39,5 @@ ENTRYPOINT [\"/usr/bin/dumb-init\", \"--\"]\n CMD [\"/usr/bin/rainbow\"]\n \n LABEL org.opencontainers.image.source=https://github.com/bluesky-social/indigo\n-LABEL org.opencontainers.image.description=\"bsky.app rainbow\"\n+LABEL org.opencontainers.image.description=\"rainbow atproto firehose fanout service\"\n LABEL org.opencontainers.image.licenses=MIT\n---\ncmd/rainbow/main.go\n@@ -3,19 +3,18 @@ package main\n import (\n \t\"context\"\n \t\"github.com/bluesky-social/indigo/events\"\n+\t_ \"net/http/pprof\"\n \t\"os\"\n \t\"os/signal\"\n \t\"syscall\"\n \t\"time\"\n \n \t\"github.com/bluesky-social/indigo/splitter\"\n-\t\"github.com/carlmjohnson/versioninfo\"\n-\t_ \"go.uber.org/automaxprocs\"\n-\n-\t_ \"net/http/pprof\"\n \n \t_ \"github.com/joho/godotenv/autoload\"\n+\t_ \"go.uber.org/automaxprocs\"\n \n+\t\"github.com/carlmjohnson/versioninfo\"\n \tlogging \"github.com/ipfs/go-log\"\n \t\"github.com/urfave/cli/v2\"\n \t\"go.opentelemetry.io/otel\"\n@@ -26,7 +25,7 @@ import (\n \tsemconv \"go.opentelemetry.io/otel/semconv/v1.4.0\"\n )\n \n-var log = logging.Logger(\"splitter\")\n+var log = logging.Logger(\"rainbow\")\n \n func init() {\n \t// control log level using, eg, GOLOG_LOG_LEVEL=debug\n@@ -39,50 +38,55 @@ func main() {\n \n func run(args []string) {\n \tapp := cli.App{\n-\t\tName:    \"splitter\",\n-\t\tUsage:   \"firehose proxy\",\n+\t\tName:    \"rainbow\",\n+\t\tUsage:   \"atproto firehose fan-out daemon\",\n \t\tVersion: versioninfo.Short(),\n \t}\n \n \tapp.Flags = []cli.Flag{\n \t\t&cli.BoolFlag{\n-\t\t\tName:  \"crawl-insecure-ws\",\n-\t\t\tUsage: \"when connecting to PDS instances, use ws:// instead of wss://\",\n+\t\t\tName:    \"crawl-insecure-ws\",\n+\t\t\tUsage:   \"when connecting to PDS instances, use ws:// instead of wss://\",\n+\t\t\tEnvVars: []string{\"RAINBOW_INSECURE_CRAWL\"},\n \t\t},\n \t\t&cli.StringFlag{\n-\t\t\tName:  \"splitter-host\",\n-\t\t\tValue: \"bsky.network\",\n+\t\t\tName:    \"splitter-host\",\n+\t\t\tValue:   \"bsky.network\",\n+\t\t\tEnvVars: []string{\"ATP_RELAY_HOST\", \"RAINBOW_RELAY_HOST\"},\n \t\t},\n \t\t&cli.StringFlag{\n-\t\t\tName:  \"persist-db\",\n-\t\t\tValue: \"\",\n-\t\t\tUsage: \"path to persistence db\",\n+\t\t\tName:    \"persist-db\",\n+\t\t\tValue:   \"./rainbow.db\",\n+\t\t\tUsage:   \"path to persistence db\",\n+\t\t\tEnvVars: []string{\"RAINBOW_DB_PATH\"},\n \t\t},\n \t\t&cli.StringFlag{\n-\t\t\tName:  \"cursor-file\",\n-\t\t\tValue: \"\",\n-\t\t\tUsage: \"write upstream cursor number to this file\",\n+\t\t\tName:    \"cursor-file\",\n+\t\t\tValue:   \"./rainbow-cursor\",\n+\t\t\tUsage:   \"write upstream cursor number to this file\",\n+\t\t\tEnvVars: []string{\"RAINBOW_CURSOR_PATH\"},\n \t\t},\n \t\t&cli.StringFlag{\n-\t\t\tName:  \"api-listen\",\n-\t\t\tValue: \":2480\",\n+\t\t\tName:    \"api-listen\",\n+\t\t\tValue:   \":2480\",\n+\t\t\tEnvVars: []string{\"RAINBOW_API_LISTEN\"},\n \t\t},\n \t\t&cli.StringFlag{\n \t\t\tName:    \"metrics-listen\",\n \t\t\tValue:   \":2481\",\n-\t\t\tEnvVars: []string{\"SPLITTER_METRICS_LISTEN\"},\n+\t\t\tEnvVars: []string{\"RAINBOW_METRICS_LISTEN\", \"SPLITTER_METRICS_LISTEN\"},\n \t\t},\n \t\t&cli.Float64Flag{\n \t\t\tName:    \"persist-hours\",\n-\t\t\tValue:   24 * 7,\n-\t\t\tEnvVars: []string{\"SPLITTER_PERSIST_HOURS\"},\n+\t\t\tValue:   24 * 3,\n+\t\t\tEnvVars: []string{\"RAINBOW_PERSIST_HOURS\", \"SPLITTER_PERSIST_HOURS\"},\n \t\t\tUsage:   \"hours to buffer (float, may be fractional)\",\n \t\t},\n \t\t&cli.Int64Flag{\n \t\t\tName:    \"persist-bytes\",\n \t\t\tValue:   0,\n \t\t\tUsage:   \"max bytes target for event cache, 0 to disable size target trimming\",\n-\t\t\tEnvVars: []string{\"SPLITTER_PERSIST_BYTES\"},\n+\t\t\tEnvVars: []string{\"RAINBOW_PERSIST_BYTES\", \"SPLITTER_PERSIST_BYTES\"},\n \t\t},\n \t}\n \n---\nsplitter/splitter.go\n@@ -196,10 +196,11 @@ func (s *Splitter) StartWithListener(listen net.Listener) error {\n \t\t}\n \t}\n \n-\t// TODO: this API is temporary until we formalize what we want here\n-\n \te.GET(\"/xrpc/com.atproto.sync.subscribeRepos\", s.EventsHandler)\n+\n \te.GET(\"/xrpc/_health\", s.HandleHealthCheck)\n+\te.GET(\"/_health\", s.HandleHealthCheck)\n+\te.GET(\"/\", s.HandleHomeMessage)\n \n \t// In order to support booting on random ports in tests, we need to tell the\n \t// Echo instance it's already got a port, and then use its StartServer\n@@ -218,6 +219,21 @@ func (s *Splitter) HandleHealthCheck(c echo.Context) error {\n \treturn c.JSON(200, HealthStatus{Status: \"ok\"})\n }\n \n+var homeMessage string = `\n+          _      _\n+ _ _ __ _(_)_ _ | |__  _____ __ __\n+| '_/ _' | | ' \\| '_ \\/ _ \\ V  V /\n+|_| \\__,_|_|_||_|_.__/\\___/\\_/\\_/\n+\n+This is an atproto [https://atproto.com] firehose fanout service, running the 'rainbow' codebase [https://github.com/bluesky-social/indigo]\n+\n+The firehose WebSocket path is at:  /xrpc/com.atproto.sync.subscribeRepos\n+`\n+\n+func (s *Splitter) HandleHomeMessage(c echo.Context) error {\n+\treturn c.String(http.StatusOK, homeMessage)\n+}\n+\n func (s *Splitter) EventsHandler(c echo.Context) error {\n \tvar since *int64\n \tif sinceVal := c.QueryParam(\"cursor\"); sinceVal != \"\" {\n---\n"}], "ideal": "Title: rainbow service setup tweaks\n\nBody: - moving service config towards \"rainbow\" away from \"splitter\"\r\n- adds env vars for more config options\r\n- defaults and tweaks for some config options\r\n- add a root path HTTP handler, which is helpful for debugging"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "repomgr/repomgr.go\n@@ -467,7 +467,7 @@ func (rm *RepoManager) GetRecordProof(ctx context.Context, user models.Uid, coll\n \t\treturn cid.Undef, nil, err\n \t}\n \n-\t_, _, err = r.GetRecord(ctx, collection+\"/\"+rkey)\n+\t_, _, err = r.GetRecordBytes(ctx, collection+\"/\"+rkey)\n \tif err != nil {\n \t\treturn cid.Undef, nil, err\n \t}\n---\n"}], "ideal": "Title: sync get record shouldnt unmarshal\n\nBody: allows this to work on non bsky.app records"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/identity.go\n@@ -65,11 +65,16 @@ func DefaultDirectory() Directory {\n \tbase := BaseDirectory{\n \t\tPLCURL: DefaultPLCURL,\n \t\tHTTPClient: http.Client{\n-\t\t\tTimeout: time.Second * 15,\n+\t\t\tTimeout: time.Second * 10,\n+\t\t\tTransport: &http.Transport{\n+\t\t\t\t// would want this around 100ms for services doing lots of handle resolution. Impacts PLC connections as well, but not too bad.\n+\t\t\t\tIdleConnTimeout: time.Millisecond * 1000,\n+\t\t\t\tMaxIdleConns:    100,\n+\t\t\t},\n \t\t},\n \t\tResolver: net.Resolver{\n \t\t\tDial: func(ctx context.Context, network, address string) (net.Conn, error) {\n-\t\t\t\td := net.Dialer{Timeout: time.Second * 5}\n+\t\t\t\td := net.Dialer{Timeout: time.Second * 3}\n \t\t\t\treturn d.DialContext(ctx, network, address)\n \t\t\t},\n \t\t},\n---\n"}], "ideal": "Title: identity package default tweaks\n\nBody: - limits on HTTP idle connections. mostly impacts did:web and HTTPS handle resolution, which can otherwise result in huge numbers of sockets hanging around (one per custom domain) when operating at scale. values chosen should not have too bad an impact on PLC usage, though we might want to split out separate PLC and non-PLC HTTP clients at some point\r\n- drop some timeouts"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/redisdir/redis_directory.go\n@@ -4,6 +4,7 @@ import (\n \t\"context\"\n \t\"errors\"\n \t\"fmt\"\n+\t\"log/slog\"\n \t\"sync\"\n \t\"time\"\n \n@@ -116,9 +117,7 @@ func (d *RedisDirectory) updateHandle(ctx context.Context, h syntax.Handle) hand\n \t\t\tTTL:   d.ErrTTL,\n \t\t})\n \t\tif err != nil {\n-\t\t\the.DID = nil\n-\t\t\the.Err = fmt.Errorf(\"identity cache write failed: %w\", err)\n-\t\t\treturn he\n+\t\t\tslog.Error(\"identity cache write failed\", \"cache\", \"handle\", \"err\", err)\n \t\t}\n \t\treturn he\n \t}\n@@ -141,9 +140,7 @@ func (d *RedisDirectory) updateHandle(ctx context.Context, h syntax.Handle) hand\n \t\tTTL:   d.HitTTL,\n \t})\n \tif err != nil {\n-\t\the.DID = nil\n-\t\the.Err = fmt.Errorf(\"identity cache write failed: %w\", err)\n-\t\treturn he\n+\t\tslog.Error(\"identity cache write failed\", \"cache\", \"did\", \"did\", ident.DID, \"err\", err)\n \t}\n \terr = d.handleCache.Set(&cache.Item{\n \t\tCtx:   ctx,\n@@ -152,9 +149,7 @@ func (d *RedisDirectory) updateHandle(ctx context.Context, h syntax.Handle) hand\n \t\tTTL:   d.HitTTL,\n \t})\n \tif err != nil {\n-\t\the.DID = nil\n-\t\the.Err = fmt.Errorf(\"identity cache write failed: %w\", err)\n-\t\treturn he\n+\t\tslog.Error(\"identity cache write failed\", \"cache\", \"handle\", \"did\", ident.DID, \"err\", err)\n \t}\n \treturn he\n }\n@@ -250,9 +245,7 @@ func (d *RedisDirectory) updateDID(ctx context.Context, did syntax.DID) identity\n \t\tTTL:   d.HitTTL,\n \t})\n \tif err != nil {\n-\t\tentry.Identity = nil\n-\t\tentry.Err = fmt.Errorf(\"identity cache write failed: %w\", err)\n-\t\treturn entry\n+\t\tslog.Error(\"identity cache write failed\", \"cache\", \"did\", \"did\", did, \"err\", err)\n \t}\n \tif he != nil {\n \t\terr = d.handleCache.Set(&cache.Item{\n@@ -262,9 +255,7 @@ func (d *RedisDirectory) updateDID(ctx context.Context, did syntax.DID) identity\n \t\t\tTTL:   d.HitTTL,\n \t\t})\n \t\tif err != nil {\n-\t\t\tentry.Identity = nil\n-\t\t\tentry.Err = fmt.Errorf(\"identity cache write failed: %w\", err)\n-\t\t\treturn entry\n+\t\t\tslog.Error(\"identity cache write failed\", \"cache\", \"handle\", \"did\", did, \"err\", err)\n \t\t}\n \t}\n \treturn entry\n---\n"}], "ideal": "Title: ident: have redis caching dir only log on 'write', not error\n\nBody: This changes the behavior when the redis caching directory successfully resolves an identity, but fails to persist to the cache. The prior behavior was to return an error to the calling code. With this PR, the library will log the error, but return the (successful) resolution result.\r\n\r\nThis helps services ride out intermittent failures (packet loss/corruption) or brief downtimes with caches (eg, redis restarts or machine reboots).\r\n\r\nThe only downside I can think of with this is that the cache being entirely down doesn't get noticed earlier? The package does confirm the connection to redis at startup, so it shouldn't be possible for a mis-configuration or non-existent backend to silently default to \"always resolving\"."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/bgs.go\n@@ -107,20 +107,22 @@ type SocketConsumer struct {\n }\n \n type BGSConfig struct {\n-\tSSL               bool\n-\tCompactInterval   time.Duration\n-\tDefaultRepoLimit  int64\n-\tConcurrencyPerPDS int64\n-\tMaxQueuePerPDS    int64\n+\tSSL                  bool\n+\tCompactInterval      time.Duration\n+\tDefaultRepoLimit     int64\n+\tConcurrencyPerPDS    int64\n+\tMaxQueuePerPDS       int64\n+\tNumCompactionWorkers int\n }\n \n func DefaultBGSConfig() *BGSConfig {\n \treturn &BGSConfig{\n-\t\tSSL:               true,\n-\t\tCompactInterval:   4 * time.Hour,\n-\t\tDefaultRepoLimit:  100,\n-\t\tConcurrencyPerPDS: 100,\n-\t\tMaxQueuePerPDS:    1_000,\n+\t\tSSL:                  true,\n+\t\tCompactInterval:      4 * time.Hour,\n+\t\tDefaultRepoLimit:     100,\n+\t\tConcurrencyPerPDS:    100,\n+\t\tMaxQueuePerPDS:       1_000,\n+\t\tNumCompactionWorkers: 2,\n \t}\n }\n \n@@ -168,7 +170,9 @@ func NewBGS(db *gorm.DB, ix *indexer.Indexer, repoman *repomgr.RepoManager, evtm\n \t\treturn nil, err\n \t}\n \n-\tcompactor := NewCompactor(nil)\n+\tcOpts := DefaultCompactorOptions()\n+\tcOpts.NumWorkers = config.NumCompactionWorkers\n+\tcompactor := NewCompactor(cOpts)\n \tcompactor.requeueInterval = config.CompactInterval\n \tcompactor.Start(bgs)\n \tbgs.compactor = compactor\n---\ncmd/bigsky/main.go\n@@ -195,6 +195,11 @@ func run(args []string) error {\n \t\t\tEnvVars: []string{\"RELAY_EVENT_PLAYBACK_TTL\"},\n \t\t\tValue:   72 * time.Hour,\n \t\t},\n+\t\t&cli.IntFlag{\n+\t\t\tName:    \"num-compaction-workers\",\n+\t\t\tEnvVars: []string{\"RELAY_NUM_COMPACTION_WORKERS\"},\n+\t\t\tValue:   2,\n+\t\t},\n \t}\n \n \tapp.Action = runBigsky\n@@ -413,6 +418,7 @@ func runBigsky(cctx *cli.Context) error {\n \tbgsConfig.ConcurrencyPerPDS = cctx.Int64(\"concurrency-per-pds\")\n \tbgsConfig.MaxQueuePerPDS = cctx.Int64(\"max-queue-per-pds\")\n \tbgsConfig.DefaultRepoLimit = cctx.Int64(\"default-repo-limit\")\n+\tbgsConfig.NumCompactionWorkers = cctx.Int(\"num-compaction-workers\")\n \tbgs, err := libbgs.NewBGS(db, ix, repoman, evtman, cachedidr, rf, hr, bgsConfig)\n \tif err != nil {\n \t\treturn err\n---\n"}], "ideal": "Title: make compaction worker count configurable\n\nBody: Want to be able to tweak this manually so we can turn it higher during off-peak if necessary"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/bigsky/main.go\n@@ -85,7 +85,7 @@ func run(args []string) error {\n \t\t\tName:    \"data-dir\",\n \t\t\tUsage:   \"path of directory for CAR files and other data\",\n \t\t\tValue:   \"data/bigsky\",\n-\t\t\tEnvVars: []string{\"DATA_DIR\"},\n+\t\t\tEnvVars: []string{\"RELAY_DATA_DIR\", \"DATA_DIR\"},\n \t\t},\n \t\t&cli.StringFlag{\n \t\t\tName:    \"plc-host\",\n@@ -112,8 +112,9 @@ func run(args []string) error {\n \t\t\tEnvVars: []string{\"RELAY_METRICS_LISTEN\", \"BGS_METRICS_LISTEN\"},\n \t\t},\n \t\t&cli.StringFlag{\n-\t\t\tName:  \"disk-persister-dir\",\n-\t\t\tUsage: \"set directory for disk persister (implicitly enables disk persister)\",\n+\t\t\tName:    \"disk-persister-dir\",\n+\t\t\tUsage:   \"set directory for disk persister (implicitly enables disk persister)\",\n+\t\t\tEnvVars: []string{\"RELAY_PERSISTER_DIR\"},\n \t\t},\n \t\t&cli.StringFlag{\n \t\t\tName:    \"admin-key\",\n---\n"}], "ideal": "Title: relay: env var for persist dir, and alt env var for data dir\n\nBody: This is mostly driven by feedback from folks running indie relays."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "lex/gen.go\n@@ -232,9 +232,16 @@ func writeMethods(typename string, ts *TypeSchema, w io.Writer) error {\n \tcase \"record\":\n \t\treturn nil\n \tcase \"query\":\n-\t\treturn ts.WriteRPC(w, typename)\n+\t\treturn ts.WriteRPC(w, typename, fmt.Sprintf(\"%s_Input\", typename))\n \tcase \"procedure\":\n-\t\treturn ts.WriteRPC(w, typename)\n+\t\tif ts.Input == nil || ts.Input.Schema == nil || ts.Input.Schema.Type == \"object\" {\n+\t\t\treturn ts.WriteRPC(w, typename, fmt.Sprintf(\"%s_Input\", typename))\n+\t\t} else if ts.Input.Schema.Type == \"ref\" {\n+\t\t\tinputname, _ := ts.namesFromRef(ts.Input.Schema.Ref)\n+\t\t\treturn ts.WriteRPC(w, typename, inputname)\n+\t\t} else {\n+\t\t\treturn fmt.Errorf(\"unhandled input type: %s\", ts.Input.Schema.Type)\n+\t\t}\n \tcase \"object\", \"string\":\n \t\treturn nil\n \tcase \"subscription\":\n---\nlex/type_schema.go\n@@ -50,7 +50,7 @@ type TypeSchema struct {\n \tMaximum any `json:\"maximum\"`\n }\n \n-func (s *TypeSchema) WriteRPC(w io.Writer, typename string) error {\n+func (s *TypeSchema) WriteRPC(w io.Writer, typename, inputname string) error {\n \tpf := printerf(w)\n \tfname := typename\n \n@@ -65,7 +65,7 @@ func (s *TypeSchema) WriteRPC(w io.Writer, typename string) error {\n \t\tcase EncodingCBOR, EncodingCAR, EncodingANY, EncodingMP4:\n \t\t\tparams = fmt.Sprintf(\"%s, input io.Reader\", params)\n \t\tcase EncodingJSON:\n-\t\t\tparams = fmt.Sprintf(\"%s, input *%s_Input\", params, fname)\n+\t\t\tparams = fmt.Sprintf(\"%s, input *%s\", params, inputname)\n \n \t\tdefault:\n \t\t\treturn fmt.Errorf(\"unsupported input encoding (RPC input): %q\", s.Input.Encoding)\n---\n"}], "ideal": "Title: lexgen: handle 'ref' as procedure input type\n\nBody: This tries to resolve the situation discovered in https://github.com/bluesky-social/indigo/pull/785, with the ozone \"upsertSet\" procedure.\r\n\r\nThat lexicon specifies the input schema via reference, instead of an \"object\" schema in-place.\r\n\r\nThis code could use real review, I just banged on it until it worked for the current lexicon."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/engine/account_meta.go\n@@ -25,6 +25,8 @@ type AccountMeta struct {\n \n type ProfileSummary struct {\n \tHasAvatar   bool\n+\tAvatarCid   *string\n+\tBannerCid   *string\n \tDescription *string\n \tDisplayName *string\n }\n---\nautomod/engine/cid_from_cdn_test.go\n@@ -0,0 +1,42 @@\n+package engine\n+\n+import (\n+\t\"github.com/stretchr/testify/assert\"\n+\t\"testing\"\n+)\n+\n+func TestCidFromCdnUrl(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\tfixCid := \"abcdefghijk\"\n+\n+\tfixtures := []struct {\n+\t\turl string\n+\t\tcid *string\n+\t}{\n+\t\t{\n+\t\t\turl: \"https://cdn.bsky.app/img/avatar/plain/did:plc:abc123/abcdefghijk@jpeg\",\n+\t\t\tcid: &fixCid,\n+\t\t},\n+\t\t{\n+\t\t\turl: \"https://cdn.bsky.app/img/feed_fullsize/plain/did:plc:abc123/abcdefghijk@jpeg\",\n+\t\t\tcid: &fixCid,\n+\t\t},\n+\t\t{\n+\t\t\turl: \"https://cdn.bsky.app/img/feed_fullsize\",\n+\t\t\tcid: nil,\n+\t\t},\n+\t\t{\n+\t\t\turl: \"https://cdn.bsky.app/img/feed_fullsize/plain/did:plc:abc123/abcdefghijk\",\n+\t\t\tcid: &fixCid,\n+\t\t},\n+\t\t{\n+\t\t\turl: \"https://cdn.asky.app/img/feed_fullsize/plain/did:plc:abc123/abcdefghijk@jpeg\",\n+\t\t\tcid: nil,\n+\t\t},\n+\t}\n+\n+\tfor _, fix := range fixtures {\n+\t\tassert.Equal(fix.cid, cidFromCdnUrl(&fix.url))\n+\t}\n+}\n---\nautomod/engine/fetch_account_meta.go\n@@ -75,6 +75,8 @@ func (e *Engine) GetAccountMeta(ctx context.Context, ident *identity.Identity) (\n \n \tam.Profile = ProfileSummary{\n \t\tHasAvatar:   pv.Avatar != nil,\n+\t\tAvatarCid:   cidFromCdnUrl(pv.Avatar),\n+\t\tBannerCid:   cidFromCdnUrl(pv.Banner),\n \t\tDescription: pv.Description,\n \t\tDisplayName: pv.DisplayName,\n \t}\n---\nautomod/engine/util.go\n@@ -1,5 +1,10 @@\n package engine\n \n+import (\n+\t\"net/url\"\n+\t\"strings\"\n+)\n+\n func dedupeStrings(in []string) []string {\n \tvar out []string\n \tseen := make(map[string]bool)\n@@ -11,3 +16,22 @@ func dedupeStrings(in []string) []string {\n \t}\n \treturn out\n }\n+\n+// get the cid from a bluesky cdn url\n+func cidFromCdnUrl(str *string) *string {\n+\tif str == nil {\n+\t\treturn nil\n+\t}\n+\n+\tu, err := url.Parse(*str)\n+\tif err != nil || u.Host != \"cdn.bsky.app\" {\n+\t\treturn nil\n+\t}\n+\n+\tparts := strings.Split(u.Path, \"/\")\n+\tif len(parts) != 6 {\n+\t\treturn nil\n+\t}\n+\n+\treturn &strings.Split(parts[5], \"@\")[0]\n+}\n---\n"}], "ideal": "Title: Add avatar to `AccountMeta`\n\nBody: smol change. couple of new rules need avatar cids. currently have to fetch from public api before the rule processes in a separate request which is meh, since we have the info here already."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/helpers.go\n@@ -283,3 +283,60 @@ func AccountIsOlderThan(c *automod.AccountContext, age time.Duration) bool {\n \t}\n \treturn false\n }\n+\n+func PostParentOrRootIsDid(post *appbsky.FeedPost, did string) bool {\n+\tif post.Reply == nil {\n+\t\treturn false\n+\t}\n+\n+\trootUri, err := syntax.ParseATURI(post.Reply.Root.Uri)\n+\tif err != nil || !rootUri.Authority().IsDID() {\n+\t\treturn false\n+\t}\n+\n+\tparentUri, err := syntax.ParseATURI(post.Reply.Parent.Uri)\n+\tif err != nil || !parentUri.Authority().IsDID() {\n+\t\treturn false\n+\t}\n+\n+\treturn rootUri.Authority().String() == did || parentUri.Authority().String() == did\n+}\n+\n+func PostParentOrRootIsAnyDid(post *appbsky.FeedPost, dids []string) bool {\n+\tif post.Reply == nil {\n+\t\treturn false\n+\t}\n+\n+\tfor _, did := range dids {\n+\t\tif PostParentOrRootIsDid(post, did) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\n+\treturn false\n+}\n+\n+func PostMentionsDid(post *appbsky.FeedPost, did string) bool {\n+\tfacets, err := ExtractFacets(post)\n+\tif err != nil {\n+\t\treturn false\n+\t}\n+\n+\tfor _, facet := range facets {\n+\t\tif facet.DID != nil && *facet.DID == did {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\n+\treturn false\n+}\n+\n+func PostMentionsAnyDid(post *appbsky.FeedPost, dids []string) bool {\n+\tfor _, did := range dids {\n+\t\tif PostMentionsDid(post, did) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\n+\treturn false\n+}\n---\nautomod/rules/helpers_test.go\n@@ -1,6 +1,8 @@\n package rules\n \n import (\n+\tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n+\tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"testing\"\n \t\"time\"\n \n@@ -115,3 +117,135 @@ func TestAccountIsYoungerThan(t *testing.T) {\n \tassert.True(AccountIsOlderThan(&ac, time.Hour))\n \tassert.False(AccountIsOlderThan(&ac, 48*time.Hour))\n }\n+\n+func TestParentOrRootIsDid(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\tpost1 := &appbsky.FeedPost{\n+\t\tText: \"some random post that i dreamt up last night, idk\",\n+\t\tReply: &appbsky.FeedPost_ReplyRef{\n+\t\t\tRoot: &comatproto.RepoStrongRef{\n+\t\t\t\tUri: \"at://did:plc:abc123/app.bsky.feed.post/rkey123\",\n+\t\t\t},\n+\t\t\tParent: &comatproto.RepoStrongRef{\n+\t\t\t\tUri: \"at://did:plc:abc123/app.bsky.feed.post/rkey123\",\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tpost2 := &appbsky.FeedPost{\n+\t\tText: \"some random post that i dreamt up last night, idk\",\n+\t\tReply: &appbsky.FeedPost_ReplyRef{\n+\t\t\tRoot: &comatproto.RepoStrongRef{\n+\t\t\t\tUri: \"at://did:plc:321abc/app.bsky.feed.post/rkey123\",\n+\t\t\t},\n+\t\t\tParent: &comatproto.RepoStrongRef{\n+\t\t\t\tUri: \"at://did:plc:abc123/app.bsky.feed.post/rkey123\",\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tpost3 := &appbsky.FeedPost{\n+\t\tText: \"some random post that i dreamt up last night, idk\",\n+\t\tReply: &appbsky.FeedPost_ReplyRef{\n+\t\t\tRoot: &comatproto.RepoStrongRef{\n+\t\t\t\tUri: \"at://did:plc:abc123/app.bsky.feed.post/rkey123\",\n+\t\t\t},\n+\t\t\tParent: &comatproto.RepoStrongRef{\n+\t\t\t\tUri: \"at://did:plc:321abc/app.bsky.feed.post/rkey123\",\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tpost4 := &appbsky.FeedPost{\n+\t\tText: \"some random post that i dreamt up last night, idk\",\n+\t\tReply: &appbsky.FeedPost_ReplyRef{\n+\t\t\tRoot: &comatproto.RepoStrongRef{\n+\t\t\t\tUri: \"at://did:plc:321abc/app.bsky.feed.post/rkey123\",\n+\t\t\t},\n+\t\t\tParent: &comatproto.RepoStrongRef{\n+\t\t\t\tUri: \"at://did:plc:321abc/app.bsky.feed.post/rkey123\",\n+\t\t\t},\n+\t\t},\n+\t}\n+\n+\tassert.True(PostParentOrRootIsDid(post1, \"did:plc:abc123\"))\n+\tassert.False(PostParentOrRootIsDid(post1, \"did:plc:321abc\"))\n+\n+\tassert.True(PostParentOrRootIsDid(post2, \"did:plc:abc123\"))\n+\tassert.True(PostParentOrRootIsDid(post2, \"did:plc:321abc\"))\n+\n+\tassert.True(PostParentOrRootIsDid(post3, \"did:plc:abc123\"))\n+\tassert.True(PostParentOrRootIsDid(post3, \"did:plc:321abc\"))\n+\n+\tassert.False(PostParentOrRootIsDid(post4, \"did:plc:abc123\"))\n+\tassert.True(PostParentOrRootIsDid(post4, \"did:plc:321abc\"))\n+\n+\tdidList1 := []string{\n+\t\t\"did:plc:cba321\",\n+\t\t\"did:web:bsky.app\",\n+\t\t\"did:plc:abc123\",\n+\t}\n+\n+\tdidList2 := []string{\n+\t\t\"did:plc:321cba\",\n+\t\t\"did:web:bsky.app\",\n+\t\t\"did:plc:123abc\",\n+\t}\n+\n+\tassert.True(PostParentOrRootIsAnyDid(post1, didList1))\n+\tassert.False(PostParentOrRootIsAnyDid(post1, didList2))\n+}\n+\n+func TestPostMentionsDid(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\tpost := &appbsky.FeedPost{\n+\t\tText: \"@hailey.at what is upppp also hello to @darthbluesky.bsky.social\",\n+\t\tFacets: []*appbsky.RichtextFacet{\n+\t\t\t{\n+\t\t\t\tFeatures: []*appbsky.RichtextFacet_Features_Elem{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tRichtextFacet_Mention: &appbsky.RichtextFacet_Mention{\n+\t\t\t\t\t\t\tDid: \"did:plc:abc123\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tIndex: &appbsky.RichtextFacet_ByteSlice{\n+\t\t\t\t\tByteStart: 0,\n+\t\t\t\t\tByteEnd:   9,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tFeatures: []*appbsky.RichtextFacet_Features_Elem{\n+\t\t\t\t\t{\n+\t\t\t\t\t\tRichtextFacet_Mention: &appbsky.RichtextFacet_Mention{\n+\t\t\t\t\t\t\tDid: \"did:plc:abc456\",\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tIndex: &appbsky.RichtextFacet_ByteSlice{\n+\t\t\t\t\tByteStart: 39,\n+\t\t\t\t\tByteEnd:   63,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}\n+\tassert.True(PostMentionsDid(post, \"did:plc:abc123\"))\n+\tassert.False(PostMentionsDid(post, \"did:plc:cba321\"))\n+\n+\tdidList1 := []string{\n+\t\t\"did:plc:cba321\",\n+\t\t\"did:web:bsky.app\",\n+\t\t\"did:plc:abc456\",\n+\t}\n+\n+\tdidList2 := []string{\n+\t\t\"did:plc:321cba\",\n+\t\t\"did:web:bsky.app\",\n+\t\t\"did:plc:123abc\",\n+\t}\n+\n+\tassert.True(PostMentionsAnyDid(post, didList1))\n+\tassert.False(PostMentionsAnyDid(post, didList2))\n+}\n---\n"}], "ideal": "Title: add `PostParentOrRootIsDid` and `PostMentionsDid` to automod helpers\n\nBody: couple of helpers for a case i keep running into."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/backfill.go\n@@ -119,7 +119,7 @@ func DefaultBackfillOptions() *BackfillOptions {\n \t\tParallelRecordCreates: 100,\n \t\tNSIDFilter:            \"\",\n \t\tSyncRequestsPerSecond: 2,\n-\t\tCheckoutPath:          \"https://bsky.social/xrpc/com.atproto.sync.getRepo\",\n+\t\tCheckoutPath:          \"https://bsky.network/xrpc/com.atproto.sync.getRepo\",\n \t}\n }\n \n---\n"}], "ideal": "Title: backfill: checkout from relay, not entryway\n\nBody: This is pretty drive-by, i'm basically going through our public code and removing direct requests against the entryway (`https://bsky.social/xrpc/...`). It might be more appropriate here to resolve to the user's actual PDS, not sure."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/keyword/tokenize.go\n@@ -12,18 +12,19 @@ import (\n )\n \n var (\n-\tpuncChars     = regexp.MustCompile(`[[:punct:]]+`)\n-\tnonTokenChars = regexp.MustCompile(`[^\\pL\\pN\\s]+`)\n+\tpuncChars                    = regexp.MustCompile(`[[:punct:]]+`)\n+\tnonTokenChars                = regexp.MustCompile(`[^\\pL\\pN\\s]+`)\n+\tnonTokenCharsSkipCensorChars = regexp.MustCompile(`[^\\pL\\pN\\s#*_-]`)\n )\n \n // Splits free-form text in to tokens, including lower-case, unicode normalization, and some unicode folding.\n //\n // The intent is for this to work similarly to an NLP tokenizer, as might be used in a fulltext search engine, and enable fast matching to a list of known tokens. It might eventually even do stemming, removing pluralization (trailing \"s\" for English), etc.\n-func TokenizeText(text string) []string {\n+func TokenizeTextWithRegex(text string, nonTokenCharsRegex *regexp.Regexp) []string {\n \t// this function needs to be re-defined in every function call to prevent a race condition\n \tnormFunc := transform.Chain(norm.NFD, runes.Remove(runes.In(unicode.Mn)), norm.NFC)\n-\tsplit := strings.ToLower(nonTokenChars.ReplaceAllString(text, \" \"))\n-\tbare := strings.ToLower(nonTokenChars.ReplaceAllString(split, \"\"))\n+\tsplit := strings.ToLower(nonTokenCharsRegex.ReplaceAllString(text, \" \"))\n+\tbare := strings.ToLower(nonTokenCharsRegex.ReplaceAllString(split, \"\"))\n \tnorm, _, err := transform.String(normFunc, bare)\n \tif err != nil {\n \t\tslog.Warn(\"unicode normalization error\", \"err\", err)\n@@ -32,6 +33,14 @@ func TokenizeText(text string) []string {\n \treturn strings.Fields(norm)\n }\n \n+func TokenizeText(text string) []string {\n+\treturn TokenizeTextWithRegex(text, nonTokenChars)\n+}\n+\n+func TokenizeTextSkippingCensorChars(text string) []string {\n+\treturn TokenizeTextWithRegex(text, nonTokenCharsSkipCensorChars)\n+}\n+\n func splitIdentRune(c rune) bool {\n \treturn !unicode.IsLetter(c) && !unicode.IsNumber(c)\n }\n---\nautomod/keyword/tokenize_test.go\n@@ -1,6 +1,7 @@\n package keyword\n \n import (\n+\t\"regexp\"\n \t\"testing\"\n \n \t\"github.com/stretchr/testify/assert\"\n@@ -17,13 +18,59 @@ func TestTokenizeText(t *testing.T) {\n \t\t{text: \"Hello, \u0e42\u0e25\u0e01!\", out: []string{\"hello\", \"\u0e42\u0e25\u0e01\"}},\n \t\t{text: \"Gda\u0144sk\", out: []string{\"gdansk\"}},\n \t\t{text: \" foo1;bar2,baz3...\", out: []string{\"foo1\", \"bar2\", \"baz3\"}},\n+\t\t{text: \"foo*bar\", out: []string{\"foo\", \"bar\"}},\n+\t\t{text: \"foo-bar\", out: []string{\"foo\", \"bar\"}},\n+\t\t{text: \"foo_bar\", out: []string{\"foo\", \"bar\"}},\n \t}\n \n \tfor _, fix := range fixtures {\n \t\tassert.Equal(fix.out, TokenizeText(fix.text))\n \t}\n }\n \n+func TestTokenizeTextWithCensorChars(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\tfixtures := []struct {\n+\t\ttext string\n+\t\tout  []string\n+\t}{\n+\t\t{text: \"\", out: []string{}},\n+\t\t{text: \"Hello, \u0e42\u0e25\u0e01!\", out: []string{\"hello\", \"\u0e42\u0e25\u0e01\"}},\n+\t\t{text: \"Gda\u0144sk\", out: []string{\"gdansk\"}},\n+\t\t{text: \" foo1;bar2,baz3...\", out: []string{\"foo1\", \"bar2\", \"baz3\"}},\n+\t\t{text: \"foo*bar,foo&bar\", out: []string{\"foo*bar\", \"foo\", \"bar\"}},\n+\t\t{text: \"foo-bar,foo&bar\", out: []string{\"foo-bar\", \"foo\", \"bar\"}},\n+\t\t{text: \"foo_bar,foo&bar\", out: []string{\"foo_bar\", \"foo\", \"bar\"}},\n+\t\t{text: \"foo#bar,foo&bar\", out: []string{\"foo#bar\", \"foo\", \"bar\"}},\n+\t}\n+\n+\tfor _, fix := range fixtures {\n+\t\tassert.Equal(fix.out, TokenizeTextSkippingCensorChars(fix.text))\n+\t}\n+}\n+\n+func TestTokenizeTextWithCustomRegex(t *testing.T) {\n+\tassert := assert.New(t)\n+\n+\tfixtures := []struct {\n+\t\ttext string\n+\t\tout  []string\n+\t}{\n+\t\t{text: \"\", out: []string{}},\n+\t\t{text: \"Hello, \u0e42\u0e25\u0e01!\", out: []string{\"hello\", \"\u0e42\u0e25\u0e01\"}},\n+\t\t{text: \"Gda\u0144sk\", out: []string{\"gdansk\"}},\n+\t\t{text: \" foo1;bar2,baz3...\", out: []string{\"foo1\", \"bar2\", \"baz3\"}},\n+\t\t{text: \"foo*bar\", out: []string{\"foo\", \"bar\"}},\n+\t\t{text: \"foo&bar,foo*bar\", out: []string{\"foo&bar\", \"foo\", \"bar\"}},\n+\t}\n+\n+\tregex := regexp.MustCompile(`[^\\pL\\pN\\s&]`)\n+\tfor _, fix := range fixtures {\n+\t\tassert.Equal(fix.out, TokenizeTextWithRegex(fix.text, regex))\n+\t}\n+}\n+\n func TestTokenizeIdentifier(t *testing.T) {\n \tassert := assert.New(t)\n \n---\n"}], "ideal": "Title: support tokenize while keeping common censor chars\n\nBody: There are some cases where it's useful to tokenize a string while _not_ splitting on some non-letter chars like `#`, `*`, `-`, or `_`. Unfortunately right now `Tokenize` will split on all of these, making some matching difficult.\r\n\r\nThis just adds a second `TokenizeTextSkippingCensorChars` for those particular use cases. Also adding `TokenizeTextWithRegex`, so that other cases can be easily covered in the future if they arise."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "mst/mst.go\n@@ -113,7 +113,7 @@ func CBORTypes() []reflect.Type {\n // MST tree node as gets serialized to CBOR. Note that the CBOR fields are all\n // single-character.\n type nodeData struct {\n-\tLeft    *cid.Cid    `cborgen:\"l\"` // [optional] pointer to lower-level subtree to the \"left\" of this path/key\n+\tLeft    *cid.Cid    `cborgen:\"l\"` // [nullable] pointer to lower-level subtree to the \"left\" of this path/key\n \tEntries []treeEntry `cborgen:\"e\"` // ordered list of entries at this node\n }\n \n@@ -122,7 +122,7 @@ type treeEntry struct {\n \tPrefixLen int64    `cborgen:\"p\"` // count of characters shared with previous path/key in tree\n \tKeySuffix []byte   `cborgen:\"k\"` // remaining part of path/key (appended to \"previous key\")\n \tVal       cid.Cid  `cborgen:\"v\"` // CID pointer at this path/key\n-\tTree      *cid.Cid `cborgen:\"t\"` // [optional] pointer to lower-level subtree to the \"right\" of this path/key entry\n+\tTree      *cid.Cid `cborgen:\"t\"` // [nullable] pointer to lower-level subtree to the \"right\" of this path/key entry\n }\n \n // MerkleSearchTree represents an MST tree node (NodeData type). It can be in\n---\n"}], "ideal": "Title: mst: clarify in comment that fields are nullable, not optional\n\nBody: See also: https://github.com/bluesky-social/atproto-website/pull/346"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/identity.go\n@@ -32,7 +32,7 @@ func NewAccountRule(c *automod.AccountContext) error {\n \n \t\t// new PDS host\n \t\tif existingAccounts == 0 {\n-\t\t\tc.Logger.Info(\"new PDS instance\", \"host\", pdsHost)\n+\t\t\tc.Logger.Info(\"new PDS instance\", \"pdsHost\", pdsHost)\n \t\t\tc.Increment(\"host\", \"new\")\n \t\t\tc.AddAccountFlag(\"host-first-account\")\n \t\t\tc.Notify(\"slack\")\n---\nbgs/bgs.go\n@@ -800,7 +800,7 @@ func (bgs *BGS) handleFedEvent(ctx context.Context, host *models.PDS, env *event\n \tcase env.RepoCommit != nil:\n \t\trepoCommitsReceivedCounter.WithLabelValues(host.Host).Add(1)\n \t\tevt := env.RepoCommit\n-\t\tlog.Debugw(\"bgs got repo append event\", \"seq\", evt.Seq, \"host\", host.Host, \"repo\", evt.Repo)\n+\t\tlog.Debugw(\"bgs got repo append event\", \"seq\", evt.Seq, \"pdsHost\", host.Host, \"repo\", evt.Repo)\n \t\tu, err := bgs.lookupUserByDid(ctx, evt.Repo)\n \t\tif err != nil {\n \t\t\tif !errors.Is(err, gorm.ErrRecordNotFound) {\n@@ -822,17 +822,17 @@ func (bgs *BGS) handleFedEvent(ctx context.Context, host *models.PDS, env *event\n \n \t\tif u.TakenDown || u.UpstreamStatus == events.AccountStatusTakendown {\n \t\t\tspan.SetAttributes(attribute.Bool(\"taken_down_by_relay_admin\", u.TakenDown))\n-\t\t\tlog.Debugw(\"dropping commit event from taken down user\", \"did\", evt.Repo, \"seq\", evt.Seq, \"host\", host.Host)\n+\t\t\tlog.Debugw(\"dropping commit event from taken down user\", \"did\", evt.Repo, \"seq\", evt.Seq, \"pdsHost\", host.Host)\n \t\t\treturn nil\n \t\t}\n \n \t\tif u.UpstreamStatus == events.AccountStatusSuspended {\n-\t\t\tlog.Debugw(\"dropping commit event from suspended user\", \"did\", evt.Repo, \"seq\", evt.Seq, \"host\", host.Host)\n+\t\t\tlog.Debugw(\"dropping commit event from suspended user\", \"did\", evt.Repo, \"seq\", evt.Seq, \"pdsHost\", host.Host)\n \t\t\treturn nil\n \t\t}\n \n \t\tif u.UpstreamStatus == events.AccountStatusDeactivated {\n-\t\t\tlog.Debugw(\"dropping commit event from deactivated user\", \"did\", evt.Repo, \"seq\", evt.Seq, \"host\", host.Host)\n+\t\t\tlog.Debugw(\"dropping commit event from deactivated user\", \"did\", evt.Repo, \"seq\", evt.Seq, \"pdsHost\", host.Host)\n \t\t\treturn nil\n \t\t}\n \n@@ -891,7 +891,7 @@ func (bgs *BGS) handleFedEvent(ctx context.Context, host *models.PDS, env *event\n \t\t}\n \n \t\tif err := bgs.repoman.HandleExternalUserEvent(ctx, host.ID, u.ID, u.Did, evt.Since, evt.Rev, evt.Blocks, evt.Ops); err != nil {\n-\t\t\tlog.Warnw(\"failed handling event\", \"err\", err, \"host\", host.Host, \"seq\", evt.Seq, \"repo\", u.Did, \"prev\", stringLink(evt.Prev), \"commit\", evt.Commit.String())\n+\t\t\tlog.Warnw(\"failed handling event\", \"err\", err, \"pdsHost\", host.Host, \"seq\", evt.Seq, \"repo\", u.Did, \"prev\", stringLink(evt.Prev), \"commit\", evt.Commit.String())\n \n \t\t\tif errors.Is(err, carstore.ErrRepoBaseMismatch) || ipld.IsNotFound(err) {\n \t\t\t\tai, lerr := bgs.Index.LookupUser(ctx, u.ID)\n---\nbgs/fedmgr.go\n@@ -481,12 +481,12 @@ func (s *Slurper) subscribeWithRedialer(ctx context.Context, host *models.PDS, s\n \t\turl := fmt.Sprintf(\"%s://%s/xrpc/com.atproto.sync.subscribeRepos?cursor=%d\", protocol, host.Host, cursor)\n \t\tcon, res, err := d.DialContext(ctx, url, nil)\n \t\tif err != nil {\n-\t\t\tlog.Warnw(\"dialing failed\", \"host\", host.Host, \"err\", err, \"backoff\", backoff)\n+\t\t\tlog.Warnw(\"dialing failed\", \"pdsHost\", host.Host, \"err\", err, \"backoff\", backoff)\n \t\t\ttime.Sleep(sleepForBackoff(backoff))\n \t\t\tbackoff++\n \n \t\t\tif backoff > 15 {\n-\t\t\t\tlog.Warnw(\"pds does not appear to be online, disabling for now\", \"host\", host.Host)\n+\t\t\t\tlog.Warnw(\"pds does not appear to be online, disabling for now\", \"pdsHost\", host.Host)\n \t\t\t\tif err := s.db.Model(&models.PDS{}).Where(\"id = ?\", host.ID).Update(\"registered\", false).Error; err != nil {\n \t\t\t\t\tlog.Errorf(\"failed to unregister failing pds: %w\", err)\n \t\t\t\t}\n@@ -536,7 +536,7 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \n \trsc := &events.RepoStreamCallbacks{\n \t\tRepoCommit: func(evt *comatproto.SyncSubscribeRepos_Commit) error {\n-\t\t\tlog.Debugw(\"got remote repo event\", \"host\", host.Host, \"repo\", evt.Repo, \"seq\", evt.Seq)\n+\t\t\tlog.Debugw(\"got remote repo event\", \"pdsHost\", host.Host, \"repo\", evt.Repo, \"seq\", evt.Seq)\n \t\t\tif err := s.cb(context.TODO(), host, &events.XRPCStreamEvent{\n \t\t\t\tRepoCommit: evt,\n \t\t\t}); err != nil {\n@@ -551,7 +551,7 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\treturn nil\n \t\t},\n \t\tRepoHandle: func(evt *comatproto.SyncSubscribeRepos_Handle) error {\n-\t\t\tlog.Infow(\"got remote handle update event\", \"host\", host.Host, \"did\", evt.Did, \"handle\", evt.Handle)\n+\t\t\tlog.Infow(\"got remote handle update event\", \"pdsHost\", host.Host, \"did\", evt.Did, \"handle\", evt.Handle)\n \t\t\tif err := s.cb(context.TODO(), host, &events.XRPCStreamEvent{\n \t\t\t\tRepoHandle: evt,\n \t\t\t}); err != nil {\n@@ -566,7 +566,7 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\treturn nil\n \t\t},\n \t\tRepoMigrate: func(evt *comatproto.SyncSubscribeRepos_Migrate) error {\n-\t\t\tlog.Infow(\"got remote repo migrate event\", \"host\", host.Host, \"did\", evt.Did, \"migrateTo\", evt.MigrateTo)\n+\t\t\tlog.Infow(\"got remote repo migrate event\", \"pdsHost\", host.Host, \"did\", evt.Did, \"migrateTo\", evt.MigrateTo)\n \t\t\tif err := s.cb(context.TODO(), host, &events.XRPCStreamEvent{\n \t\t\t\tRepoMigrate: evt,\n \t\t\t}); err != nil {\n@@ -581,7 +581,7 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\treturn nil\n \t\t},\n \t\tRepoTombstone: func(evt *comatproto.SyncSubscribeRepos_Tombstone) error {\n-\t\t\tlog.Infow(\"got remote repo tombstone event\", \"host\", host.Host, \"did\", evt.Did)\n+\t\t\tlog.Infow(\"got remote repo tombstone event\", \"pdsHost\", host.Host, \"did\", evt.Did)\n \t\t\tif err := s.cb(context.TODO(), host, &events.XRPCStreamEvent{\n \t\t\t\tRepoTombstone: evt,\n \t\t\t}); err != nil {\n@@ -596,7 +596,7 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\treturn nil\n \t\t},\n \t\tRepoInfo: func(info *comatproto.SyncSubscribeRepos_Info) error {\n-\t\t\tlog.Infow(\"info event\", \"name\", info.Name, \"message\", info.Message, \"host\", host.Host)\n+\t\t\tlog.Infow(\"info event\", \"name\", info.Name, \"message\", info.Message, \"pdsHost\", host.Host)\n \t\t\treturn nil\n \t\t},\n \t\tRepoIdentity: func(ident *comatproto.SyncSubscribeRepos_Identity) error {\n---\ncmd/athome/handlers.go\n@@ -17,7 +17,7 @@ func (srv *Server) reqHandle(c echo.Context) syntax.Handle {\n \thost = strings.SplitN(host, \":\", 2)[0]\n \thandle, err := syntax.ParseHandle(host)\n \tif err != nil {\n-\t\tslog.Warn(\"host is not a valid handle, fallback to default\", \"host\", host)\n+\t\tslog.Warn(\"host is not a valid handle, fallback to default\", \"hostname\", host)\n \t\thandle = srv.defaultHandle\n \t}\n \treturn handle\n---\ncmd/hepa/server.go\n@@ -95,7 +95,7 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\t\treturn nil, fmt.Errorf(\"ozone account DID supplied was not valid: %v\", err)\n \t\t}\n \t\tozoneClient.Auth.Did = od.String()\n-\t\tlogger.Info(\"configured ozone admin client\", \"did\", od.String(), \"host\", config.OzoneHost)\n+\t\tlogger.Info(\"configured ozone admin client\", \"did\", od.String(), \"ozoneHost\", config.OzoneHost)\n \t} else {\n \t\tlogger.Info(\"did not configure ozone client\")\n \t}\n@@ -112,7 +112,7 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\t\tadminClient.Headers = make(map[string]string)\n \t\t\tadminClient.Headers[\"x-ratelimit-bypass\"] = config.RatelimitBypass\n \t\t}\n-\t\tlogger.Info(\"configured PDS admin client\", \"host\", config.PDSHost)\n+\t\tlogger.Info(\"configured PDS admin client\", \"pdsHost\", config.PDSHost)\n \t} else {\n \t\tlogger.Info(\"did not configure PDS admin client\")\n \t}\n---\n"}], "ideal": "Title: don't use 'host' as structured logging field\n\nBody: at least in datadog, the structured logging 'host' field clobbers host metadata for the log line.\r\n\r\nthis might not impact loko, but seems reasonable to just avoid the naming collision generally."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "api/atproto/serverrefreshSession.go\n@@ -24,6 +24,12 @@ type ServerRefreshSession_Output struct {\n \n // ServerRefreshSession calls the XRPC method \"com.atproto.server.refreshSession\".\n func ServerRefreshSession(ctx context.Context, c *xrpc.Client) (*ServerRefreshSession_Output, error) {\n+\t// For refreshing the session, we need to use the RefreshJwt.\n+\t// Do only looks at AccessJwt so we need to copy the RefreshJwt token to it.\n+\tif c.Auth != nil && c.Auth.RefreshJwt != \"\" {\n+\t\tc.Auth.AccessJwt = c.Auth.RefreshJwt\n+\t}\n+\n \tvar out ServerRefreshSession_Output\n \tif err := c.Do(ctx, xrpc.Procedure, \"\", \"com.atproto.server.refreshSession\", nil, nil, &out); err != nil {\n \t\treturn nil, err\n---\n"}], "ideal": "Title: Use RefreshJwt when calling ServerRefreshSession.\n\nBody: *xrpc.Client.Do only looks at Auth.AccessJwt when adding the jwt token, so I changed ServerRefreshSession to copy the RefreshJwt token to it before calling Do.\r\n\r\nAlternatively, we can change Do to use RefreshJwt if the method is \"com.atproto.server.refreshSession\". I'm fine either way, though adding more custom logic to Do makes it less and less a generic Do."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/goat/net.go\n@@ -3,40 +3,31 @@ package main\n import (\n \t\"context\"\n \t\"fmt\"\n-\t\"io\"\n \t\"log/slog\"\n-\t\"net/http\"\n \n \t\"github.com/bluesky-social/indigo/atproto/data\"\n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n+\t\"github.com/bluesky-social/indigo/xrpc\"\n )\n \n func fetchRecord(ctx context.Context, ident identity.Identity, aturi syntax.ATURI) (any, error) {\n-\tpdsURL := ident.PDSEndpoint()\n \n \tslog.Debug(\"fetching record\", \"did\", ident.DID.String(), \"collection\", aturi.Collection().String(), \"rkey\", aturi.RecordKey().String())\n-\turl := fmt.Sprintf(\"%s/xrpc/com.atproto.repo.getRecord?repo=%s&collection=%s&rkey=%s\",\n-\t\tpdsURL, ident.DID, aturi.Collection(), aturi.RecordKey())\n-\tresp, err := http.Get(url)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\tif resp.StatusCode != http.StatusOK {\n-\t\treturn nil, fmt.Errorf(\"fetch failed\")\n+\txrpcc := xrpc.Client{\n+\t\tHost: ident.PDSEndpoint(),\n \t}\n-\trespBytes, err := io.ReadAll(resp.Body)\n+\tresp, err := RepoGetRecord(ctx, &xrpcc, \"\", aturi.Collection().String(), ident.DID.String(), aturi.RecordKey().String())\n \tif err != nil {\n \t\treturn nil, err\n \t}\n \n-\tbody, err := data.UnmarshalJSON(respBytes)\n-\tif err != nil {\n-\t\treturn nil, err\n+\tif nil == resp.Value {\n+\t\treturn nil, fmt.Errorf(\"empty record in response\")\n \t}\n-\trecord, ok := body[\"value\"].(map[string]any)\n-\tif !ok {\n-\t\treturn nil, fmt.Errorf(\"fetched record was not an object\")\n+\trecord, err := data.UnmarshalJSON(*resp.Value)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"fetched record was invalid data: %w\", err)\n \t}\n \treturn record, nil\n }\n---\ncmd/goat/record.go\n@@ -180,7 +180,7 @@ func runRecordList(cctx *cli.Context) error {\n \t\tcursor := \"\"\n \t\tfor {\n \t\t\t// collection string, cursor string, limit int64, repo string, reverse bool, rkeyEnd string, rkeyStart string\n-\t\t\tresp, err := comatproto.RepoListRecords(ctx, &xrpcc, nsid, cursor, 100, ident.DID.String(), false, \"\", \"\")\n+\t\t\tresp, err := RepoListRecords(ctx, &xrpcc, nsid, cursor, 100, ident.DID.String(), false, \"\", \"\")\n \t\t\tif err != nil {\n \t\t\t\treturn err\n \t\t\t}\n@@ -295,7 +295,7 @@ func runRecordUpdate(cctx *cli.Context) error {\n \trkey := cctx.String(\"rkey\")\n \n \t// NOTE: need to fetch existing record CID to perform swap. this is optional in theory, but golang can't deal with \"optional\" and \"nullable\", so we always need to set this (?)\n-\texisting, err := comatproto.RepoGetRecord(ctx, xrpcc, \"\", nsid, xrpcc.Auth.Did, rkey)\n+\texisting, err := RepoGetRecord(ctx, xrpcc, \"\", nsid, xrpcc.Auth.Did, rkey)\n \tif err != nil {\n \t\treturn err\n \t}\n---\ncmd/goat/repogetRecord.go\n@@ -0,0 +1,42 @@\n+// Copied from indigo:api/atproto/repolistRecords.go\n+\n+package main\n+\n+// schema: com.atproto.repo.getRecord\n+\n+import (\n+\t\"context\"\n+\t\"encoding/json\"\n+\n+\t\"github.com/bluesky-social/indigo/xrpc\"\n+)\n+\n+// RepoGetRecord_Output is the output of a com.atproto.repo.getRecord call.\n+type RepoGetRecord_Output struct {\n+\tCid *string `json:\"cid,omitempty\" cborgen:\"cid,omitempty\"`\n+\tUri string  `json:\"uri\" cborgen:\"uri\"`\n+\t//  NOTE: changed from lex decoder to json.RawMessage\n+\tValue *json.RawMessage `json:\"value\" cborgen:\"value\"`\n+}\n+\n+// RepoGetRecord calls the XRPC method \"com.atproto.repo.getRecord\".\n+//\n+// cid: The CID of the version of the record. If not specified, then return the most recent version.\n+// collection: The NSID of the record collection.\n+// repo: The handle or DID of the repo.\n+// rkey: The Record Key.\n+func RepoGetRecord(ctx context.Context, c *xrpc.Client, cid string, collection string, repo string, rkey string) (*RepoGetRecord_Output, error) {\n+\tvar out RepoGetRecord_Output\n+\n+\tparams := map[string]interface{}{\n+\t\t\"cid\":        cid,\n+\t\t\"collection\": collection,\n+\t\t\"repo\":       repo,\n+\t\t\"rkey\":       rkey,\n+\t}\n+\tif err := c.Do(ctx, xrpc.Query, \"\", \"com.atproto.repo.getRecord\", params, nil, &out); err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treturn &out, nil\n+}\n---\ncmd/goat/repolistRecords.go\n@@ -0,0 +1,53 @@\n+// Copied from indigo:api/atproto/repolistRecords.go\n+\n+package main\n+\n+// schema: com.atproto.repo.listRecords\n+\n+import (\n+\t\"context\"\n+\t\"encoding/json\"\n+\n+\t\"github.com/bluesky-social/indigo/xrpc\"\n+)\n+\n+// RepoListRecords_Output is the output of a com.atproto.repo.listRecords call.\n+type RepoListRecords_Output struct {\n+\tCursor  *string                   `json:\"cursor,omitempty\" cborgen:\"cursor,omitempty\"`\n+\tRecords []*RepoListRecords_Record `json:\"records\" cborgen:\"records\"`\n+}\n+\n+// RepoListRecords_Record is a \"record\" in the com.atproto.repo.listRecords schema.\n+type RepoListRecords_Record struct {\n+\tCid string `json:\"cid\" cborgen:\"cid\"`\n+\tUri string `json:\"uri\" cborgen:\"uri\"`\n+\t//  NOTE: changed from lex decoder to json.RawMessage\n+\tValue *json.RawMessage `json:\"value\" cborgen:\"value\"`\n+}\n+\n+// RepoListRecords calls the XRPC method \"com.atproto.repo.listRecords\".\n+//\n+// collection: The NSID of the record type.\n+// limit: The number of records to return.\n+// repo: The handle or DID of the repo.\n+// reverse: Flag to reverse the order of the returned records.\n+// rkeyEnd: DEPRECATED: The highest sort-ordered rkey to stop at (exclusive)\n+// rkeyStart: DEPRECATED: The lowest sort-ordered rkey to start from (exclusive)\n+func RepoListRecords(ctx context.Context, c *xrpc.Client, collection string, cursor string, limit int64, repo string, reverse bool, rkeyEnd string, rkeyStart string) (*RepoListRecords_Output, error) {\n+\tvar out RepoListRecords_Output\n+\n+\tparams := map[string]interface{}{\n+\t\t\"collection\": collection,\n+\t\t\"cursor\":     cursor,\n+\t\t\"limit\":      limit,\n+\t\t\"repo\":       repo,\n+\t\t\"reverse\":    reverse,\n+\t\t\"rkeyEnd\":    rkeyEnd,\n+\t\t\"rkeyStart\":  rkeyStart,\n+\t}\n+\tif err := c.Do(ctx, xrpc.Query, \"\", \"com.atproto.repo.listRecords\", params, nil, &out); err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treturn &out, nil\n+}\n---\n"}], "ideal": "Title: goat: generic record data\n\nBody: Little hack to make `goat` work better with generic record data, aka when we don't know the Lexicon. In this context, just dumping the JSON to stdout (pretty printed).\r\n\r\nSharing b/c we might want to do this generally, at least for API endpoints: `json.RawMessage` instead of `lexutil.LexiconTypeDecoder` when we encounter `unknown` schema type. Note that this won't work for records, and the schema rules do allow `unknown` in records, it just hasn't happened yet.\r\n\r\nAnother place we encounter this is DID documents, which don't even have `$type` in the JSON."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/all.go\n@@ -20,6 +20,7 @@ func DefaultRules() automod.RuleSet {\n \t\t\tReplySingleBadWordPostRule,\n \t\t\tAggressivePromotionRule,\n \t\t\tIdenticalReplyPostRule,\n+\t\t\tIdenticalReplyPostSameParentRule,\n \t\t\tDistinctMentionsRule,\n \t\t\tYoungAccountDistinctMentionsRule,\n \t\t\tMisleadingLinkUnicodeReversalPostRule,\n---\nautomod/rules/replies.go\n@@ -78,6 +78,41 @@ func IdenticalReplyPostRule(c *automod.RecordContext, post *appbsky.FeedPost) er\n \treturn nil\n }\n \n+// Similar to above rule but only counts replies to the same post. More aggressively applies a spam label to new accounts that are less than a day old.\n+var identicalReplySameParentLimit = 3\n+var identicalReplySameParentMaxAge = 24 * time.Hour\n+var identicalReplySameParentMaxPosts int64 = 50\n+var _ automod.PostRuleFunc = IdenticalReplyPostSameParentRule\n+\n+func IdenticalReplyPostSameParentRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n+\tif post.Reply == nil || IsSelfThread(c, post) {\n+\t\treturn nil\n+\t}\n+\n+\tif ParentOrRootIsFollower(c, post) {\n+\t\treturn nil\n+\t}\n+\n+\tpostCount := c.Account.PostsCount\n+\tif AccountIsOlderThan(&c.AccountContext, identicalReplySameParentMaxAge) || postCount >= identicalReplySameParentMaxPosts {\n+\t\treturn nil\n+\t}\n+\n+\tperiod := countstore.PeriodHour\n+\tbucket := c.Account.Identity.DID.String() + \"/\" + post.Reply.Parent.Uri + \"/\" + HashOfString(post.Text)\n+\tc.IncrementPeriod(\"reply-text-same-post\", bucket, period)\n+\n+\tcount := c.GetCount(\"reply-text-same-post\", bucket, period)\n+\tif count >= identicalReplySameParentLimit {\n+\t\tc.AddAccountFlag(\"multi-identical-reply-same-post\")\n+\t\tc.ReportAccount(automod.ReportReasonSpam, fmt.Sprintf(\"possible spam (%d identical reply-posts to same post today)\", count))\n+\t\tc.AddAccountLabel(\"spam\")\n+\t\tc.Notify(\"slack\")\n+\t}\n+\n+\treturn nil\n+}\n+\n // TODO: bumping temporarily\n // var youngReplyAccountLimit = 12\n var youngReplyAccountLimit = 30\n---\n"}], "ideal": "Title: add `IdenticalReplyPostSameParentRule` to automod\n\nBody: adds a spam label to accounts that are under 24 hours doing this, otherwise just reports. maybe too hasty on the label, can adjust. (note our client really doesn't make it easy to make an identical post multiple times in a row like this, where even failures will usually close the composer anyway, so its likely to be intentional). same could probably be applied for same author but with a maybe higher limit"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/compactor.go\n@@ -3,6 +3,7 @@ package bgs\n import (\n \t\"context\"\n \t\"fmt\"\n+\t\"math/rand/v2\"\n \t\"sync\"\n \t\"time\"\n \n@@ -82,20 +83,47 @@ func (q *uniQueue) Remove(uid models.Uid) {\n }\n \n // Pop pops the first item off the front of the queue\n-func (q *uniQueue) Pop() (*queueItem, bool) {\n+func (q *uniQueue) Pop() (queueItem, bool) {\n \tq.lk.Lock()\n \tdefer q.lk.Unlock()\n \n \tif len(q.q) == 0 {\n-\t\treturn nil, false\n+\t\treturn queueItem{}, false\n \t}\n \n \titem := q.q[0]\n \tq.q = q.q[1:]\n \tdelete(q.members, item.uid)\n \n \tcompactionQueueDepth.Dec()\n-\treturn &item, true\n+\treturn item, true\n+}\n+\n+// PopRandom pops a random item off the of the queue\n+// Note: this disrupts the sorted order of the queue and in-order is no longer quite in-order. The randomly popped element is replaced with the last element.\n+func (q *uniQueue) PopRandom() (queueItem, bool) {\n+\tq.lk.Lock()\n+\tdefer q.lk.Unlock()\n+\n+\tif len(q.q) == 0 {\n+\t\treturn queueItem{}, false\n+\t}\n+\n+\tvar item queueItem\n+\tif len(q.q) == 1 {\n+\t\titem = q.q[0]\n+\t\tq.q = nil\n+\t} else {\n+\t\tpos := rand.IntN(len(q.q))\n+\t\titem = q.q[pos]\n+\t\tlast := len(q.q) - 1\n+\t\tq.q[pos] = q.q[last]\n+\t\tq.q = q.q[:last]\n+\t}\n+\tdelete(q.members, item.uid)\n+\n+\tcompactionQueueDepth.Dec()\n+\treturn item, true\n }\n \n type CompactorState struct {\n@@ -105,24 +133,33 @@ type CompactorState struct {\n \tstats     *carstore.CompactionStats\n }\n \n+func (cstate *CompactorState) set(uid models.Uid, did, status string, stats *carstore.CompactionStats) {\n+\tcstate.latestUID = uid\n+\tcstate.latestDID = did\n+\tcstate.status = status\n+\tcstate.stats = stats\n+}\n+\n // Compactor is a compactor daemon that compacts repos in the background\n type Compactor struct {\n \tq                 *uniQueue\n-\tstate             *CompactorState\n \tstateLk           sync.RWMutex\n \texit              chan struct{}\n-\texited            chan struct{}\n \trequeueInterval   time.Duration\n \trequeueLimit      int\n \trequeueShardCount int\n \trequeueFast       bool\n+\n+\tnumWorkers int\n+\twg         sync.WaitGroup\n }\n \n type CompactorOptions struct {\n \tRequeueInterval   time.Duration\n \tRequeueLimit      int\n \tRequeueShardCount int\n \tRequeueFast       bool\n+\tNumWorkers        int\n }\n \n func DefaultCompactorOptions() *CompactorOptions {\n@@ -131,6 +168,7 @@ func DefaultCompactorOptions() *CompactorOptions {\n \t\tRequeueLimit:      0,\n \t\tRequeueShardCount: 50,\n \t\tRequeueFast:       true,\n+\t\tNumWorkers:        2,\n \t}\n }\n \n@@ -143,13 +181,12 @@ func NewCompactor(opts *CompactorOptions) *Compactor {\n \t\tq: &uniQueue{\n \t\t\tmembers: make(map[models.Uid]struct{}),\n \t\t},\n-\t\tstate:             &CompactorState{},\n \t\texit:              make(chan struct{}),\n-\t\texited:            make(chan struct{}),\n \t\trequeueInterval:   opts.RequeueInterval,\n \t\trequeueLimit:      opts.RequeueLimit,\n \t\trequeueFast:       opts.RequeueFast,\n \t\trequeueShardCount: opts.RequeueShardCount,\n+\t\tnumWorkers:        opts.NumWorkers,\n \t}\n }\n \n@@ -158,34 +195,19 @@ type compactionStats struct {\n \tTargets   []carstore.CompactionTarget\n }\n \n-func (c *Compactor) SetState(uid models.Uid, did, status string, stats *carstore.CompactionStats) {\n-\tc.stateLk.Lock()\n-\tdefer c.stateLk.Unlock()\n-\n-\tc.state.latestUID = uid\n-\tc.state.latestDID = did\n-\tc.state.status = status\n-\tc.state.stats = stats\n-}\n-\n-func (c *Compactor) GetState() *CompactorState {\n-\tc.stateLk.RLock()\n-\tdefer c.stateLk.RUnlock()\n-\n-\treturn &CompactorState{\n-\t\tlatestUID: c.state.latestUID,\n-\t\tlatestDID: c.state.latestDID,\n-\t\tstatus:    c.state.status,\n-\t\tstats:     c.state.stats,\n-\t}\n-}\n-\n var errNoReposToCompact = fmt.Errorf(\"no repos to compact\")\n \n // Start starts the compactor\n func (c *Compactor) Start(bgs *BGS) {\n \tlog.Info(\"starting compactor\")\n-\tgo c.doWork(bgs)\n+\tc.wg.Add(c.numWorkers)\n+\tfor i := range c.numWorkers {\n+\t\tstrategy := NextInOrder\n+\t\tif i%2 != 0 {\n+\t\t\tstrategy = NextRandom\n+\t\t}\n+\t\tgo c.doWork(bgs, strategy)\n+\t}\n \tif c.requeueInterval > 0 {\n \t\tgo func() {\n \t\t\tlog.Infow(\"starting compactor requeue routine\",\n@@ -217,30 +239,29 @@ func (c *Compactor) Start(bgs *BGS) {\n func (c *Compactor) Shutdown() {\n \tlog.Info(\"stopping compactor\")\n \tclose(c.exit)\n-\t<-c.exited\n+\tc.wg.Wait()\n \tlog.Info(\"compactor stopped\")\n }\n \n-func (c *Compactor) doWork(bgs *BGS) {\n+func (c *Compactor) doWork(bgs *BGS, strategy NextStrategy) {\n+\tdefer c.wg.Done()\n \tfor {\n \t\tselect {\n \t\tcase <-c.exit:\n \t\t\tlog.Info(\"compactor worker exiting, no more active compactions running\")\n-\t\t\tclose(c.exited)\n \t\t\treturn\n \t\tdefault:\n \t\t}\n \n \t\tctx := context.Background()\n \t\tstart := time.Now()\n-\t\tstate, err := c.compactNext(ctx, bgs)\n+\t\tstate, err := c.compactNext(ctx, bgs, strategy)\n \t\tif err != nil {\n \t\t\tif err == errNoReposToCompact {\n \t\t\t\tlog.Debug(\"no repos to compact, waiting and retrying\")\n \t\t\t\ttime.Sleep(time.Second * 5)\n \t\t\t\tcontinue\n \t\t\t}\n-\t\t\tstate = c.GetState()\n \t\t\tlog.Errorw(\"failed to compact repo\",\n \t\t\t\t\"err\", err,\n \t\t\t\t\"uid\", state.latestUID,\n@@ -263,34 +284,54 @@ func (c *Compactor) doWork(bgs *BGS) {\n \t}\n }\n \n-func (c *Compactor) compactNext(ctx context.Context, bgs *BGS) (*CompactorState, error) {\n+type NextStrategy int\n+\n+const (\n+\tNextInOrder NextStrategy = iota\n+\tNextRandom\n+)\n+\n+func (c *Compactor) compactNext(ctx context.Context, bgs *BGS, strategy NextStrategy) (CompactorState, error) {\n \tctx, span := otel.Tracer(\"compactor\").Start(ctx, \"CompactNext\")\n \tdefer span.End()\n \n-\titem, ok := c.q.Pop()\n-\tif !ok || item == nil {\n-\t\treturn nil, errNoReposToCompact\n+\tvar item queueItem\n+\tvar ok bool\n+\tswitch strategy {\n+\tcase NextRandom:\n+\t\titem, ok = c.q.PopRandom()\n+\tdefault:\n+\t\titem, ok = c.q.Pop()\n+\t}\n+\tif !ok {\n+\t\treturn CompactorState{}, errNoReposToCompact\n \t}\n \n-\tc.SetState(item.uid, \"unknown\", \"getting_user\", nil)\n+\tstate := CompactorState{\n+\t\tlatestUID: item.uid,\n+\t\tlatestDID: \"unknown\",\n+\t\tstatus:    \"getting_user\",\n+\t}\n \n \tuser, err := bgs.lookupUserByUID(ctx, item.uid)\n \tif err != nil {\n \t\tspan.RecordError(err)\n-\t\tc.SetState(item.uid, \"unknown\", \"failed_getting_user\", nil)\n-\t\treturn nil, fmt.Errorf(\"failed to get user %d: %w\", item.uid, err)\n+\t\tstate.status = \"failed_getting_user\"\n+\t\terr := fmt.Errorf(\"failed to get user %d: %w\", item.uid, err)\n+\t\treturn state, err\n \t}\n \n \tspan.SetAttributes(attribute.String(\"repo\", user.Did), attribute.Int(\"uid\", int(item.uid)))\n \n-\tc.SetState(item.uid, user.Did, \"compacting\", nil)\n+\tstate.latestDID = user.Did\n \n \tstart := time.Now()\n \tst, err := bgs.repoman.CarStore().CompactUserShards(ctx, item.uid, item.fast)\n \tif err != nil {\n \t\tspan.RecordError(err)\n-\t\tc.SetState(item.uid, user.Did, \"failed_compacting\", nil)\n-\t\treturn nil, fmt.Errorf(\"failed to compact shards for user %d: %w\", item.uid, err)\n+\t\tstate.status = \"failed_compacting\"\n+\t\terr := fmt.Errorf(\"failed to compact shards for user %d: %w\", item.uid, err)\n+\t\treturn state, err\n \t}\n \tcompactionDuration.Observe(time.Since(start).Seconds())\n \n@@ -302,9 +343,10 @@ func (c *Compactor) compactNext(ctx context.Context, bgs *BGS) (*CompactorState,\n \t\tattribute.Int(\"refs\", st.TotalRefs),\n \t)\n \n-\tc.SetState(item.uid, user.Did, \"done\", st)\n+\tstate.status = \"done\"\n+\tstate.stats = st\n \n-\treturn c.GetState(), nil\n+\treturn state, nil\n }\n \n func (c *Compactor) EnqueueRepo(ctx context.Context, user User, fast bool) {\n---\n"}], "ideal": "Title: multi-threaded compactor with randomness\n\nBody: This is #742 with additional feature of half the compactor workers pop randomly from the backlog"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/backfill.go\n@@ -468,7 +468,7 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n \t\treturn fmt.Errorf(\"failed to read event repo: %w\", err)\n \t}\n \n-\tvar ops []*BufferedOp\n+\tops := make([]*BufferedOp, 0, len(evt.Ops))\n \tfor _, op := range evt.Ops {\n \t\tkind := repomgr.EventKind(op.Action)\n \t\tswitch kind {\n---\ncmd/supercollider/main.go\n@@ -586,7 +586,7 @@ func initSpeedyRepoMan(key *godid.PrivKey) (*repomgr.RepoManager, *godid.PrivKey\n \n // HandleRepoEvent is the callback for the RepoManager\n func (s *Server) HandleRepoEvent(ctx context.Context, evt *repomgr.RepoEvent) {\n-\tvar outops []*comatproto.SyncSubscribeRepos_RepoOp\n+\toutops := make([]*comatproto.SyncSubscribeRepos_RepoOp, 0, len(evt.Ops))\n \tfor _, op := range evt.Ops {\n \t\tlink := (*lexutil.LexLink)(op.RecCid)\n \t\toutops = append(outops, &comatproto.SyncSubscribeRepos_RepoOp{\n@@ -596,8 +596,6 @@ func (s *Server) HandleRepoEvent(ctx context.Context, evt *repomgr.RepoEvent) {\n \t\t})\n \t}\n \n-\ttoobig := false\n-\n \tif err := s.Events.AddEvent(ctx, &events.XRPCStreamEvent{\n \t\tRepoCommit: &comatproto.SyncSubscribeRepos_Commit{\n \t\t\tRepo:   s.Dids[evt.User-1],\n@@ -606,7 +604,7 @@ func (s *Server) HandleRepoEvent(ctx context.Context, evt *repomgr.RepoEvent) {\n \t\t\tCommit: lexutil.LexLink(evt.NewRoot),\n \t\t\tTime:   time.Now().Format(util.ISO8601),\n \t\t\tOps:    outops,\n-\t\t\tTooBig: toobig,\n+\t\t\tTooBig: false,\n \t\t},\n \t\tPrivUid: evt.User,\n \t}); err != nil {\n---\nindexer/indexer.go\n@@ -86,7 +86,7 @@ func (ix *Indexer) HandleRepoEvent(ctx context.Context, evt *repomgr.RepoEvent)\n \n \tlog.Debugw(\"Handling Repo Event!\", \"uid\", evt.User)\n \n-\tvar outops []*comatproto.SyncSubscribeRepos_RepoOp\n+\toutops := make([]*comatproto.SyncSubscribeRepos_RepoOp, 0, len(evt.Ops))\n \tfor _, op := range evt.Ops {\n \t\tlink := (*lexutil.LexLink)(op.RecCid)\n \t\toutops = append(outops, &comatproto.SyncSubscribeRepos_RepoOp{\n---\nrepomgr/repomgr.go\n@@ -576,7 +576,7 @@ func (rm *RepoManager) HandleExternalUserEvent(ctx context.Context, pdsid uint,\n \n \t}\n \n-\tvar evtops []RepoOp\n+\tevtops := make([]RepoOp, 0, len(ops))\n \n \tfor _, op := range ops {\n \t\tparts := strings.SplitN(op.Path, \"/\", 2)\n@@ -679,7 +679,7 @@ func (rm *RepoManager) BatchWrite(ctx context.Context, user models.Uid, writes [\n \t\treturn err\n \t}\n \n-\tvar ops []RepoOp\n+\tops := make([]RepoOp, 0, len(writes))\n \tfor _, w := range writes {\n \t\tswitch {\n \t\tcase w.RepoApplyWrites_Create != nil:\n@@ -826,7 +826,7 @@ func (rm *RepoManager) ImportNewRepo(ctx context.Context, user models.Uid, repoD\n \t\t\treturn fmt.Errorf(\"diff trees (curhead: %s): %w\", curhead, err)\n \t\t}\n \n-\t\tvar ops []RepoOp\n+\t\tops := make([]RepoOp, 0, len(diffops))\n \t\tfor _, op := range diffops {\n \t\t\trepoOpsImported.Inc()\n \t\t\tout, err := processOp(ctx, bs, op, rm.hydrateRecords)\n---\n"}], "ideal": "Title: Pre-allocate ops slices that are appended in a loop where possible.\n\nBody: This ensures that only one larger allocation is done instead of multiple small ones, reducing pressure on the garbage collector."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/compactor.go\n@@ -105,24 +105,33 @@ type CompactorState struct {\n \tstats     *carstore.CompactionStats\n }\n \n+func (cstate *CompactorState) set(uid models.Uid, did, status string, stats *carstore.CompactionStats) {\n+\tcstate.latestUID = uid\n+\tcstate.latestDID = did\n+\tcstate.status = status\n+\tcstate.stats = stats\n+}\n+\n // Compactor is a compactor daemon that compacts repos in the background\n type Compactor struct {\n \tq                 *uniQueue\n-\tstate             *CompactorState\n \tstateLk           sync.RWMutex\n \texit              chan struct{}\n-\texited            chan struct{}\n \trequeueInterval   time.Duration\n \trequeueLimit      int\n \trequeueShardCount int\n \trequeueFast       bool\n+\n+\tnumWorkers int\n+\twg         sync.WaitGroup\n }\n \n type CompactorOptions struct {\n \tRequeueInterval   time.Duration\n \tRequeueLimit      int\n \tRequeueShardCount int\n \tRequeueFast       bool\n+\tNumWorkers        int\n }\n \n func DefaultCompactorOptions() *CompactorOptions {\n@@ -131,6 +140,7 @@ func DefaultCompactorOptions() *CompactorOptions {\n \t\tRequeueLimit:      0,\n \t\tRequeueShardCount: 50,\n \t\tRequeueFast:       true,\n+\t\tNumWorkers:        2,\n \t}\n }\n \n@@ -143,13 +153,12 @@ func NewCompactor(opts *CompactorOptions) *Compactor {\n \t\tq: &uniQueue{\n \t\t\tmembers: make(map[models.Uid]struct{}),\n \t\t},\n-\t\tstate:             &CompactorState{},\n \t\texit:              make(chan struct{}),\n-\t\texited:            make(chan struct{}),\n \t\trequeueInterval:   opts.RequeueInterval,\n \t\trequeueLimit:      opts.RequeueLimit,\n \t\trequeueFast:       opts.RequeueFast,\n \t\trequeueShardCount: opts.RequeueShardCount,\n+\t\tnumWorkers:        opts.NumWorkers,\n \t}\n }\n \n@@ -158,34 +167,15 @@ type compactionStats struct {\n \tTargets   []carstore.CompactionTarget\n }\n \n-func (c *Compactor) SetState(uid models.Uid, did, status string, stats *carstore.CompactionStats) {\n-\tc.stateLk.Lock()\n-\tdefer c.stateLk.Unlock()\n-\n-\tc.state.latestUID = uid\n-\tc.state.latestDID = did\n-\tc.state.status = status\n-\tc.state.stats = stats\n-}\n-\n-func (c *Compactor) GetState() *CompactorState {\n-\tc.stateLk.RLock()\n-\tdefer c.stateLk.RUnlock()\n-\n-\treturn &CompactorState{\n-\t\tlatestUID: c.state.latestUID,\n-\t\tlatestDID: c.state.latestDID,\n-\t\tstatus:    c.state.status,\n-\t\tstats:     c.state.stats,\n-\t}\n-}\n-\n var errNoReposToCompact = fmt.Errorf(\"no repos to compact\")\n \n // Start starts the compactor\n func (c *Compactor) Start(bgs *BGS) {\n \tlog.Info(\"starting compactor\")\n-\tgo c.doWork(bgs)\n+\tc.wg.Add(c.numWorkers)\n+\tfor _ = range c.numWorkers {\n+\t\tgo c.doWork(bgs, &c.wg)\n+\t}\n \tif c.requeueInterval > 0 {\n \t\tgo func() {\n \t\t\tlog.Infow(\"starting compactor requeue routine\",\n@@ -217,16 +207,16 @@ func (c *Compactor) Start(bgs *BGS) {\n func (c *Compactor) Shutdown() {\n \tlog.Info(\"stopping compactor\")\n \tclose(c.exit)\n-\t<-c.exited\n+\tc.wg.Wait()\n \tlog.Info(\"compactor stopped\")\n }\n \n-func (c *Compactor) doWork(bgs *BGS) {\n+func (c *Compactor) doWork(bgs *BGS, wg *sync.WaitGroup) {\n+\tdefer wg.Done()\n \tfor {\n \t\tselect {\n \t\tcase <-c.exit:\n \t\t\tlog.Info(\"compactor worker exiting, no more active compactions running\")\n-\t\t\tclose(c.exited)\n \t\t\treturn\n \t\tdefault:\n \t\t}\n@@ -240,7 +230,6 @@ func (c *Compactor) doWork(bgs *BGS) {\n \t\t\t\ttime.Sleep(time.Second * 5)\n \t\t\t\tcontinue\n \t\t\t}\n-\t\t\tstate = c.GetState()\n \t\t\tlog.Errorw(\"failed to compact repo\",\n \t\t\t\t\"err\", err,\n \t\t\t\t\"uid\", state.latestUID,\n@@ -263,34 +252,37 @@ func (c *Compactor) doWork(bgs *BGS) {\n \t}\n }\n \n-func (c *Compactor) compactNext(ctx context.Context, bgs *BGS) (*CompactorState, error) {\n+func (c *Compactor) compactNext(ctx context.Context, bgs *BGS) (state CompactorState, err error) {\n \tctx, span := otel.Tracer(\"compactor\").Start(ctx, \"CompactNext\")\n \tdefer span.End()\n \n \titem, ok := c.q.Pop()\n \tif !ok || item == nil {\n-\t\treturn nil, errNoReposToCompact\n+\t\terr = errNoReposToCompact\n+\t\treturn\n \t}\n \n-\tc.SetState(item.uid, \"unknown\", \"getting_user\", nil)\n+\tstate.set(item.uid, \"unknown\", \"getting_user\", nil)\n \n \tuser, err := bgs.lookupUserByUID(ctx, item.uid)\n \tif err != nil {\n \t\tspan.RecordError(err)\n-\t\tc.SetState(item.uid, \"unknown\", \"failed_getting_user\", nil)\n-\t\treturn nil, fmt.Errorf(\"failed to get user %d: %w\", item.uid, err)\n+\t\tstate.set(item.uid, \"unknown\", \"failed_getting_user\", nil)\n+\t\terr = fmt.Errorf(\"failed to get user %d: %w\", item.uid, err)\n+\t\treturn\n \t}\n \n \tspan.SetAttributes(attribute.String(\"repo\", user.Did), attribute.Int(\"uid\", int(item.uid)))\n \n-\tc.SetState(item.uid, user.Did, \"compacting\", nil)\n+\tstate.set(item.uid, user.Did, \"compacting\", nil)\n \n \tstart := time.Now()\n \tst, err := bgs.repoman.CarStore().CompactUserShards(ctx, item.uid, item.fast)\n \tif err != nil {\n \t\tspan.RecordError(err)\n-\t\tc.SetState(item.uid, user.Did, \"failed_compacting\", nil)\n-\t\treturn nil, fmt.Errorf(\"failed to compact shards for user %d: %w\", item.uid, err)\n+\t\tstate.set(item.uid, user.Did, \"failed_compacting\", nil)\n+\t\terr = fmt.Errorf(\"failed to compact shards for user %d: %w\", item.uid, err)\n+\t\treturn\n \t}\n \tcompactionDuration.Observe(time.Since(start).Seconds())\n \n@@ -302,9 +294,10 @@ func (c *Compactor) compactNext(ctx context.Context, bgs *BGS) (*CompactorState,\n \t\tattribute.Int(\"refs\", st.TotalRefs),\n \t)\n \n-\tc.SetState(item.uid, user.Did, \"done\", st)\n+\tstate.set(item.uid, user.Did, \"done\", st)\n \n-\treturn c.GetState(), nil\n+\terr = nil\n+\treturn\n }\n \n func (c *Compactor) EnqueueRepo(ctx context.Context, user User, fast bool) {\n---\n"}], "ideal": "Title: run N threads of compactor\n\nBody: riffing on #741 "}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/bgs.go\n@@ -39,6 +39,7 @@ import (\n \tpromclient \"github.com/prometheus/client_golang/prometheus\"\n \t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n \tdto \"github.com/prometheus/client_model/go\"\n+\tcbg \"github.com/whyrusleeping/cbor-gen\"\n \t\"go.opentelemetry.io/otel\"\n \t\"go.opentelemetry.io/otel/attribute\"\n \t\"gorm.io/gorm\"\n@@ -686,11 +687,12 @@ func (bgs *BGS) EventsHandler(c echo.Context) error {\n \t\t\t\treturn fmt.Errorf(\"unrecognized event kind\")\n \t\t\t}\n \n-\t\t\tif err := header.MarshalCBOR(wc); err != nil {\n+\t\t\tcborWriter := cbg.NewCborWriter(wc)\n+\t\t\tif err := header.MarshalCBOR(cborWriter); err != nil {\n \t\t\t\treturn fmt.Errorf(\"failed to write header: %w\", err)\n \t\t\t}\n \n-\t\t\tif err := obj.MarshalCBOR(wc); err != nil {\n+\t\t\tif err := obj.MarshalCBOR(cborWriter); err != nil {\n \t\t\t\treturn fmt.Errorf(\"failed to write event: %w\", err)\n \t\t\t}\n \n---\n"}], "ideal": "Title: optimize alloc hot spot\n\nBody: 15% of alloc are NewCborWriter() inside MarshalCBOR() in BGS.EventHandler(), cut half of them"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/hashtags.go\n@@ -10,6 +10,11 @@ import (\n \n // looks for specific hashtags from known lists\n func BadHashtagsPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n+\t// In cases where we have a soft signaling hashtag that are problematic in combination with other hashtags\n+\t// we'd want to check the record contains the combination before taking any action\n+\tpotentiallyBadHashtags := []string{}\n+\tpotentiallyBadHashtagCombo := []string{}\n+\n \tfor _, tag := range ExtractHashtagsPost(post) {\n \t\ttag = NormalizeHashtag(tag)\n \t\t// skip some bad-word hashtags which frequently false-positive\n@@ -19,6 +24,16 @@ func BadHashtagsPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error\n \t\tif c.InSet(\"bad-hashtags\", tag) || c.InSet(\"bad-words\", tag) {\n \t\t\tc.AddRecordFlag(\"bad-hashtag\")\n \t\t\tc.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"possible bad word in hashtags: %s\", tag))\n+\n+\t\t\tif c.InSet(\"potentially-bad-hashtags\", tag) {\n+\t\t\t\tpotentiallyBadHashtags = append(potentiallyBadHashtags, tag)\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t\tif c.InSet(\"potentially-bad-hashtag-combos\", tag) {\n+\t\t\t\tpotentiallyBadHashtagCombo = append(potentiallyBadHashtagCombo, tag)\n+\t\t\t\tbreak\n+\t\t\t}\n+\n \t\t\tbreak\n \t\t}\n \t\tword := keyword.SlugContainsExplicitSlur(keyword.Slugify(tag))\n@@ -28,6 +43,13 @@ func BadHashtagsPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error\n \t\t\tbreak\n \t\t}\n \t}\n+\n+\tif len(potentiallyBadHashtagCombo) > 0 && len(potentiallyBadHashtags) > 0 {\n+\t\tc.AddRecordFlag(\"bad-hashtag-combo\")\n+\t\tc.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"bad hashtag combo: %s %s. account will be taken down\", potentiallyBadHashtagCombo, potentiallyBadHashtags))\n+\t\tc.TakedownAccount()\n+\t}\n+\n \treturn nil\n }\n \n---\n"}], "ideal": "Title: :sparkles: Add combo hashtag rule\n\nBody: This PR adds a way for us to takedown accounts that post content with very bad hashtags.\r\nThis introduces the need for 2 new sets `potentially-bad-hashtags` and `potentially-bad-hashtag-combos`. \r\n\r\nHowever, ideally, these would be nested arrays so that each `potentially-bad-hashtags` item would have nested items of `potentially-bad-hashtag-combos` so that we could build hierarchies like \r\n\r\n'test' -> ['check', 'now']\r\n'call' - > ['me', 'her']\r\n- if a post has #test and #check rule will be activated but 'test' and 'me' won't"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/visual/hiveai_client.go\n@@ -20,6 +20,8 @@ import (\n type HiveAIClient struct {\n \tClient   http.Client\n \tApiToken string\n+\n+\tPreScreenClient *PreScreenClient\n }\n \n // schema: https://docs.thehive.ai/reference/classification\n---\nautomod/visual/hiveai_rule.go\n@@ -13,11 +13,29 @@ func (hal *HiveAIClient) HiveLabelBlobRule(c *automod.RecordContext, blob lexuti\n \t\treturn nil\n \t}\n \n+\tvar psclabel string\n+\tif hal.PreScreenClient != nil {\n+\t\tval, err := hal.PreScreenClient.PreScreenImage(c.Ctx, data)\n+\t\tif err != nil {\n+\t\t\tc.Logger.Info(\"prescreen-request-error\", \"err\", err)\n+\t\t} else {\n+\t\t\tpsclabel = val\n+\t\t}\n+\t}\n+\n \tlabels, err := hal.LabelBlob(c.Ctx, blob, data)\n \tif err != nil {\n \t\treturn err\n \t}\n \n+\tif psclabel == \"sfw\" {\n+\t\tif len(labels) > 0 {\n+\t\t\tc.Logger.Info(\"prescreen-safe-failure\", \"uri\", c.RecordOp.ATURI())\n+\t\t} else {\n+\t\t\tc.Logger.Info(\"prescreen-safe-success\", \"uri\", c.RecordOp.ATURI())\n+\t\t}\n+\t}\n+\n \tfor _, l := range labels {\n \t\tc.AddRecordLabel(l)\n \t}\n---\nautomod/visual/prescreen.go\n@@ -0,0 +1,130 @@\n+package visual\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\t\"mime/multipart\"\n+\t\"net/http\"\n+\t\"sync\"\n+\t\"time\"\n+)\n+\n+const failureThresh = 10\n+\n+type PreScreenClient struct {\n+\tHost  string\n+\tToken string\n+\n+\tbreakerEOL time.Time\n+\tbreakerLk  sync.Mutex\n+\tfailures   int\n+\n+\tc *http.Client\n+}\n+\n+func NewPreScreenClient(host, token string) *PreScreenClient {\n+\tc := &http.Client{\n+\t\tTimeout: time.Second * 5,\n+\t}\n+\n+\treturn &PreScreenClient{\n+\t\tHost:  host,\n+\t\tToken: token,\n+\t\tc:     c,\n+\t}\n+}\n+\n+func (c *PreScreenClient) available() bool {\n+\tc.breakerLk.Lock()\n+\tdefer c.breakerLk.Unlock()\n+\tif c.breakerEOL.IsZero() {\n+\t\treturn true\n+\t}\n+\n+\tif time.Now().After(c.breakerEOL) {\n+\t\tc.breakerEOL = time.Time{}\n+\t\treturn true\n+\t}\n+\n+\treturn false\n+}\n+\n+func (c *PreScreenClient) recordCallResult(success bool) {\n+\tc.breakerLk.Lock()\n+\tdefer c.breakerLk.Unlock()\n+\tif !c.breakerEOL.IsZero() {\n+\t\treturn\n+\t}\n+\n+\tif success {\n+\t\tc.failures = 0\n+\t} else {\n+\t\tc.failures++\n+\t\tif c.failures > failureThresh {\n+\t\t\tc.breakerEOL = time.Now().Add(time.Minute)\n+\t\t\tc.failures = 0\n+\t\t}\n+\t}\n+}\n+\n+func (c *PreScreenClient) PreScreenImage(ctx context.Context, blob []byte) (string, error) {\n+\tif !c.available() {\n+\t\treturn \"\", fmt.Errorf(\"pre-screening temporarily unavailable\")\n+\t}\n+\n+\tres, err := c.checkImage(ctx, blob)\n+\tif err != nil {\n+\t\tc.recordCallResult(false)\n+\t\treturn \"\", err\n+\t}\n+\n+\tc.recordCallResult(true)\n+\treturn res, nil\n+}\n+\n+type PreScreenResult struct {\n+\tResult string `json:\"result\"`\n+}\n+\n+func (c *PreScreenClient) checkImage(ctx context.Context, data []byte) (string, error) {\n+\turl := c.Host + \"/predict\"\n+\n+\tbody := new(bytes.Buffer)\n+\twriter := multipart.NewWriter(body)\n+\n+\tpart, err := writer.CreateFormFile(\"files\", \"image\")\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\n+\tpart.Write(data)\n+\n+\tif err := writer.Close(); err != nil {\n+\t\treturn \"\", err\n+\t}\n+\n+\treq, err := http.NewRequest(\"POST\", url, body)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\n+\treq = req.WithContext(ctx)\n+\n+\treq.Header.Set(\"Content-Type\", writer.FormDataContentType())\n+\treq.Header.Set(\"Authorization\", \"Bearer \"+c.Token)\n+\n+\tresp, err := c.c.Do(req)\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\tdefer resp.Body.Close()\n+\n+\tvar out PreScreenResult\n+\tif err := json.NewDecoder(resp.Body).Decode(&out); err != nil {\n+\t\treturn \"\", err\n+\t}\n+\n+\treturn out.Result, nil\n+}\n---\ncmd/hepa/main.go\n@@ -138,6 +138,16 @@ func run(args []string) error {\n \t\t\tUsage:   \"force a fixed number of parallel firehose workers. default (or 0) for auto-scaling; 200 works for a large instance\",\n \t\t\tEnvVars: []string{\"HEPA_FIREHOSE_PARALLELISM\"},\n \t\t},\n+\t\t&cli.StringFlag{\n+\t\t\tName:    \"prescreen-host\",\n+\t\t\tUsage:   \"hostname of prescreen server\",\n+\t\t\tEnvVars: []string{\"HEPA_PRESCREEN_HOST\"},\n+\t\t},\n+\t\t&cli.StringFlag{\n+\t\t\tName:    \"prescreen-token\",\n+\t\t\tUsage:   \"secret token for prescreen server\",\n+\t\t\tEnvVars: []string{\"HEPA_PRESCREEN_TOKEN\"},\n+\t\t},\n \t}\n \n \tapp.Commands = []*cli.Command{\n@@ -242,6 +252,8 @@ var runCmd = &cli.Command{\n \t\t\t\tRatelimitBypass:     cctx.String(\"ratelimit-bypass\"),\n \t\t\t\tRulesetName:         cctx.String(\"ruleset\"),\n \t\t\t\tFirehoseParallelism: cctx.Int(\"firehose-parallelism\"),\n+\t\t\t\tPreScreenHost:       cctx.String(\"prescreen-host\"),\n+\t\t\t\tPreScreenToken:      cctx.String(\"prescreen-token\"),\n \t\t\t},\n \t\t)\n \t\tif err != nil {\n@@ -316,6 +328,8 @@ func configEphemeralServer(cctx *cli.Context) (*Server, error) {\n \t\t\tRatelimitBypass:     cctx.String(\"ratelimit-bypass\"),\n \t\t\tRulesetName:         cctx.String(\"ruleset\"),\n \t\t\tFirehoseParallelism: cctx.Int(\"firehose-parallelism\"),\n+\t\t\tPreScreenHost:       cctx.String(\"prescreen-host\"),\n+\t\t\tPreScreenToken:      cctx.String(\"prescreen-token\"),\n \t\t},\n \t)\n }\n---\ncmd/hepa/server.go\n@@ -61,6 +61,8 @@ type Config struct {\n \tRulesetName         string\n \tRatelimitBypass     string\n \tFirehoseParallelism int\n+\tPreScreenHost       string\n+\tPreScreenToken      string\n }\n \n func NewServer(dir identity.Directory, config Config) (*Server, error) {\n@@ -169,6 +171,11 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\tlogger.Info(\"configuring Hive AI image labeler\")\n \t\thc := visual.NewHiveAIClient(config.HiveAPIToken)\n \t\textraBlobRules = append(extraBlobRules, hc.HiveLabelBlobRule)\n+\n+\t\tif config.PreScreenHost != \"\" {\n+\t\t\tpsc := visual.NewPreScreenClient(config.PreScreenHost, config.PreScreenToken)\n+\t\t\thc.PreScreenClient = psc\n+\t\t}\n \t}\n \n \tif config.AbyssHost != \"\" && config.AbyssPassword != \"\" {\n---\n"}], "ideal": "Title: add rigging for hive to pre-screen images before sending to hive\n\nBody: for now, just going to log if the pre-screen fails at its job"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "api/bsky/cbor_gen.go\n@@ -6838,12 +6838,22 @@ func (t *LabelerDefs_LabelerPolicies) UnmarshalCBOR(r io.Reader) (err error) {\n \t\t\t\t\t_ = err\n \n \t\t\t\t\t{\n-\t\t\t\t\t\tsval, err := cbg.ReadStringWithMax(cr, 1000000)\n+\t\t\t\t\t\tb, err := cr.ReadByte()\n \t\t\t\t\t\tif err != nil {\n \t\t\t\t\t\t\treturn err\n \t\t\t\t\t\t}\n+\t\t\t\t\t\tif b != cbg.CborNull[0] {\n+\t\t\t\t\t\t\tif err := cr.UnreadByte(); err != nil {\n+\t\t\t\t\t\t\t\treturn err\n+\t\t\t\t\t\t\t}\n \n-\t\t\t\t\t\tt.LabelValues[i] = &sval\n+\t\t\t\t\t\t\tsval, err := cbg.ReadStringWithMax(cr, 1000000)\n+\t\t\t\t\t\t\tif err != nil {\n+\t\t\t\t\t\t\t\treturn err\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tt.LabelValues[i] = (*string)(&sval)\n+\t\t\t\t\t\t}\n \t\t\t\t\t}\n \n \t\t\t\t}\n---\ngo.mod\n@@ -52,7 +52,7 @@ require (\n \tgithub.com/samber/slog-echo v1.8.0\n \tgithub.com/stretchr/testify v1.9.0\n \tgithub.com/urfave/cli/v2 v2.25.7\n-\tgithub.com/whyrusleeping/cbor-gen v0.1.1-0.20240311221002-68b9f235c302\n+\tgithub.com/whyrusleeping/cbor-gen v0.1.3-0.20240731173018-74d74643234c\n \tgithub.com/whyrusleeping/go-did v0.0.0-20230824162731-404d1707d5d6\n \tgitlab.com/yawning/secp256k1-voi v0.0.0-20230925100816-f2616030848b\n \tgo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.46.1\n---\ngo.sum\n@@ -614,8 +614,8 @@ github.com/warpfork/go-wish v0.0.0-20220906213052-39a1cc7a02d0 h1:GDDkbFiaK8jsSD\n github.com/warpfork/go-wish v0.0.0-20220906213052-39a1cc7a02d0/go.mod h1:x6AKhvSSexNrVSrViXSHUEbICjmGXhtgABaHIySUSGw=\n github.com/whyrusleeping/cbor v0.0.0-20171005072247-63513f603b11 h1:5HZfQkwe0mIfyDmc1Em5GqlNRzcdtlv4HTNmdpt7XH0=\n github.com/whyrusleeping/cbor v0.0.0-20171005072247-63513f603b11/go.mod h1:Wlo/SzPmxVp6vXpGt/zaXhHH0fn4IxgqZc82aKg6bpQ=\n-github.com/whyrusleeping/cbor-gen v0.1.1-0.20240311221002-68b9f235c302 h1:MhInbXe4SzcImAKktUvWBCWZgcw6MYf5NfumTj1BhAw=\n-github.com/whyrusleeping/cbor-gen v0.1.1-0.20240311221002-68b9f235c302/go.mod h1:pM99HXyEbSQHcosHc0iW7YFmwnscr+t9Te4ibko05so=\n+github.com/whyrusleeping/cbor-gen v0.1.3-0.20240731173018-74d74643234c h1:Jmc9fHbd0LKFmS5CkLgczNUyW36UbiyvbHCG9xCTyiw=\n+github.com/whyrusleeping/cbor-gen v0.1.3-0.20240731173018-74d74643234c/go.mod h1:pM99HXyEbSQHcosHc0iW7YFmwnscr+t9Te4ibko05so=\n github.com/whyrusleeping/chunker v0.0.0-20181014151217-fe64bd25879f h1:jQa4QT2UP9WYv2nzyawpKMOCl+Z/jW7djv2/J50lj9E=\n github.com/whyrusleeping/chunker v0.0.0-20181014151217-fe64bd25879f/go.mod h1:p9UJB6dDgdPgMJZs7UjUOdulKyRr9fqkS+6JKAInPy8=\n github.com/whyrusleeping/go-did v0.0.0-20230824162731-404d1707d5d6 h1:yJ9/LwIGIk/c0CdoavpC9RNSGSruIspSZtxG3Nnldic=\n---\n"}], "ideal": "Title: upgrade cbor-gen\n\nBody: use its improved handling of a []*string field"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "Makefile\n@@ -67,10 +67,7 @@ check: ## Compile everything, checking syntax (does not output binaries)\n \n .PHONY: lexgen\n lexgen: ## Run codegen tool for lexicons (lexicon JSON to Go packages)\n-\tgo run ./cmd/lexgen/ --package bsky --prefix app.bsky --outdir api/bsky $(LEXDIR)\n-\tgo run ./cmd/lexgen/ --package atproto --prefix com.atproto --outdir api/atproto $(LEXDIR)\n-\tgo run ./cmd/lexgen/ --package chat --prefix chat.bsky --outdir api/chat $(LEXDIR)\n-\tgo run ./cmd/lexgen/ --package ozone --prefix tools.ozone --outdir api/ozone $(LEXDIR)\n+\tgo run ./cmd/lexgen/ $(LEXDIR)\n \n .PHONY: cborgen\n cborgen: ## Run codegen tool for CBOR serialization\n---\ncmd/lexgen/main.go\n@@ -11,8 +11,7 @@ import (\n \tcli \"github.com/urfave/cli/v2\"\n )\n \n-func findSchemas(dir string) ([]string, error) {\n-\tvar out []string\n+func findSchemas(dir string, out []string) ([]string, error) {\n \terr := filepath.Walk(dir, func(path string, info fs.FileInfo, err error) error {\n \t\tif err != nil {\n \t\t\treturn err\n@@ -29,13 +28,14 @@ func findSchemas(dir string) ([]string, error) {\n \t\treturn nil\n \t})\n \tif err != nil {\n-\t\treturn nil, err\n+\t\treturn out, err\n \t}\n \n \treturn out, nil\n \n }\n \n+// for direct .json lexicon files or directories containing lexicon .json files, get one flat list of all paths to .json files\n func expandArgs(args []string) ([]string, error) {\n \tvar out []string\n \tfor _, a := range args {\n@@ -44,11 +44,10 @@ func expandArgs(args []string) ([]string, error) {\n \t\t\treturn nil, err\n \t\t}\n \t\tif st.IsDir() {\n-\t\t\ts, err := findSchemas(a)\n+\t\t\tout, err = findSchemas(a, out)\n \t\t\tif err != nil {\n \t\t\t\treturn nil, err\n \t\t\t}\n-\t\t\tout = append(out, s...)\n \t\t} else if strings.HasSuffix(a, \".json\") {\n \t\t\tout = append(out, a)\n \t\t}\n@@ -82,13 +81,6 @@ func main() {\n \t\t},\n \t}\n \tapp.Action = func(cctx *cli.Context) error {\n-\t\toutdir := cctx.String(\"outdir\")\n-\t\tif outdir == \"\" {\n-\t\t\treturn fmt.Errorf(\"must specify output directory (--outdir)\")\n-\t\t}\n-\n-\t\tprefix := cctx.String(\"prefix\")\n-\n \t\tpaths, err := expandArgs(cctx.Args().Slice())\n \t\tif err != nil {\n \t\t\treturn err\n@@ -108,15 +100,13 @@ func main() {\n \t\t\tschemas = append(schemas, s)\n \t\t}\n \n-\t\tpkgname := cctx.String(\"package\")\n-\n-\t\timports := map[string]string{\n-\t\t\t\"app.bsky\":    \"github.com/bluesky-social/indigo/api/bsky\",\n-\t\t\t\"com.atproto\": \"github.com/bluesky-social/indigo/api/atproto\",\n-\t\t}\n-\n \t\tif cctx.Bool(\"gen-server\") {\n-\t\t\tdefmap := lex.BuildExtDefMap(schemas, []string{\"com.atproto\", \"app.bsky\"})\n+\t\t\tpkgname := cctx.String(\"package\")\n+\t\t\toutdir := cctx.String(\"outdir\")\n+\t\t\tif outdir == \"\" {\n+\t\t\t\treturn fmt.Errorf(\"must specify output directory (--outdir)\")\n+\t\t\t}\n+\t\t\tdefmap := lex.BuildExtDefMap(schemas)\n \t\t\t_ = defmap\n \n \t\t\tpaths := cctx.StringSlice(\"types-import\")\n@@ -133,23 +123,7 @@ func main() {\n \t\t\t}\n \n \t\t} else {\n-\t\t\tdefmap := lex.BuildExtDefMap(schemas, []string{\"com.atproto\", \"app.bsky\"})\n-\n-\t\t\t// Run this twice as a hack to deal with indirect references referencing indirect references.\n-\t\t\t// This part of the codegen needs to be redone\n-\t\t\tlex.FixRecordReferences(schemas, defmap, prefix)\n-\t\t\tlex.FixRecordReferences(schemas, defmap, prefix)\n-\t\t\tfor i, s := range schemas {\n-\t\t\t\tif !strings.HasPrefix(s.ID, prefix) {\n-\t\t\t\t\tcontinue\n-\t\t\t\t}\n-\n-\t\t\t\tfname := filepath.Join(outdir, s.Name()+\".go\")\n-\n-\t\t\t\tif err := lex.GenCodeForSchema(pkgname, prefix, fname, true, s, defmap, imports); err != nil {\n-\t\t\t\t\treturn fmt.Errorf(\"failed to process schema %q: %w\", paths[i], err)\n-\t\t\t\t}\n-\t\t\t}\n+\t\t\treturn lex.Run(schemas)\n \t\t}\n \n \t\treturn nil\n---\nlex/gen.go\n@@ -25,6 +25,7 @@ const (\n )\n \n type Schema struct {\n+\tpath   string\n \tprefix string\n \n \tLexicon int                    `json:\"lexicon\"`\n@@ -50,9 +51,9 @@ type InputType struct {\n }\n \n type TypeSchema struct {\n-\tprefix    string\n-\tid        string\n-\tdefName   string\n+\tprefix    string // prefix of a major package being processed, e.g. com.atproto\n+\tid        string // parent Schema.ID\n+\tdefName   string // parent Schema.Defs[defName] points to this *TypeSchema\n \tdefMap    map[string]*ExtDef\n \tneedsCbor bool\n \tneedsType bool\n@@ -149,7 +150,6 @@ func (s *Schema) AllTypes(prefix string, defMap map[string]*ExtDef) []outputType\n \t\tif ts.Type == \"ref\" {\n \t\t\trefname := ts.Ref\n \t\t\tif strings.HasPrefix(refname, \"#\") {\n-\t\t\t\tfmt.Println(\"Foo\")\n \t\t\t\trefname = s.ID + ts.Ref\n \t\t\t}\n \n@@ -222,11 +222,14 @@ func ReadSchema(f string) (*Schema, error) {\n \tif err := json.NewDecoder(fi).Decode(&s); err != nil {\n \t\treturn nil, err\n \t}\n+\ts.path = f\n \n \treturn &s, nil\n }\n \n-func BuildExtDefMap(ss []*Schema, prefixes []string) map[string]*ExtDef {\n+// Build total map of all types defined inside schemas.\n+// Return map from fully qualified type name to its *TypeSchema\n+func BuildExtDefMap(ss []*Schema) map[string]*ExtDef {\n \tout := make(map[string]*ExtDef)\n \tfor _, s := range ss {\n \t\tfor k, d := range s.Defs {\n@@ -235,9 +238,9 @@ func BuildExtDefMap(ss []*Schema, prefixes []string) map[string]*ExtDef {\n \t\t\td.defName = k\n \n \t\t\tvar pref string\n-\t\t\tfor _, p := range prefixes {\n-\t\t\t\tif strings.HasPrefix(s.ID, p) {\n-\t\t\t\t\tpref = p\n+\t\t\tfor _, pkg := range Packages {\n+\t\t\t\tif strings.HasPrefix(s.ID, pkg.Prefix) {\n+\t\t\t\t\tpref = pkg.Prefix\n \t\t\t\t\tbreak\n \t\t\t\t}\n \t\t\t}\n@@ -300,7 +303,7 @@ func printerf(w io.Writer) func(format string, args ...any) {\n \t}\n }\n \n-func GenCodeForSchema(pkg string, prefix string, fname string, reqcode bool, s *Schema, defmap map[string]*ExtDef, imports map[string]string) error {\n+func GenCodeForSchema(pkg string, prefix string, fname string, reqcode bool, s *Schema, defmap map[string]*ExtDef) error {\n \tbuf := new(bytes.Buffer)\n \tpf := printerf(buf)\n \n@@ -324,7 +327,7 @@ func GenCodeForSchema(pkg string, prefix string, fname string, reqcode bool, s *\n \tpf(\"\\tcbg \\\"github.com/whyrusleeping/cbor-gen\\\"\\n\")\n \tpf(\"\\t\\\"github.com/bluesky-social/indigo/xrpc\\\"\\n\")\n \tpf(\"\\t\\\"github.com/bluesky-social/indigo/lex/util\\\"\\n\")\n-\tfor k, v := range imports {\n+\tfor k, v := range prefixToGoImport {\n \t\tif k != prefix {\n \t\t\tpf(\"\\t%s %q\\n\", importNameForPrefix(k), v)\n \t\t}\n@@ -1470,3 +1473,51 @@ func (ts *TypeSchema) writeCborUnmarshalerEnum(name string, w io.Writer) error {\n \n \treturn nil\n }\n+\n+type Package struct {\n+\tGoPackage string\n+\tPrefix    string\n+\tOutdir    string\n+}\n+\n+var Packages []Package = []Package{\n+\tPackage{\"bsky\", \"app.bsky\", \"api/bsky\"},\n+\tPackage{\"atproto\", \"com.atproto\", \"api/atproto\"},\n+\tPackage{\"chat\", \"chat.bsky\", \"api/chat\"},\n+\tPackage{\"ozone\", \"tools.ozone\", \"api/ozone\"},\n+}\n+\n+var prefixToGoImport map[string]string\n+\n+func init() {\n+\tprefixToGoImport = map[string]string{\n+\t\t\"app.bsky\":    \"github.com/bluesky-social/indigo/api/bsky\",\n+\t\t\"chat.bsky\":   \"github.com/bluesky-social/indigo/api/chat\",\n+\t\t\"com.atproto\": \"github.com/bluesky-social/indigo/api/atproto\",\n+\t\t\"tools.ozone\": \"github.com/bluesky-social/indigo/api/ozone\",\n+\t}\n+}\n+\n+func Run(schemas []*Schema) error {\n+\tdefmap := BuildExtDefMap(schemas)\n+\n+\tfor _, pkg := range Packages {\n+\t\tprefix := pkg.Prefix\n+\t\tFixRecordReferences(schemas, defmap, prefix)\n+\t}\n+\n+\tfor _, pkg := range Packages {\n+\t\tfor _, s := range schemas {\n+\t\t\tif !strings.HasPrefix(s.ID, pkg.Prefix) {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\tfname := filepath.Join(pkg.Outdir, s.Name()+\".go\")\n+\n+\t\t\tif err := GenCodeForSchema(pkg.GoPackage, pkg.Prefix, fname, true, s, defmap); err != nil {\n+\t\t\t\treturn fmt.Errorf(\"failed to process schema %q: %w\", s.path, err)\n+\t\t\t}\n+\t\t}\n+\t}\n+\treturn nil\n+}\n---\n"}], "ideal": "Title: lexgen runs all packages together\n\nBody: cross-package references can now make a type know that it needs to include a type field"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/bigsky/main.go\n@@ -348,10 +348,10 @@ func runBigsky(cctx *cli.Context) error {\n \n \trlskip := cctx.String(\"bsky-social-rate-limit-skip\")\n \tix.ApplyPDSClientSettings = func(c *xrpc.Client) {\n+\t\tif c.Client == nil {\n+\t\t\tc.Client = util.RobustHTTPClient()\n+\t\t}\n \t\tif strings.HasSuffix(c.Host, \".bsky.network\") {\n-\t\t\tif c.Client == nil {\n-\t\t\t\tc.Client = util.RobustHTTPClient()\n-\t\t\t}\n \t\t\tc.Client.Timeout = time.Minute * 30\n \t\t\tif rlskip != \"\" {\n \t\t\t\tc.Headers = map[string]string{\n---\n"}], "ideal": "Title: fix nil pointer exception on creating account, when relay is self-hosted\n\nBody: close #704"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/all.go\n@@ -38,6 +38,7 @@ func DefaultRules() automod.RuleSet {\n \t\t\tInteractionChurnRule,\n \t\t\tBadWordRecordKeyRule,\n \t\t\tBadWordOtherRecordRule,\n+\t\t\tTooManyRepostRule,\n \t\t},\n \t\tRecordDeleteRules: []automod.RecordRuleFunc{\n \t\t\tDeleteInteractionRule,\n---\nautomod/rules/reposts.go\n@@ -0,0 +1,53 @@\n+package rules\n+\n+import (\n+\t\"fmt\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bluesky-social/indigo/automod\"\n+\t\"github.com/bluesky-social/indigo/automod/countstore\"\n+)\n+\n+var dailyRepostThresholdWithoutPost = 30\n+var dailyRepostThresholdWithLowPost = 100\n+var dailyPostThresholdWithHighRepost = 5\n+\n+var _ automod.RecordRuleFunc = TooManyRepostRule\n+\n+// looks for accounts which do frequent reposts\n+func TooManyRepostRule(c *automod.RecordContext) error {\n+\n+\tdid := c.Account.Identity.DID.String()\n+\t// Don't bother checking reposts from accounts older than 30 days\n+\tif c.Account.Private != nil {\n+\t\tage := time.Since(c.Account.Private.IndexedAt)\n+\t\tif age > 30*24*time.Hour {\n+\t\t\treturn nil\n+\t\t}\n+\t}\n+\n+\t// Special case for newsmast bridge feeds\n+\thandle := c.Account.Identity.Handle.String()\n+\tif strings.HasSuffix(handle, \".ap.brid.gy\") {\n+\t\treturn nil\n+\t}\n+\n+\tswitch c.RecordOp.Collection {\n+\tcase \"app.bsky.feed.post\":\n+\t\tc.Increment(\"post\", did)\n+\tcase \"app.bsky.feed.repost\":\n+\t\tc.Increment(\"repost\", did)\n+\t\t// +1 to avoid potential divide by 0 issue\n+\t\trepostCount := c.GetCount(\"repost\", did, countstore.PeriodDay)\n+\t\tpostCount := c.GetCount(\"post\", did, countstore.PeriodDay)\n+\t\thighRepost := (repostCount >= dailyRepostThresholdWithoutPost && postCount < 1) || (repostCount >= dailyRepostThresholdWithLowPost && postCount < dailyPostThresholdWithHighRepost)\n+\t\tif highRepost {\n+\t\t\tc.Logger.Info(\"high-repost-count\", \"reposted-today\", repostCount, \"posted-today\", postCount)\n+\t\t\tc.AddAccountFlag(\"high-repost-count\")\n+\t\t\tc.ReportAccount(automod.ReportReasonSpam, fmt.Sprintf(\"too many reposts: %d reposts, %d posts today (so far)\", repostCount, postCount))\n+\t\t\tc.Notify(\"slack\")\n+\t\t}\n+\t}\n+\treturn nil\n+}\n---\n"}], "ideal": "Title: automod: add basic repost rule\n\nBody: TODO:\r\n- [ ] Verify the threshold values are correct\r\n- [ ] Uncomment ozone report line\r\n\r\nThis PR adds basic checks for relatively new accounts reposting too frequently and reports them to ozone."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/bigsky/main.go\n@@ -343,6 +343,9 @@ func runBigsky(cctx *cli.Context) error {\n \t\t\t\t\t\"x-ratelimit-bypass\": rlskip,\n \t\t\t\t}\n \t\t\t}\n+\t\t} else {\n+\t\t\t// Generic PDS timeout\n+\t\t\tc.Client.Timeout = time.Minute * 1\n \t\t}\n \t}\n \trf.ApplyPDSClientSettings = ix.ApplyPDSClientSettings\n---\n"}], "ideal": "Title: Increase PDS repo fetch timeout\n\nBody: Increases the default timeout for generic PDSs when running GetRepo from the Relay."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/fedmgr.go\n@@ -72,10 +72,10 @@ func DefaultSlurperOptions() *SlurperOptions {\n \treturn &SlurperOptions{\n \t\tSSL:                   false,\n \t\tDefaultPerSecondLimit: 50,\n-\t\tDefaultPerHourLimit:   1500,\n-\t\tDefaultPerDayLimit:    10_000,\n+\t\tDefaultPerHourLimit:   2500,\n+\t\tDefaultPerDayLimit:    20_000,\n \t\tDefaultCrawlLimit:     rate.Limit(5),\n-\t\tDefaultRepoLimit:      10,\n+\t\tDefaultRepoLimit:      100,\n \t}\n }\n \n---\n"}], "ideal": "Title: relay: bump default repo limit configuration\n\nBody: The main thing here is `DefaultRepoLimit`. Also bumped the other numbers a bit to be consistent."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/gosky/bgs.go\n@@ -22,7 +22,7 @@ var bgsAdminCmd = &cli.Command{\n \t\t},\n \t\t&cli.StringFlag{\n \t\t\tName:  \"bgs\",\n-\t\t\tValue: \"https://bgs.bsky-sandbox.dev\",\n+\t\t\tValue: \"http://localhost:2470\",\n \t\t},\n \t},\n \tSubcommands: []*cli.Command{\n---\n"}], "ideal": "Title: gosky: default localhost relay, not sandbox\n\nBody: motivation here is that we are shutting down sandbox. pointing it at prod feels like it would be confusing for other devs."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "carstore/bs.go\n@@ -10,6 +10,7 @@ import (\n \t\"os\"\n \t\"path/filepath\"\n \t\"sort\"\n+\t\"strconv\"\n \t\"strings\"\n \t\"sync\"\n \t\"sync/atomic\"\n@@ -32,6 +33,7 @@ import (\n \tcbg \"github.com/whyrusleeping/cbor-gen\"\n \t\"go.opentelemetry.io/otel\"\n \t\"go.opentelemetry.io/otel/attribute\"\n+\t\"gorm.io/driver/postgres\"\n \t\"gorm.io/gorm\"\n )\n \n@@ -1097,7 +1099,7 @@ func (cs *CarStore) deleteShards(ctx context.Context, shs []*CarShard) error {\n \t\treturn nil\n \t}\n \n-\tchunkSize := 10000\n+\tchunkSize := 2000\n \tfor i := 0; i < len(shs); i += chunkSize {\n \t\tsl := shs[i:]\n \t\tif len(sl) > chunkSize {\n@@ -1196,31 +1198,6 @@ func (cb *compBucket) isEmpty() bool {\n \treturn len(cb.shards) == 0\n }\n \n-func (cs *CarStore) copyShardBlocksFiltered(ctx context.Context, sh *CarShard, w io.Writer, keep map[cid.Cid]bool) error {\n-\tfi, err := os.Open(sh.Path)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\tdefer fi.Close()\n-\n-\trr, err := car.NewCarReader(fi)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\tfor {\n-\t\tblk, err := rr.Next()\n-\t\tif err != nil {\n-\t\t\treturn err\n-\t\t}\n-\n-\t\tif keep[blk.Cid()] {\n-\t\t\t_, err := LdWrite(w, blk.Cid().Bytes(), blk.RawData())\n-\t\t\treturn err\n-\t\t}\n-\t}\n-}\n-\n func (cs *CarStore) openNewCompactedShardFile(ctx context.Context, user models.Uid, seq int) (*os.File, string, error) {\n \t// TODO: some overwrite protections\n \tfi, err := os.CreateTemp(cs.rootDir, fnameForShard(user, seq))\n@@ -1254,27 +1231,49 @@ func (cs *CarStore) getBlockRefsForShards(ctx context.Context, shardIds []uint)\n \n \tspan.SetAttributes(attribute.Int(\"shards\", len(shardIds)))\n \n-\tchunkSize := 10000\n+\tchunkSize := 2000\n \tout := make([]blockRef, 0, len(shardIds))\n \tfor i := 0; i < len(shardIds); i += chunkSize {\n \t\tsl := shardIds[i:]\n \t\tif len(sl) > chunkSize {\n \t\t\tsl = sl[:chunkSize]\n \t\t}\n \n-\t\tvar brefs []blockRef\n-\t\tif err := cs.meta.Raw(`select * from block_refs where shard in (?)`, sl).Scan(&brefs).Error; err != nil {\n-\t\t\treturn nil, err\n+\t\tif err := blockRefsForShards(ctx, cs.meta, sl, &out); err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"getting block refs: %w\", err)\n \t\t}\n-\n-\t\tout = append(out, brefs...)\n \t}\n \n \tspan.SetAttributes(attribute.Int(\"refs\", len(out)))\n \n \treturn out, nil\n }\n \n+func valuesStatementForShards(shards []uint) string {\n+\tsb := new(strings.Builder)\n+\tfor i, v := range shards {\n+\t\tsb.WriteByte('(')\n+\t\tsb.WriteString(strconv.Itoa(int(v)))\n+\t\tsb.WriteByte(')')\n+\t\tif i != len(shards)-1 {\n+\t\t\tsb.WriteByte(',')\n+\t\t}\n+\t}\n+\treturn sb.String()\n+}\n+\n+func blockRefsForShards(ctx context.Context, db *gorm.DB, shards []uint, obuf *[]blockRef) error {\n+\t// Check the database driver\n+\tswitch db.Dialector.(type) {\n+\tcase *postgres.Dialector:\n+\t\tsval := valuesStatementForShards(shards)\n+\t\tq := fmt.Sprintf(`SELECT block_refs.* FROM block_refs INNER JOIN (VALUES %s) AS vals(v) ON block_refs.shard = v`, sval)\n+\t\treturn db.Raw(q).Scan(obuf).Error\n+\tdefault:\n+\t\treturn db.Raw(`SELECT * FROM block_refs WHERE shard IN (?)`, shards).Scan(obuf).Error\n+\t}\n+}\n+\n func shardSize(sh *CarShard) (int64, error) {\n \tst, err := os.Stat(sh.Path)\n \tif err != nil {\n---\n"}], "ideal": "Title: in postgres use optimized where in query\n\nBody: We need to find a good way to run these tests on postgres"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "carstore/bs.go\n@@ -1085,17 +1085,16 @@ func (cs *CarStore) deleteShards(ctx context.Context, shs []*CarShard) error {\n \t\t\treturn err\n \t\t}\n \n-\t\tvar outErr error\n \t\tfor _, sh := range subs {\n \t\t\tif err := cs.deleteShardFile(ctx, sh); err != nil {\n \t\t\t\tif !os.IsNotExist(err) {\n \t\t\t\t\treturn err\n \t\t\t\t}\n-\t\t\t\toutErr = err\n+\t\t\t\tlog.Warnw(\"shard file we tried to delete did not exist\", \"shard\", sh.ID, \"path\", sh.Path)\n \t\t\t}\n \t\t}\n \n-\t\treturn outErr\n+\t\treturn nil\n \t}\n \n \tchunkSize := 10000\n---\n"}], "ideal": "Title: more effectively ignore file not found errors in delete path\n\nBody: Returning the errors while soft ignoring them only means we dont finish the rest of the compaction cleanup work in these cases"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "carstore/bs.go\n@@ -551,7 +551,7 @@ func (cs *CarStore) iterateShardBlocks(ctx context.Context, sh *CarShard, cb fun\n \n \trr, err := car.NewCarReader(fi)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"opening shard car: %w\", err)\n \t}\n \n \tfor {\n@@ -1479,7 +1479,7 @@ func (cs *CarStore) CompactUserShards(ctx context.Context, user models.Uid, skip\n \t\t}\n \n \t\tif err := cs.compactBucket(ctx, user, b, shardsById, keep); err != nil {\n-\t\t\treturn nil, err\n+\t\t\treturn nil, fmt.Errorf(\"compact bucket: %w\", err)\n \t\t}\n \n \t\tstats.NewShards++\n@@ -1504,7 +1504,7 @@ func (cs *CarStore) CompactUserShards(ctx context.Context, user models.Uid, skip\n \t// now we need to delete the staleRefs we successfully cleaned up\n \t// we can safely delete a staleRef if all the shards that have blockRefs with matching stale refs were processed\n \tif err := cs.deleteStaleRefs(ctx, user, brefs, staleRefs, removedShards); err != nil {\n-\t\treturn nil, err\n+\t\treturn nil, fmt.Errorf(\"delete stale refs: %w\", err)\n \t}\n \n \tstats.DupeCount = len(dupes)\n@@ -1577,7 +1577,7 @@ func (cs *CarStore) compactBucket(ctx context.Context, user models.Uid, b *compB\n \tlastsh := shardsById[last.ID]\n \tfi, path, err := cs.openNewCompactedShardFile(ctx, user, last.Seq)\n \tif err != nil {\n-\t\treturn err\n+\t\treturn fmt.Errorf(\"opening new file: %w\", err)\n \t}\n \n \tdefer fi.Close()\n@@ -1614,7 +1614,9 @@ func (cs *CarStore) compactBucket(ctx context.Context, user models.Uid, b *compB\n \t\t\t}\n \t\t\treturn nil\n \t\t}); err != nil {\n-\t\t\treturn err\n+\t\t\t// If we ever fail to iterate a shard file because its\n+\t\t\t// corrupted, just log an error and skip the shard\n+\t\t\tlog.Errorw(\"iterating blocks in shard\", \"shard\", s.ID, \"err\", err, \"uid\", user)\n \t\t}\n \t}\n \n---\n"}], "ideal": "Title: keep going if we encounter corrupted shard files\n\nBody: If the relay gets shut down very suddenly and things arent properly synced to disk (I think this only happens if there are unexpected power failures on the host machine) then we can get into weird states where some repos have corrupted shard files. \r\nThey keep functioning fine at a high level, but compaction gets impacted and prevented from finishing.\r\n\r\nThese repos should really just get wiped and resynced, but this change should prevent them from wreaking havoc in the compaction engine."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/bgs.go\n@@ -1449,14 +1449,13 @@ func (bgs *BGS) ResyncPDS(ctx context.Context, pds models.PDS) error {\n \n \t// Check repo revs against our local copy and enqueue crawls for any that are out of date\n \tfor _, r := range repos {\n+\t\tif err := sem.Acquire(ctx, 1); err != nil {\n+\t\t\tlog.Errorw(\"failed to acquire semaphore\", \"error\", err)\n+\t\t\tresults <- revCheckResult{err: err}\n+\t\t\tcontinue\n+\t\t}\n \t\tgo func(r comatproto.SyncListRepos_Repo) {\n-\t\t\tif err := sem.Acquire(ctx, 1); err != nil {\n-\t\t\t\tlog.Errorw(\"failed to acquire semaphore\", \"error\", err)\n-\t\t\t\tresults <- revCheckResult{err: err}\n-\t\t\t\treturn\n-\t\t\t}\n \t\t\tdefer sem.Release(1)\n-\n \t\t\tlog := log.With(\"did\", r.Did, \"remote_rev\", r.Rev)\n \t\t\t// Fetches the user if we have it, otherwise automatically enqueues it for crawling\n \t\t\tai, err := bgs.Index.GetUserOrMissing(ctx, r.Did)\n---\n"}], "ideal": "Title: Acquire semaphore outside of goroutine for resyncs\n\nBody: Currently we end up with millions of goroutines waiting on semaphores during a full PDS resync if we run against all production PDSs, this fix waits for the semaphore _before_ spawning the goroutine reducing allocs and the size of the stack significantly."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "indexer/repofetch.go\n@@ -3,7 +3,10 @@ package indexer\n import (\n \t\"bytes\"\n \t\"context\"\n+\t\"errors\"\n \t\"fmt\"\n+\t\"io\"\n+\t\"io/fs\"\n \t\"sync\"\n \n \t\"github.com/bluesky-social/indigo/api/atproto\"\n@@ -147,7 +150,7 @@ func (rf *RepoFetcher) FetchAndIndexRepo(ctx context.Context, job *crawlWork) er\n \tif err := rf.repoman.ImportNewRepo(ctx, ai.Uid, ai.Did, bytes.NewReader(repo), &rev); err != nil {\n \t\tspan.RecordError(err)\n \n-\t\tif ipld.IsNotFound(err) {\n+\t\tif ipld.IsNotFound(err) || errors.Is(err, io.EOF) || errors.Is(err, fs.ErrNotExist) {\n \t\t\tlog.Errorw(\"partial repo fetch was missing data\", \"did\", ai.Did, \"pds\", pds.Host, \"rev\", rev)\n \t\t\trepo, err := rf.fetchRepo(ctx, c, &pds, ai.Did, \"\")\n \t\t\tif err != nil {\n---\n"}], "ideal": "Title: fallback to clean repo reset in more cases\n\nBody: If we have a filesystem messup for some reason just wipe and reset the repo"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/query.go\n@@ -7,6 +7,7 @@ import (\n \t\"fmt\"\n \t\"io/ioutil\"\n \t\"log/slog\"\n+\t\"strings\"\n \n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n@@ -275,7 +276,7 @@ func DoSearchProfiles(ctx context.Context, dir identity.Directory, escli *es.Cli\n \n \tfilters := params.Filters()\n \n-\tbasic := map[string]interface{}{\n+\tfulltext := map[string]interface{}{\n \t\t\"simple_query_string\": map[string]interface{}{\n \t\t\t\"query\":            params.Query,\n \t\t\t\"fields\":           []string{\"everything\"},\n@@ -285,11 +286,38 @@ func DoSearchProfiles(ctx context.Context, dir identity.Directory, escli *es.Cli\n \t\t\t\"analyze_wildcard\": false,\n \t\t},\n \t}\n+\tprimary := fulltext\n+\n+\t// if the query string is just a single token (after parsing out filter\n+\t// syntax), then have the primary query be an \"OR\" of the basic fulltext\n+\t// query and the typeahead query\n+\tif len(strings.Split(params.Query, \" \")) == 1 {\n+\t\ttypeahead := map[string]interface{}{\n+\t\t\t\"multi_match\": map[string]interface{}{\n+\t\t\t\t\"query\":    params.Query,\n+\t\t\t\t\"type\":     \"bool_prefix\",\n+\t\t\t\t\"operator\": \"and\",\n+\t\t\t\t\"fields\": []string{\n+\t\t\t\t\t\"typeahead\",\n+\t\t\t\t\t\"typeahead._2gram\",\n+\t\t\t\t\t\"typeahead._3gram\",\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\t\tprimary = map[string]interface{}{\n+\t\t\t\"bool\": map[string]interface{}{\n+\t\t\t\t\"should\": []interface{}{\n+\t\t\t\t\tfulltext,\n+\t\t\t\t\ttypeahead,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\t}\n \n \tquery := map[string]interface{}{\n \t\t\"query\": map[string]interface{}{\n \t\t\t\"bool\": map[string]interface{}{\n-\t\t\t\t\"must\": basic,\n+\t\t\t\t\"must\": primary,\n \t\t\t\t\"should\": []interface{}{\n \t\t\t\t\tmap[string]interface{}{\"term\": map[string]interface{}{\"has_avatar\": true}},\n \t\t\t\t\tmap[string]interface{}{\"term\": map[string]interface{}{\"has_banner\": true}},\n---\n"}], "ideal": "Title: palomar: 'OR' for single-token profile searches\n\nBody: Just sketching, didn't even test this against a local index"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "xrpc/xrpc.go\n@@ -184,7 +184,7 @@ func (c *Client) Do(ctx context.Context, kind XRPCRequestType, inpenc string, me\n \t}\n \n \t// use admin auth if we have it configured and are doing a request that requires it\n-\tif c.AdminToken != nil && (strings.HasPrefix(method, \"com.atproto.admin.\") || strings.HasPrefix(method, \"tools.ozone.\") || method == \"com.atproto.account.createInviteCode\" || method == \"com.atproto.server.createInviteCodes\") {\n+\tif c.AdminToken != nil && (strings.HasPrefix(method, \"com.atproto.admin.\") || strings.HasPrefix(method, \"tools.ozone.\") || method == \"com.atproto.server.createInviteCode\" || method == \"com.atproto.server.createInviteCodes\") {\n \t\treq.Header.Set(\"Authorization\", \"Basic \"+base64.StdEncoding.EncodeToString([]byte(\"admin:\"+*c.AdminToken)))\n \t} else if c.Auth != nil {\n \t\treq.Header.Set(\"Authorization\", \"Bearer \"+c.Auth.AccessJwt)\n---\n"}], "ideal": "Title: com.atproto.account.createInviteCode has been renamed to com.atproto.server.createInviteCode\n\nBody: https://github.com/bluesky-social/atproto/blob/main/lexicons/com/atproto/server/createInviteCode.json"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/gormstore.go\n@@ -65,21 +65,26 @@ func (s *Gormstore) LoadJobs(ctx context.Context) error {\n }\n \n func (s *Gormstore) loadJobs(ctx context.Context, limit int) error {\n+\tenqueuedIndexClause := \"\"\n+\tretryableIndexClause := \"\"\n+\n+\t// If the DB is a SQLite DB, we can use INDEXED BY to speed up the query\n+\tif s.db.Dialector.Name() == \"sqlite\" {\n+\t\tenqueuedIndexClause = \"INDEXED BY enqueued_job_idx\"\n+\t\tretryableIndexClause = \"INDEXED BY retryable_job_idx\"\n+\t}\n+\n+\tenqueuedSelect := fmt.Sprintf(`SELECT repo FROM gorm_db_jobs %s WHERE state  = 'enqueued' LIMIT ?`, enqueuedIndexClause)\n+\tretryableSelect := fmt.Sprintf(`SELECT repo FROM gorm_db_jobs %s WHERE state like 'failed%%' AND (retry_after = NULL OR retry_after < ?) LIMIT ?`, retryableIndexClause)\n+\n \tvar todo []string\n-\tif err := s.db.Raw(\n-\t\t`SELECT repo FROM gorm_db_jobs INDEXED BY enqueued_job_idx WHERE state  = 'enqueued' LIMIT ?`,\n-\t\tlimit,\n-\t).Scan(&todo).Error; err != nil {\n+\tif err := s.db.Raw(enqueuedSelect, limit).Scan(&todo).Error; err != nil {\n \t\treturn err\n \t}\n \n \tif len(todo) < limit {\n \t\tvar moreTodo []string\n-\t\tif err := s.db.Raw(\n-\t\t\t`SELECT repo FROM gorm_db_jobs INDEXED BY retryable_job_idx WHERE state like 'failed%' AND (retry_after = NULL OR retry_after < ?) LIMIT ?`,\n-\t\t\ttime.Now(),\n-\t\t\tlimit-len(todo),\n-\t\t).Scan(&moreTodo).Error; err != nil {\n+\t\tif err := s.db.Raw(retryableSelect, time.Now(), limit-len(todo)).Scan(&moreTodo).Error; err != nil {\n \t\t\treturn err\n \t\t}\n \t\ttodo = append(todo, moreTodo...)\n---\n"}], "ideal": "Title: Only use INDEXED BY in queries when the driver is a sqlite3 driver\n\nBody: Addresses #655 "}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/transform.go\n@@ -34,7 +34,7 @@ type PostDoc struct {\n \tRecordCID         string   `json:\"record_cid\"`\n \tCreatedAt         *string  `json:\"created_at,omitempty\"`\n \tText              string   `json:\"text\"`\n-\tTextJA            string   `json:\"text_ja,omitempty\"`\n+\tTextJA            *string  `json:\"text_ja,omitempty\"`\n \tLangCode          []string `json:\"lang_code,omitempty\"`\n \tLangCodeIso2      []string `json:\"lang_code_iso2,omitempty\"`\n \tMentionDID        []string `json:\"mention_did,omitempty\"`\n@@ -186,7 +186,7 @@ func TransformPost(post *appbsky.FeedPost, ident *identity.Identity, rkey, cid s\n \t}\n \n \tif containsJapanese(post.Text) {\n-\t\tdoc.TextJA = post.Text\n+\t\tdoc.TextJA = &post.Text\n \t}\n \n \tif post.CreatedAt != \"\" {\n---\n"}], "ideal": "Title: search: ensure text_ja is optional\n\nBody: The `omitempty` logic was probably already working, but this makes it more explicit and the code more readable.\r\n\r\nThanks Jaz!"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/backfill.go\n@@ -30,7 +30,10 @@ type Job interface {\n \tSetRev(ctx context.Context, rev string) error\n \tRetryCount() int\n \n-\tBufferOps(ctx context.Context, since *string, rev string, ops []*bufferedOp) (bool, error)\n+\t// BufferOps buffers the given operations and returns true if the operations\n+\t// were buffered.\n+\t// The given operations move the repo from since to rev.\n+\tBufferOps(ctx context.Context, since *string, rev string, ops []*BufferedOp) (bool, error)\n \t// FlushBufferedOps calls the given callback for each buffered operation\n \t// Once done it clears the buffer and marks the job as \"complete\"\n \t// Allowing the Job interface to abstract away the details of how buffered\n@@ -465,7 +468,7 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n \t\treturn fmt.Errorf(\"failed to read event repo: %w\", err)\n \t}\n \n-\tvar ops []*bufferedOp\n+\tvar ops []*BufferedOp\n \tfor _, op := range evt.Ops {\n \t\tkind := repomgr.EventKind(op.Action)\n \t\tswitch kind {\n@@ -474,17 +477,16 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n \t\t\tif err != nil {\n \t\t\t\treturn fmt.Errorf(\"getting record failed (%s,%s): %w\", op.Action, op.Path, err)\n \t\t\t}\n-\n-\t\t\tops = append(ops, &bufferedOp{\n-\t\t\t\tkind: kind,\n-\t\t\t\tpath: op.Path,\n-\t\t\t\trec:  rec,\n-\t\t\t\tcid:  &cc,\n+\t\t\tops = append(ops, &BufferedOp{\n+\t\t\t\tKind:   kind,\n+\t\t\t\tPath:   op.Path,\n+\t\t\t\tRecord: rec,\n+\t\t\t\tCid:    &cc,\n \t\t\t})\n \t\tcase repomgr.EvtKindDeleteRecord:\n-\t\t\tops = append(ops, &bufferedOp{\n-\t\t\t\tkind: kind,\n-\t\t\t\tpath: op.Path,\n+\t\t\tops = append(ops, &BufferedOp{\n+\t\t\t\tKind: kind,\n+\t\t\t\tPath: op.Path,\n \t\t\t})\n \t\tdefault:\n \t\t\treturn fmt.Errorf(\"invalid op action: %q\", op.Action)\n@@ -511,17 +513,17 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n \t}\n \n \tfor _, op := range ops {\n-\t\tswitch op.kind {\n+\t\tswitch op.Kind {\n \t\tcase repomgr.EvtKindCreateRecord:\n-\t\t\tif err := bf.HandleCreateRecord(ctx, evt.Repo, evt.Rev, op.path, op.rec, op.cid); err != nil {\n+\t\t\tif err := bf.HandleCreateRecord(ctx, evt.Repo, evt.Rev, op.Path, op.Record, op.Cid); err != nil {\n \t\t\t\treturn fmt.Errorf(\"create record failed: %w\", err)\n \t\t\t}\n \t\tcase repomgr.EvtKindUpdateRecord:\n-\t\t\tif err := bf.HandleUpdateRecord(ctx, evt.Repo, evt.Rev, op.path, op.rec, op.cid); err != nil {\n+\t\t\tif err := bf.HandleUpdateRecord(ctx, evt.Repo, evt.Rev, op.Path, op.Record, op.Cid); err != nil {\n \t\t\t\treturn fmt.Errorf(\"update record failed: %w\", err)\n \t\t\t}\n \t\tcase repomgr.EvtKindDeleteRecord:\n-\t\t\tif err := bf.HandleDeleteRecord(ctx, evt.Repo, evt.Rev, op.path); err != nil {\n+\t\t\tif err := bf.HandleDeleteRecord(ctx, evt.Repo, evt.Rev, op.Path); err != nil {\n \t\t\t\treturn fmt.Errorf(\"delete record failed: %w\", err)\n \t\t\t}\n \t\t}\n@@ -535,15 +537,15 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n }\n \n func (bf *Backfiller) BufferOp(ctx context.Context, repo string, since *string, rev string, kind repomgr.EventKind, path string, rec *[]byte, cid *cid.Cid) (bool, error) {\n-\treturn bf.BufferOps(ctx, repo, since, rev, []*bufferedOp{{\n-\t\tpath: path,\n-\t\tkind: kind,\n-\t\trec:  rec,\n-\t\tcid:  cid,\n+\treturn bf.BufferOps(ctx, repo, since, rev, []*BufferedOp{{\n+\t\tPath:   path,\n+\t\tKind:   kind,\n+\t\tRecord: rec,\n+\t\tCid:    cid,\n \t}})\n }\n \n-func (bf *Backfiller) BufferOps(ctx context.Context, repo string, since *string, rev string, ops []*bufferedOp) (bool, error) {\n+func (bf *Backfiller) BufferOps(ctx context.Context, repo string, since *string, rev string, ops []*BufferedOp) (bool, error) {\n \tj, err := bf.Store.GetJob(ctx, repo)\n \tif err != nil {\n \t\tif !errors.Is(err, ErrJobNotFound) {\n---\nbackfill/gormstore.go\n@@ -168,7 +168,7 @@ func (s *Gormstore) createJobForRepo(repo, state string) error {\n \treturn nil\n }\n \n-func (j *Gormjob) BufferOps(ctx context.Context, since *string, rev string, ops []*bufferedOp) (bool, error) {\n+func (j *Gormjob) BufferOps(ctx context.Context, since *string, rev string, ops []*BufferedOp) (bool, error) {\n \tj.lk.Lock()\n \tdefer j.lk.Unlock()\n \n@@ -373,7 +373,7 @@ func (j *Gormjob) FlushBufferedOps(ctx context.Context, fn func(kind repomgr.Eve\n \t\t}\n \n \t\tfor _, op := range opset.ops {\n-\t\t\tif err := fn(op.kind, opset.rev, op.path, op.rec, op.cid); err != nil {\n+\t\t\tif err := fn(op.Kind, opset.rev, op.Path, op.Record, op.Cid); err != nil {\n \t\t\t\treturn err\n \t\t\t}\n \t\t}\n---\nbackfill/memstore.go\n@@ -10,17 +10,22 @@ import (\n \t\"github.com/ipfs/go-cid\"\n )\n \n-type bufferedOp struct {\n-\tkind repomgr.EventKind\n-\tpath string\n-\trec  *[]byte\n-\tcid  *cid.Cid\n+// A BufferedOp is an operation buffered while a repo is being backfilled.\n+type BufferedOp struct {\n+\t// Kind describes the type of operation.\n+\tKind repomgr.EventKind\n+\t// Path contains the path the operation applies to.\n+\tPath string\n+\t// Record contains the serialized record for create and update operations.\n+\tRecord *[]byte\n+\t// Cid is the CID of the record.\n+\tCid *cid.Cid\n }\n \n type opSet struct {\n \tsince *string\n \trev   string\n-\tops   []*bufferedOp\n+\tops   []*BufferedOp\n }\n \n type Memjob struct {\n@@ -107,18 +112,18 @@ func (s *Memstore) BufferOp(ctx context.Context, repo string, since *string, rev\n \tj.bufferedOps = append(j.bufferedOps, &opSet{\n \t\tsince: since,\n \t\trev:   rev,\n-\t\tops: []*bufferedOp{&bufferedOp{\n-\t\t\tpath: path,\n-\t\t\tkind: kind,\n-\t\t\trec:  rec,\n-\t\t\tcid:  cid,\n+\t\tops: []*BufferedOp{&BufferedOp{\n+\t\t\tPath:   path,\n+\t\t\tKind:   kind,\n+\t\t\tRecord: rec,\n+\t\t\tCid:    cid,\n \t\t}},\n \t})\n \tj.updatedAt = time.Now()\n \treturn true, nil\n }\n \n-func (j *Memjob) BufferOps(ctx context.Context, since *string, rev string, ops []*bufferedOp) (bool, error) {\n+func (j *Memjob) BufferOps(ctx context.Context, since *string, rev string, ops []*BufferedOp) (bool, error) {\n \tj.lk.Lock()\n \tdefer j.lk.Unlock()\n \n@@ -208,13 +213,13 @@ func (j *Memjob) FlushBufferedOps(ctx context.Context, fn func(kind repomgr.Even\n \n \t\tfor _, opset := range j.bufferedOps {\n \t\t\tfor _, op := range opset.ops {\n-\t\t\t\tif err := fn(op.kind, op.path, op.rec, op.cid); err != nil {\n+\t\t\t\tif err := fn(op.Kind, op.Path, op.Record, op.Cid); err != nil {\n \t\t\t\t\treturn err\n \t\t\t\t}\n \t\t\t}\n \t\t}\n \n-\t\tj.bufferedOps = map[string][]*bufferedOp{}\n+\t\tj.bufferedOps = map[string][]*BufferedOp{}\n \t\tj.state = StateComplete\n \n \t\treturn nil\n---\n"}], "ideal": "Title: backfill: export BufferedOp\n\nBody: (part of #638)\r\n\r\nThis exports the `backfill.BufferedOp` struct to make it possible to implement a custom `Store` and corresponding `Job`.\r\nI've also renamed the fields slightly for easier understanding, and added some documentation."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/backfill.go\n@@ -35,7 +35,7 @@ type Job interface {\n \t// Once done it clears the buffer and marks the job as \"complete\"\n \t// Allowing the Job interface to abstract away the details of how buffered\n \t// operations are stored and/or locked\n-\tFlushBufferedOps(ctx context.Context, cb func(kind, rev, path string, rec *[]byte, cid *cid.Cid) error) error\n+\tFlushBufferedOps(ctx context.Context, cb func(kind repomgr.EventKind, rev, path string, rec *[]byte, cid *cid.Cid) error) error\n \n \tClearBufferedOps(ctx context.Context) error\n }\n@@ -236,9 +236,9 @@ func (b *Backfiller) FlushBuffer(ctx context.Context, job Job) int {\n \trepo := job.Repo()\n \n \t// Flush buffered operations, clear the buffer, and mark the job as \"complete\"\n-\t// Clearning and marking are handled by the job interface\n-\terr := job.FlushBufferedOps(ctx, func(kind, rev, path string, rec *[]byte, cid *cid.Cid) error {\n-\t\tswitch repomgr.EventKind(kind) {\n+\t// Clearing and marking are handled by the job interface\n+\terr := job.FlushBufferedOps(ctx, func(kind repomgr.EventKind, rev, path string, rec *[]byte, cid *cid.Cid) error {\n+\t\tswitch kind {\n \t\tcase repomgr.EvtKindCreateRecord:\n \t\t\terr := b.HandleCreateRecord(ctx, repo, rev, path, rec, cid)\n \t\t\tif err != nil {\n@@ -467,22 +467,23 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n \n \tvar ops []*bufferedOp\n \tfor _, op := range evt.Ops {\n-\t\tswitch op.Action {\n-\t\tcase \"create\", \"update\":\n+\t\tkind := repomgr.EventKind(op.Action)\n+\t\tswitch kind {\n+\t\tcase repomgr.EvtKindCreateRecord, repomgr.EvtKindUpdateRecord:\n \t\t\tcc, rec, err := bf.getRecord(ctx, r, op)\n \t\t\tif err != nil {\n \t\t\t\treturn fmt.Errorf(\"getting record failed (%s,%s): %w\", op.Action, op.Path, err)\n \t\t\t}\n \n \t\t\tops = append(ops, &bufferedOp{\n-\t\t\t\tkind: op.Action,\n+\t\t\t\tkind: kind,\n \t\t\t\tpath: op.Path,\n \t\t\t\trec:  rec,\n \t\t\t\tcid:  &cc,\n \t\t\t})\n-\t\tcase \"delete\":\n+\t\tcase repomgr.EvtKindDeleteRecord:\n \t\t\tops = append(ops, &bufferedOp{\n-\t\t\t\tkind: op.Action,\n+\t\t\t\tkind: kind,\n \t\t\t\tpath: op.Path,\n \t\t\t})\n \t\tdefault:\n@@ -511,15 +512,15 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n \n \tfor _, op := range ops {\n \t\tswitch op.kind {\n-\t\tcase \"create\":\n+\t\tcase repomgr.EvtKindCreateRecord:\n \t\t\tif err := bf.HandleCreateRecord(ctx, evt.Repo, evt.Rev, op.path, op.rec, op.cid); err != nil {\n \t\t\t\treturn fmt.Errorf(\"create record failed: %w\", err)\n \t\t\t}\n-\t\tcase \"update\":\n+\t\tcase repomgr.EvtKindUpdateRecord:\n \t\t\tif err := bf.HandleUpdateRecord(ctx, evt.Repo, evt.Rev, op.path, op.rec, op.cid); err != nil {\n \t\t\t\treturn fmt.Errorf(\"update record failed: %w\", err)\n \t\t\t}\n-\t\tcase \"delete\":\n+\t\tcase repomgr.EvtKindDeleteRecord:\n \t\t\tif err := bf.HandleDeleteRecord(ctx, evt.Repo, evt.Rev, op.path); err != nil {\n \t\t\t\treturn fmt.Errorf(\"delete record failed: %w\", err)\n \t\t\t}\n@@ -533,7 +534,7 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n \treturn nil\n }\n \n-func (bf *Backfiller) BufferOp(ctx context.Context, repo string, since *string, rev, kind, path string, rec *[]byte, cid *cid.Cid) (bool, error) {\n+func (bf *Backfiller) BufferOp(ctx context.Context, repo string, since *string, rev string, kind repomgr.EventKind, path string, rec *[]byte, cid *cid.Cid) (bool, error) {\n \treturn bf.BufferOps(ctx, repo, since, rev, []*bufferedOp{{\n \t\tpath: path,\n \t\tkind: kind,\n---\nbackfill/backfill_test.go\n@@ -63,15 +63,15 @@ func TestBackfill(t *testing.T) {\n \t\t\tt.Fatal(err)\n \t\t}\n \t\tif s.State() == backfill.StateInProgress {\n-\t\t\tbf.BufferOp(ctx, testRepos[0], \"delete\", \"app.bsky.feed.follow/1\", nil, &cid.Undef)\n-\t\t\tbf.BufferOp(ctx, testRepos[0], \"delete\", \"app.bsky.feed.follow/2\", nil, &cid.Undef)\n-\t\t\tbf.BufferOp(ctx, testRepos[0], \"delete\", \"app.bsky.feed.follow/3\", nil, &cid.Undef)\n-\t\t\tbf.BufferOp(ctx, testRepos[0], \"delete\", \"app.bsky.feed.follow/4\", nil, &cid.Undef)\n-\t\t\tbf.BufferOp(ctx, testRepos[0], \"delete\", \"app.bsky.feed.follow/5\", nil, &cid.Undef)\n+\t\t\tbf.BufferOp(ctx, testRepos[0], repomgr.EvtKindDeleteRecord, \"app.bsky.feed.follow/1\", nil, &cid.Undef)\n+\t\t\tbf.BufferOp(ctx, testRepos[0], repomgr.EvtKindDeleteRecord, \"app.bsky.feed.follow/2\", nil, &cid.Undef)\n+\t\t\tbf.BufferOp(ctx, testRepos[0], repomgr.EvtKindDeleteRecord, \"app.bsky.feed.follow/3\", nil, &cid.Undef)\n+\t\t\tbf.BufferOp(ctx, testRepos[0], repomgr.EvtKindDeleteRecord, \"app.bsky.feed.follow/4\", nil, &cid.Undef)\n+\t\t\tbf.BufferOp(ctx, testRepos[0], repomgr.EvtKindDeleteRecord, \"app.bsky.feed.follow/5\", nil, &cid.Undef)\n \n-\t\t\tbf.BufferOp(ctx, testRepos[0], \"create\", \"app.bsky.feed.follow/1\", nil, &cid.Undef)\n+\t\t\tbf.BufferOp(ctx, testRepos[0], repomgr.EvtKindCreateRecord, \"app.bsky.feed.follow/1\", nil, &cid.Undef)\n \n-\t\t\tbf.BufferOp(ctx, testRepos[0], \"update\", \"app.bsky.feed.follow/1\", nil, &cid.Undef)\n+\t\t\tbf.BufferOp(ctx, testRepos[0], repomgr.EvtKindUpdateRecord, \"app.bsky.feed.follow/1\", nil, &cid.Undef)\n \n \t\t\tbreak\n \t\t}\n---\nbackfill/gormstore.go\n@@ -8,6 +8,7 @@ import (\n \t\"sync\"\n \t\"time\"\n \n+\t\"github.com/bluesky-social/indigo/repomgr\"\n \t\"github.com/ipfs/go-cid\"\n \t\"gorm.io/gorm\"\n )\n@@ -328,7 +329,7 @@ func (j *Gormjob) SetState(ctx context.Context, state string) error {\n \treturn j.db.Save(j.dbj).Error\n }\n \n-func (j *Gormjob) FlushBufferedOps(ctx context.Context, fn func(kind, rev, path string, rec *[]byte, cid *cid.Cid) error) error {\n+func (j *Gormjob) FlushBufferedOps(ctx context.Context, fn func(kind repomgr.EventKind, rev, path string, rec *[]byte, cid *cid.Cid) error) error {\n \t// TODO: this will block any events for this repo while this flush is ongoing, is that okay?\n \tj.lk.Lock()\n \tdefer j.lk.Unlock()\n---\nbackfill/memstore.go\n@@ -6,11 +6,12 @@ import (\n \t\"sync\"\n \t\"time\"\n \n+\t\"github.com/bluesky-social/indigo/repomgr\"\n \t\"github.com/ipfs/go-cid\"\n )\n \n type bufferedOp struct {\n-\tkind string\n+\tkind repomgr.EventKind\n \tpath string\n \trec  *[]byte\n \tcid  *cid.Cid\n@@ -81,7 +82,7 @@ func (s *Memstore) EnqueueJobWithState(repo, state string) error {\n \treturn nil\n }\n \n-func (s *Memstore) BufferOp(ctx context.Context, repo string, since *string, rev, kind, path string, rec *[]byte, cid *cid.Cid) (bool, error) {\n+func (s *Memstore) BufferOp(ctx context.Context, repo string, since *string, rev string, kind repomgr.EventKind, path string, rec *[]byte, cid *cid.Cid) (bool, error) {\n \ts.lk.Lock()\n \n \t// If the job doesn't exist, we can't buffer an op for it\n@@ -199,7 +200,7 @@ func (j *Memjob) SetRev(ctx context.Context, rev string) error {\n \treturn nil\n }\n \n-func (j *Memjob) FlushBufferedOps(ctx context.Context, fn func(kind, rev, path string, rec *[]byte, cid *cid.Cid) error) error {\n+func (j *Memjob) FlushBufferedOps(ctx context.Context, fn func(kind repomgr.EventKind, rev, path string, rec *[]byte, cid *cid.Cid) error) error {\n \tpanic(\"TODO: copy what we end up doing from the gormstore\")\n \t/*\n \t\tj.lk.Lock()\n---\n"}], "ideal": "Title: backfill: use constants for bufferedOp.kind\n\nBody: (Part of https://github.com/bluesky-social/indigo/issues/638)\r\n\r\nThis utilizes constants from the `repomgr` package for buffered operations.\r\nThis was already the case, actually, as they were used [here](https://github.com/bluesky-social/indigo/blob/main/backfill/backfill.go#L241), I just added them throughout the code.\r\n\r\nThey're also used to check the operations emitted by the firehose: https://github.com/bluesky-social/indigo/blob/main/backfill/backfill.go#L469-L471\r\nThe firehose, in turn, uses the events emitted by the repo manager for the `Action` field in firehose events: https://github.com/bluesky-social/indigo/blob/main/indexer/indexer.go#L83-L94\r\nThis brings us full circle:\r\nRepo manager emits diff operations -> firehose repo commit ops `.Action` -> backfill buffered op `.kind`\r\n\r\nNotably, the constants are also given in the lexicon: https://github.com/bluesky-social/atproto/blob/main/lexicons/com/atproto/sync/subscribeRepos.json#L178\r\nBut `lexgen` does not generate constants for them.\r\n\r\nThe test in `backfill_test.go` is broken, but I changed the constants anyway."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/visual/hiveai_client.go\n@@ -89,31 +89,39 @@ func summarizeSexualLabels(cl []HiveAIResp_Class) string {\n \t\tscores[cls.Class] = cls.Score\n \t}\n \n+\tthreshold := 0.90\n+\n+\t// if this is furry art content, then require very high confidence when flagging for any sexual reason\n+\t// note that this is a custom model, not always returned in generic Hive responses\n+\tif furryScore, ok := scores[\"furry-yes_furry\"]; ok && furryScore > 0.95 {\n+\t\tthreshold = 0.99\n+\t}\n+\n \t// first check if porn...\n \tfor _, pornClass := range []string{\"yes_sexual_activity\", \"animal_genitalia_and_human\", \"yes_realistic_nsfw\"} {\n-\t\tif scores[pornClass] >= 0.9 {\n+\t\tif scores[pornClass] >= threshold {\n \t\t\treturn \"porn\"\n \t\t}\n \t}\n-\tif scores[\"general_nsfw\"] >= 0.9 {\n+\tif scores[\"general_nsfw\"] >= threshold {\n \t\t// special case for some anime examples\n \t\tif scores[\"animated_animal_genitalia\"] >= 0.5 {\n \t\t\treturn \"porn\"\n \t\t}\n \n \t\t// special case for some pornographic/explicit classic drawings\n-\t\tif scores[\"yes_undressed\"] >= 0.9 && scores[\"yes_sexual_activity\"] >= 0.9 {\n+\t\tif scores[\"yes_undressed\"] >= threshold && scores[\"yes_sexual_activity\"] >= threshold {\n \t\t\treturn \"porn\"\n \t\t}\n \t}\n \n \t// then check for sexual suggestive (which may include nudity)...\n \tfor _, sexualClass := range []string{\"yes_sexual_intent\", \"yes_sex_toy\"} {\n-\t\tif scores[sexualClass] >= 0.9 {\n+\t\tif scores[sexualClass] >= threshold {\n \t\t\treturn \"sexual\"\n \t\t}\n \t}\n-\tif scores[\"yes_undressed\"] >= 0.9 {\n+\tif scores[\"yes_undressed\"] >= threshold {\n \t\t// special case for bondage examples\n \t\tif scores[\"yes_sex_toy\"] > 0.75 {\n \t\t\treturn \"sexual\"\n@@ -122,15 +130,15 @@ func summarizeSexualLabels(cl []HiveAIResp_Class) string {\n \n \t// then non-sexual nudity...\n \tfor _, nudityClass := range []string{\"yes_male_nudity\", \"yes_female_nudity\", \"yes_undressed\"} {\n-\t\tif scores[nudityClass] >= 0.9 {\n+\t\tif scores[nudityClass] >= threshold {\n \t\t\treturn \"nudity\"\n \t\t}\n \t}\n \n \t// then finally flag remaining \"underwear\" images in to sexually suggestive\n \t// (after non-sexual content already labeled above)\n \tfor _, underwearClass := range []string{\"yes_male_underwear\", \"yes_female_underwear\"} {\n-\t\tif scores[underwearClass] >= 0.9 {\n+\t\tif scores[underwearClass] >= threshold {\n \t\t\treturn \"sexual\"\n \t\t}\n \t}\n---\n"}], "ideal": "Title: visual: tweak Hive thesholds for furry content specifically\n\nBody: Experimental improvement to auto-labeling, specifically for furry art (aka, cartoon content). Should reduce false-positive sexual and porn labels on this category of content (though still some false-positives)."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/gosky/admin.go\n@@ -29,6 +29,10 @@ var adminCmd = &cli.Command{\n \t\t\tEnvVars:  []string{\"ATP_AUTH_ADMIN_PASSWORD\"},\n \t\t\tRequired: true,\n \t\t},\n+\t\t&cli.StringFlag{\n+\t\t\tName:  \"admin-endpoint\",\n+\t\t\tValue: \"https://mod.bsky.app\",\n+\t\t},\n \t},\n \tSubcommands: []*cli.Command{\n \t\tbuildInviteTreeCmd,\n@@ -78,7 +82,7 @@ var checkUserCmd = &cli.Command{\n \n \t\tadminKey := cctx.String(\"admin-password\")\n \t\txrpcc.AdminToken = &adminKey\n-\t\txrpcc.Host = id.PDSEndpoint()\n+\t\txrpcc.Host = cctx.String(\"admin-endpoint\")\n \n \t\trep, err := toolsozone.ModerationGetRepo(ctx, xrpcc, did)\n \t\tif err != nil {\n@@ -623,25 +627,25 @@ var takeDownAccountCmd = &cli.Command{\n \n \t\tfor _, did := range cctx.Args().Slice() {\n \t\t\tif !strings.HasPrefix(did, \"did:\") {\n-\t\t\t\tphr := &api.ProdHandleResolver{}\n-\t\t\t\tresp, err := phr.ResolveHandleToDid(ctx, did)\n+\t\t\t\tdir := identity.DefaultDirectory()\n+\t\t\t\tresp, err := dir.LookupHandle(ctx, syntax.Handle(did))\n \t\t\t\tif err != nil {\n \t\t\t\t\treturn err\n \t\t\t\t}\n \n-\t\t\t\tdid = resp\n+\t\t\t\tdid = resp.DID.String()\n \t\t\t}\n \n \t\t\treason := cctx.String(\"reason\")\n \t\t\tadminUser := cctx.String(\"admin-user\")\n \t\t\tif !strings.HasPrefix(adminUser, \"did:\") {\n-\t\t\t\tphr := &api.ProdHandleResolver{}\n-\t\t\t\tresp, err := phr.ResolveHandleToDid(ctx, adminUser)\n+\t\t\t\tdir := identity.DefaultDirectory()\n+\t\t\t\tresp, err := dir.LookupHandle(ctx, syntax.Handle(adminUser))\n \t\t\t\tif err != nil {\n \t\t\t\t\treturn err\n \t\t\t\t}\n \n-\t\t\t\tadminUser = resp\n+\t\t\t\tadminUser = resp.DID.String()\n \t\t\t}\n \n \t\t\tresp, err := toolsozone.ModerationEmitEvent(ctx, xrpcc, &toolsozone.ModerationEmitEvent_Input{\n---\ncmd/gosky/handle.go\n@@ -4,8 +4,9 @@ import (\n \t\"context\"\n \t\"fmt\"\n \n-\tapi \"github.com/bluesky-social/indigo/api\"\n \tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n+\t\"github.com/bluesky-social/indigo/atproto/identity\"\n+\t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \t\"github.com/bluesky-social/indigo/util/cliutil\"\n \n \tcli \"github.com/urfave/cli/v2\"\n@@ -30,15 +31,20 @@ var resolveHandleCmd = &cli.Command{\n \t\tif err != nil {\n \t\t\treturn err\n \t\t}\n-\t\thandle := args[0]\n \n-\t\tphr := &api.ProdHandleResolver{}\n-\t\tout, err := phr.ResolveHandleToDid(ctx, handle)\n+\t\th, err := syntax.ParseHandle(args[0])\n+\t\tif err != nil {\n+\t\t\treturn fmt.Errorf(\"resolving %q: %w\", args[0], err)\n+\t\t}\n+\n+\t\tdir := identity.DefaultDirectory()\n+\n+\t\tres, err := dir.LookupHandle(ctx, h)\n \t\tif err != nil {\n \t\t\treturn err\n \t\t}\n \n-\t\tfmt.Println(out)\n+\t\tfmt.Println(res.DID)\n \n \t\treturn nil\n \t},\n---\ncmd/gosky/main.go\n@@ -765,7 +765,7 @@ var listLabelsCmd = &cli.Command{\n \t\tsince := time.Now().Add(-1 * delta).UnixMilli()\n \n \t\txrpcc := &xrpc.Client{\n-\t\t\tHost: \"https://api.bsky.app\",\n+\t\t\tHost: \"https://mod.bsky.app\",\n \t\t}\n \n \t\tfor {\n---\n"}], "ideal": "Title: fix handle resolution in some cli commands\n\nBody: probably more of this to come, the ProdHandleResolver type is basically broken now"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/base_directory.go\n@@ -53,11 +53,6 @@ func (d *BaseDirectory) LookupHandle(ctx context.Context, h syntax.Handle) (*Ide\n \t}\n \tident.Handle = declared\n \n-\t// optimistic pre-parsing of public key\n-\tpk, err := ident.PublicKey()\n-\tif nil == err {\n-\t\tident.ParsedPublicKey = pk\n-\t}\n \treturn &ident, nil\n }\n \n@@ -88,11 +83,6 @@ func (d *BaseDirectory) LookupDID(ctx context.Context, did syntax.DID) (*Identit\n \t\t}\n \t}\n \n-\t// optimistic pre-parsing of public key\n-\tpk, err := ident.PublicKey()\n-\tif nil == err {\n-\t\tident.ParsedPublicKey = pk\n-\t}\n \treturn &ident, nil\n }\n \n---\natproto/identity/identity.go\n@@ -55,7 +55,8 @@ var ErrDIDNotFound = errors.New(\"DID not found\")\n // Indicates that DID resolution process failed. A wrapped error may provide more context.\n var ErrDIDResolutionFailed = errors.New(\"DID resolution failed\")\n \n-var ErrKeyNotDeclared = errors.New(\"identity has no public repo signing key\")\n+// Indicates that DID document did not include a public key with the specified ID\n+var ErrKeyNotDeclared = errors.New(\"DID document did not declare a relevant public key\")\n \n var DefaultPLCURL = \"https://plc.directory\"\n \n@@ -91,9 +92,6 @@ type Identity struct {\n \tAlsoKnownAs []string\n \tServices    map[string]Service\n \tKeys        map[string]Key\n-\n-\t// If a valid atproto repo signing public key was parsed, it can be cached here. This is a nullable/optional field (crypto.PublicKey is an interface). Calling code should use [Identity.PublicKey] instead of accessing this member.\n-\tParsedPublicKey crypto.PublicKey\n }\n \n type Key struct {\n@@ -155,34 +153,25 @@ func ParseIdentity(doc *DIDDocument) Identity {\n \t}\n }\n \n-// Identifies and parses the atproto repo signing public key, specifically, out of any keys associated with this identity.\n+// Identifies and parses the atproto repo signing public key, specifically, out of any keys in this identity's DID document.\n //\n // Returns [ErrKeyNotFound] if there is no such key.\n //\n // Note that [crypto.PublicKey] is an interface, not a concrete type.\n func (i *Identity) PublicKey() (crypto.PublicKey, error) {\n-\tif i.ParsedPublicKey != nil {\n-\t\treturn i.ParsedPublicKey, nil\n-\t}\n-\tif i.Keys == nil {\n-\t\treturn nil, fmt.Errorf(\"identity has no atproto public key attached\")\n-\t}\n-\treturn i.PublicKeyFor(\"atproto\")\n+\treturn i.GetPublicKey(\"atproto\")\n }\n \n-// Identifies and parses a specified service signing public key, specifically, out of any keys associated with this identity.\n+// Identifies and parses a specified service signing public key out of any keys in this identity's DID document.\n //\n // Returns [ErrKeyNotFound] if there is no such key.\n //\n // Note that [crypto.PublicKey] is an interface, not a concrete type.\n-func (i *Identity) PublicKeyFor(forKey string) (crypto.PublicKey, error) {\n-\tif i.ParsedPublicKey != nil {\n-\t\treturn i.ParsedPublicKey, nil\n-\t}\n+func (i *Identity) GetPublicKey(id string) (crypto.PublicKey, error) {\n \tif i.Keys == nil {\n-\t\treturn nil, fmt.Errorf(\"identity has no atproto public key attached\")\n+\t\treturn nil, ErrKeyNotDeclared\n \t}\n-\tk, ok := i.Keys[forKey]\n+\tk, ok := i.Keys[id]\n \tif !ok {\n \t\treturn nil, ErrKeyNotDeclared\n \t}\n@@ -212,14 +201,25 @@ func (i *Identity) PublicKeyFor(forKey string) (crypto.PublicKey, error) {\n \t}\n }\n \n-// The home PDS endpoint for this account, if one is included in identity metadata (returns empty string if not found).\n+// The home PDS endpoint for this identity, if one is included in the DID document.\n //\n-// The endpoint should be an HTTP URL with method, hostname, and optional port, and (usually) no path segments.\n+// The endpoint should be an HTTP URL with method, hostname, and optional port. It may or may not include path segments.\n+//\n+// Returns an empty string if the serivce isn't found, or if the URL fails to parse.\n func (i *Identity) PDSEndpoint() string {\n+\treturn i.GetServiceEndpoint(\"atproto_pds\")\n+}\n+\n+// Returns the service endpoint URL for specified service ID (the fragment part of identifier, not including the hash symbol).\n+//\n+// The endpoint should be an HTTP URL with method, hostname, and optional port. It may or may not include path segments.\n+//\n+// Returns an empty string if the serivce isn't found, or if the URL fails to parse.\n+func (i *Identity) GetServiceEndpoint(id string) string {\n \tif i.Services == nil {\n \t\treturn \"\"\n \t}\n-\tendpoint, ok := i.Services[\"atproto_pds\"]\n+\tendpoint, ok := i.Services[id]\n \tif !ok {\n \t\treturn \"\"\n \t}\n---\natproto/identity/redisdir/redis_directory.go\n@@ -112,7 +112,6 @@ func (d *RedisDirectory) updateHandle(ctx context.Context, h syntax.Handle) (*ha\n \t\treturn &he, nil\n \t}\n \n-\tident.ParsedPublicKey = nil\n \tentry := identityEntry{\n \t\tUpdated:  time.Now(),\n \t\tIdentity: ident,\n@@ -195,10 +194,6 @@ func (d *RedisDirectory) ResolveHandle(ctx context.Context, h syntax.Handle) (sy\n \n func (d *RedisDirectory) updateDID(ctx context.Context, did syntax.DID) (*identityEntry, error) {\n \tident, err := d.Inner.LookupDID(ctx, did)\n-\t// wipe parsed public key; it's a waste of space and can't serialize\n-\tif nil == err {\n-\t\tident.ParsedPublicKey = nil\n-\t}\n \t// persist the identity lookup error, instead of processing it immediately\n \tentry := identityEntry{\n \t\tUpdated:  time.Now(),\n---\nautomod/capture/capture.go\n@@ -26,8 +26,6 @@ func CaptureRecent(ctx context.Context, eng *automod.Engine, atid syntax.AtIdent\n \t\t}\n \t}\n \n-\t// clear any pre-parsed key, which would fail to marshal as JSON\n-\tident.ParsedPublicKey = nil\n \tam, err := eng.GetAccountMeta(ctx, ident)\n \tif err != nil {\n \t\treturn nil, err\n---\nautomod/capture/testdata/capture_atprotocom.json\n@@ -18,8 +18,7 @@\n           \"Type\": \"Multikey\",\n           \"PublicKeyMultibase\": \"zQ3shunBKsXixLxKtC5qeSG9E4J5RkGN57im31pcTzbNQnm5w\"\n         }\n-      },\n-      \"ParsedPublicKey\": null\n+      }\n     },\n     \"Profile\": {\n       \"HasAvatar\": true,\n---\nautomod/engine/fetch_account_meta.go\n@@ -16,9 +16,6 @@ func (e *Engine) GetAccountMeta(ctx context.Context, ident *identity.Identity) (\n \n \tlogger := e.Logger.With(\"did\", ident.DID.String())\n \n-\t// wipe parsed public key; it's a waste of space and can't serialize\n-\tident.ParsedPublicKey = nil\n-\n \t// fallback in case client wasn't configured (eg, testing)\n \tif e.BskyClient == nil {\n \t\tlogger.Warn(\"skipping account meta hydration\")\n---\nautomod/rules/quick.go\n@@ -9,7 +9,7 @@ import (\n \t\"github.com/bluesky-social/indigo/automod\"\n )\n \n-var botLinkStrings = []string{\"ainna13762491\", \"LINK\u62bc\u3057\u3066\", \"\u2192 https://tiny.one/\"}\n+var botLinkStrings = []string{\"ainna13762491\", \"LINK\u62bc\u3057\u3066\", \"\u2192 https://tiny\", \"\u21d2 http://tiny\"}\n var botSpamTLDs = []string{\".today\", \".life\"}\n var botSpamStrings = []string{\"515-9719\"}\n \n---\nautomod/rules/testdata/capture_hackerdarkweb.json\n@@ -18,8 +18,7 @@\n           \"Type\": \"Multikey\",\n           \"PublicKeyMultibase\": \"zQ3sha9ULLgA6zyJmk1z2uDkpkSs4Ypou33RE8XuhwWtSHF75\"\n         }\n-      },\n-      \"ParsedPublicKey\": null\n+      }\n     },\n     \"Profile\": {\n       \"HasAvatar\": true,\n---\n"}], "ideal": "Title: identity: remove ParsedPublicKey caching; tweak get/parsing method names and doc-comments\n\nBody: The main thing here is removing the cached (\"pre-parsed\") key in the identity doc. I think this was non-trivial overhead when doing lots of lookups, and required manual override when serializing (actually caching!) the objects. I don't think we relied on the key parse caching for performance anywhere; if actual profiling shows we need it, should add as a private field, or cache externally.\r\n\r\n`PublicKeyFor` read a bit weird and non-idiomatic to my eyes so I updated to `GetPublicKey(id)`, and added a service endpoint equivalent. If this is too nit-picky or the method is being used a bunch elsewhere (branches?) can revert that bit."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/identity.go\n@@ -167,7 +167,22 @@ func (i *Identity) PublicKey() (crypto.PublicKey, error) {\n \tif i.Keys == nil {\n \t\treturn nil, fmt.Errorf(\"identity has no atproto public key attached\")\n \t}\n-\tk, ok := i.Keys[\"atproto\"]\n+\treturn i.PublicKeyFor(\"atproto\")\n+}\n+\n+// Identifies and parses a specified service signing public key, specifically, out of any keys associated with this identity.\n+//\n+// Returns [ErrKeyNotFound] if there is no such key.\n+//\n+// Note that [crypto.PublicKey] is an interface, not a concrete type.\n+func (i *Identity) PublicKeyFor(forKey string) (crypto.PublicKey, error) {\n+\tif i.ParsedPublicKey != nil {\n+\t\treturn i.ParsedPublicKey, nil\n+\t}\n+\tif i.Keys == nil {\n+\t\treturn nil, fmt.Errorf(\"identity has no atproto public key attached\")\n+\t}\n+\tk, ok := i.Keys[forKey]\n \tif !ok {\n \t\treturn nil, ErrKeyNotDeclared\n \t}\n---\n"}], "ideal": "Title: atproto/identity: add PublicKeyFor method\n\nBody: For labelers we need to specify which service public key we grab."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/parse_query.go\n@@ -43,7 +43,11 @@ func ParseQuery(ctx context.Context, dir identity.Directory, raw string) (string\n \t\t\tcontinue\n \t\t}\n \t\tif strings.HasPrefix(p, \"from:\") && len(p) > 6 {\n-\t\t\thandle, err := syntax.ParseHandle(p[5:])\n+\t\t\th := p[5:]\n+\t\t\tif h[0] == '@' {\n+\t\t\t\th = h[1:]\n+\t\t\t}\n+\t\t\thandle, err := syntax.ParseHandle(h)\n \t\t\tif err != nil {\n \t\t\t\tkeep = append(keep, p)\n \t\t\t\tcontinue\n---\nsearch/parse_query_test.go\n@@ -55,4 +55,9 @@ func TestParseQuery(t *testing.T) {\n \tq, f = ParseQuery(ctx, &dir, p6)\n \tassert.Equal(`some other stuff`, q)\n \tassert.Equal(2, len(f))\n+\n+\tp7 := \"known from:@known.example.com\"\n+\tq, f = ParseQuery(ctx, &dir, p7)\n+\tassert.Equal(\"known\", q)\n+\tassert.Equal(1, len(f))\n }\n---\n"}], "ideal": "Title: search: allow at-prefixed handle with \"from:\"\n\nBody: has a bit of test coverage which gives me confidence, but haven't done any other testings. blast radius seems small.\r\n\r\ncloses: https://github.com/bluesky-social/atproto/issues/2028"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/parse_query.go\n@@ -25,6 +25,7 @@ func ParseQuery(ctx context.Context, dir identity.Directory, raw string) (string\n \tfor _, p := range parts {\n \t\tp = strings.Trim(p, \"\\\"\")\n \n+\t\t// Hashtag Parsing\n \t\tif strings.HasPrefix(p, \"#\") && len(p) > 1 {\n \t\t\tfilters = append(filters, map[string]interface{}{\n \t\t\t\t\"term\": map[string]interface{}{\n@@ -36,29 +37,38 @@ func ParseQuery(ctx context.Context, dir identity.Directory, raw string) (string\n \t\t\t})\n \t\t\tcontinue\n \t\t}\n+\n+\t\t// DID Parsing\n \t\tif strings.HasPrefix(p, \"did:\") {\n \t\t\tfilters = append(filters, map[string]interface{}{\n \t\t\t\t\"term\": map[string]interface{}{\"did\": p},\n \t\t\t})\n \t\t\tcontinue\n \t\t}\n+\n+\t\t// Explicit Handle/DID Parsing\n \t\tif strings.HasPrefix(p, \"from:\") && len(p) > 6 {\n-\t\t\thandle, err := syntax.ParseHandle(p[5:])\n-\t\t\tif err != nil {\n-\t\t\t\tkeep = append(keep, p)\n+\t\t\tdid, err := identifierToDID(ctx, dir, p[5:])\n+\t\t\tif nil == err {\n+\t\t\t\tfilters = append(filters, map[string]interface{}{\n+\t\t\t\t\t\"term\": map[string]interface{}{\"from\": did.String()},\n+\t\t\t\t})\n \t\t\t\tcontinue\n \t\t\t}\n-\t\t\tid, err := dir.LookupHandle(ctx, handle)\n-\t\t\tif err != nil {\n-\t\t\t\tif err != identity.ErrHandleNotFound {\n-\t\t\t\t\tslog.Error(\"failed to resolve handle\", \"err\", err)\n-\t\t\t\t}\n+\t\t\tslog.Error(\"failed to parse identifier in from: clause\", \"error\", err)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\t// Bsky URL Parsing (for quote posts)\n+\t\tif strings.HasPrefix(p, \"https://bsky.app/profile/\") {\n+\t\t\tatURI, err := bskyURLtoATURI(ctx, dir, p)\n+\t\t\tif nil == err {\n+\t\t\t\tfilters = append(filters, map[string]interface{}{\n+\t\t\t\t\t\"term\": map[string]interface{}{\"embed_aturi\": atURI.String()},\n+\t\t\t\t})\n \t\t\t\tcontinue\n \t\t\t}\n-\t\t\tfilters = append(filters, map[string]interface{}{\n-\t\t\t\t\"term\": map[string]interface{}{\"did\": id.DID.String()},\n-\t\t\t})\n-\t\t\tcontinue\n+\t\t\tslog.Error(\"failed to parse bsky URL\", \"error\", err)\n \t\t}\n \n \t\tkeep = append(keep, p)\n@@ -85,3 +95,56 @@ func ParseQuery(ctx context.Context, dir identity.Directory, raw string) (string\n \t}\n \treturn out, filters\n }\n+\n+func identifierToDID(ctx context.Context, dir identity.Directory, term string) (*syntax.DID, error) {\n+\tatID, err := syntax.ParseAtIdentifier(term)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to parse identifier: %w\", err)\n+\t}\n+\n+\tif atID.IsDID() {\n+\t\tasDID, _ := atID.AsDID()\n+\t\treturn &asDID, nil\n+\t}\n+\n+\tif atID.IsHandle() {\n+\t\tasHandle, _ := atID.AsHandle()\n+\t\tid, err := dir.LookupHandle(ctx, asHandle)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"failed to resolve handle: %w\", err)\n+\t\t}\n+\t\treturn &id.DID, nil\n+\t}\n+\n+\treturn nil, fmt.Errorf(\"unexpectedly reached bottom of parsing: %s\", term)\n+}\n+\n+func bskyURLtoATURI(ctx context.Context, dir identity.Directory, term string) (*syntax.ATURI, error) {\n+\t// split up the URL\n+\tparts := strings.Split(term, \"/\")\n+\tif len(parts) < 7 {\n+\t\treturn nil, fmt.Errorf(\"Post URL missing parts: %s\", term)\n+\t}\n+\n+\tif parts[3] != \"profile\" && parts[5] != \"post\" {\n+\t\treturn nil, fmt.Errorf(\"unexpected URL pattern: not of the form /profile/<ident>/post/<rkey>\")\n+\t}\n+\n+\trkey, err := syntax.ParseRecordKey(parts[6])\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to parse record key: %w\", err)\n+\t}\n+\n+\tdid, err := identifierToDID(ctx, dir, parts[4])\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to parse identifier: %w\", err)\n+\t}\n+\n+\tatURI, err := syntax.ParseATURI(fmt.Sprintf(\"at://%s/app.bsky.feed.post/%s\", did, rkey))\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to construct ATURI: %w\", err)\n+\t}\n+\n+\treturn &atURI, nil\n+\n+}\n---\nsearch/parse_query_test.go\n@@ -55,4 +55,20 @@ func TestParseQuery(t *testing.T) {\n \tq, f = ParseQuery(ctx, &dir, p6)\n \tassert.Equal(`some other stuff`, q)\n \tassert.Equal(2, len(f))\n+\n+\tp7 := `https://bsky.app/profile/did:plc:q6gjnaw2blty4crticxkmujt/post/3kmmi33vc2l2w`\n+\tq, f = ParseQuery(ctx, &dir, p7)\n+\tassert.Equal(`*`, q)\n+\tassert.Equal(1, len(f))\n+\tassert.Equal([]map[string]interface{}{\n+\t\t{\"term\": map[string]interface{}{\"embed_aturi\": \"at://did:plc:q6gjnaw2blty4crticxkmujt/app.bsky.feed.post/3kmmi33vc2l2w\"}},\n+\t}, f)\n+\n+\tp8 := `https://bsky.app/profile/known.example.com/post/3kmmi33vc2l2w`\n+\tq, f = ParseQuery(ctx, &dir, p8)\n+\tassert.Equal(`*`, q)\n+\tassert.Equal(1, len(f))\n+\tassert.Equal([]map[string]interface{}{\n+\t\t{\"term\": map[string]interface{}{\"embed_aturi\": \"at://did:plc:abc222/app.bsky.feed.post/3kmmi33vc2l2w\"}},\n+\t}, f)\n }\n---\n"}], "ideal": "Title: Support searching for quotes of a post when you see a bsky.app post U\u2026\n\nBody: \u2026RL in a search term"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/parse_query.go\n@@ -29,7 +29,7 @@ func ParseQuery(ctx context.Context, dir identity.Directory, raw string) (string\n \t\t\tfilters = append(filters, map[string]interface{}{\n \t\t\t\t\"term\": map[string]interface{}{\n \t\t\t\t\t\"tag\": map[string]interface{}{\n-\t\t\t\t\t\t\"value\":            strings.ToLower(p[1:]),\n+\t\t\t\t\t\t\"value\":            p[1:],\n \t\t\t\t\t\t\"case_insensitive\": true,\n \t\t\t\t\t},\n \t\t\t\t},\n---\n"}], "ideal": "Title: Remove toLower from query since we set caseInsensitive, it was causin\u2026\n\nBody: \u2026g some issues with cyrillic capitalCased queries"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/backfill.go\n@@ -490,8 +490,8 @@ func (bf *Backfiller) HandleEvent(ctx context.Context, evt *atproto.SyncSubscrib\n \t\t}\n \t}\n \n-\tif evt.Prev == nil {\n-\t\t// The first event for a repo will have a nil prev, we can enqueue the repo as \"complete\" to avoid fetching the empty repo\n+\tif evt.Since == nil {\n+\t\t// The first event for a repo will have a nil since, we can enqueue the repo as \"complete\" to avoid fetching the empty repo\n \t\tif err := bf.Store.EnqueueJobWithState(ctx, evt.Repo, StateComplete); err != nil {\n \t\t\treturn fmt.Errorf(\"failed to enqueue job with state for repo %q: %w\", evt.Repo, err)\n \t\t}\n---\n"}], "ideal": "Title: Check for since, not prev, when backfilling\n\nBody: Resolves issue raised in https://github.com/bluesky-social/indigo/issues/595\r\n\r\nDouble checked with https://github.com/ericvolp12/atp-looking-glass to see what's coming through the firehose for `since` and `prev` fields and yep this was my bad."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/gosky/main.go\n@@ -433,6 +433,45 @@ var getRecordCmd = &cli.Command{\n \t\t\t\treturn err\n \t\t\t}\n \n+\t\t\tfmt.Println(string(b))\n+\t\t\treturn nil\n+\t\t} else if strings.HasPrefix(cctx.Args().First(), \"https://bsky.app\") {\n+\t\t\txrpcc, err := cliutil.GetXrpcClient(cctx, false)\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\n+\t\t\tparts := strings.Split(cctx.Args().First(), \"/\")\n+\t\t\tif len(parts) < 4 {\n+\t\t\t\treturn fmt.Errorf(\"invalid post url\")\n+\t\t\t}\n+\t\t\trkey := parts[len(parts)-1]\n+\t\t\tdid := parts[len(parts)-3]\n+\n+\t\t\tvar collection string\n+\t\t\tswitch parts[len(parts)-2] {\n+\t\t\tcase \"post\":\n+\t\t\t\tcollection = \"app.bsky.feed.post\"\n+\t\t\tcase \"profile\":\n+\t\t\t\tcollection = \"app.bsky.actor.profile\"\n+\t\t\t\tdid = rkey\n+\t\t\t\trkey = \"self\"\n+\t\t\tcase \"feed\":\n+\t\t\t\tcollection = \"app.bsky.feed.generator\"\n+\t\t\tdefault:\n+\t\t\t\treturn fmt.Errorf(\"unrecognized link\")\n+\t\t\t}\n+\n+\t\t\tout, err := comatproto.RepoGetRecord(ctx, xrpcc, \"\", collection, did, rkey)\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\n+\t\t\tb, err := json.MarshalIndent(out.Value.Val, \"\", \"  \")\n+\t\t\tif err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\n \t\t\tfmt.Println(string(b))\n \t\t\treturn nil\n \t\t} else {\n---\n"}], "ideal": "Title: handle bsky.app urls in get-record\n\nBody: got tired of translating bsky.app links into at:// links"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/fedmgr.go\n@@ -563,6 +563,21 @@ func (s *Slurper) handleConnection(ctx context.Context, host *models.PDS, con *w\n \t\t\tlog.Infow(\"info event\", \"name\", info.Name, \"message\", info.Message, \"host\", host.Host)\n \t\t\treturn nil\n \t\t},\n+\t\tRepoIdentity: func(ident *comatproto.SyncSubscribeRepos_Identity) error {\n+\t\t\tlog.Infow(\"identity event\", \"did\", ident.Did)\n+\t\t\tif err := s.cb(context.TODO(), host, &events.XRPCStreamEvent{\n+\t\t\t\tRepoIdentity: ident,\n+\t\t\t}); err != nil {\n+\t\t\t\tlog.Errorf(\"failed handling event from %q (%d): %s\", host.Host, ident.Seq, err)\n+\t\t\t}\n+\t\t\t*lastCursor = ident.Seq\n+\n+\t\t\tif err := s.updateCursor(sub, *lastCursor); err != nil {\n+\t\t\t\treturn fmt.Errorf(\"updating cursor: %w\", err)\n+\t\t\t}\n+\n+\t\t\treturn nil\n+\t\t},\n \t\t// TODO: all the other event types (handle change, migration, etc)\n \t\tError: func(errf *events.ErrorFrame) error {\n \t\t\tswitch errf.Error {\n---\ncmd/hepa/consumer.go\n@@ -65,7 +65,7 @@ func (s *Server) RunConsumer(ctx context.Context) error {\n \t\t\t}\n \t\t\treturn nil\n \t\t},\n-\t\tIdentity: func(evt *comatproto.SyncSubscribeRepos_Identity) error {\n+\t\tRepoIdentity: func(evt *comatproto.SyncSubscribeRepos_Identity) error {\n \t\t\tatomic.StoreInt64(&s.lastSeq, evt.Seq)\n \t\t\tdid, err := syntax.ParseDID(evt.Did)\n \t\t\tif err != nil {\n---\nevents/consumer.go\n@@ -17,7 +17,7 @@ import (\n type RepoStreamCallbacks struct {\n \tRepoCommit    func(evt *comatproto.SyncSubscribeRepos_Commit) error\n \tRepoHandle    func(evt *comatproto.SyncSubscribeRepos_Handle) error\n-\tIdentity      func(evt *comatproto.SyncSubscribeRepos_Identity) error\n+\tRepoIdentity  func(evt *comatproto.SyncSubscribeRepos_Identity) error\n \tRepoInfo      func(evt *comatproto.SyncSubscribeRepos_Info) error\n \tRepoMigrate   func(evt *comatproto.SyncSubscribeRepos_Migrate) error\n \tRepoTombstone func(evt *comatproto.SyncSubscribeRepos_Tombstone) error\n@@ -36,8 +36,8 @@ func (rsc *RepoStreamCallbacks) EventHandler(ctx context.Context, xev *XRPCStrea\n \t\treturn rsc.RepoInfo(xev.RepoInfo)\n \tcase xev.RepoMigrate != nil && rsc.RepoMigrate != nil:\n \t\treturn rsc.RepoMigrate(xev.RepoMigrate)\n-\tcase xev.RepoIdentity != nil && rsc.Identity != nil:\n-\t\treturn rsc.Identity(xev.RepoIdentity)\n+\tcase xev.RepoIdentity != nil && rsc.RepoIdentity != nil:\n+\t\treturn rsc.RepoIdentity(xev.RepoIdentity)\n \tcase xev.RepoTombstone != nil && rsc.RepoTombstone != nil:\n \t\treturn rsc.RepoTombstone(xev.RepoTombstone)\n \tcase xev.LabelLabels != nil && rsc.LabelLabels != nil:\n---\n"}], "ideal": "Title: process identity events from the pds slurper\n\nBody: These weren't getting routed through"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/helpers.go\n@@ -197,3 +197,46 @@ func HashOfString(s string) string {\n \tval := murmur3.Sum64([]byte(s))\n \treturn fmt.Sprintf(\"%016x\", val)\n }\n+\n+func ParentOrRootIsFollower(c *automod.RecordContext, post *appbsky.FeedPost) bool {\n+\tif post.Reply == nil || IsSelfThread(c, post) {\n+\t\treturn false\n+\t}\n+\n+\tparentURI, err := syntax.ParseATURI(post.Reply.Parent.Uri)\n+\tif err != nil {\n+\t\tc.Logger.Warn(\"failed to parse reply AT-URI\", \"uri\", post.Reply.Parent.Uri)\n+\t\treturn false\n+\t}\n+\tparentDID, err := parentURI.Authority().AsDID()\n+\tif err != nil {\n+\t\tc.Logger.Warn(\"reply AT-URI authority not a DID\", \"uri\", post.Reply.Parent.Uri)\n+\t\treturn false\n+\t}\n+\n+\trel := c.GetAccountRelationship(parentDID)\n+\tif rel.FollowedBy {\n+\t\treturn true\n+\t}\n+\n+\trootURI, err := syntax.ParseATURI(post.Reply.Root.Uri)\n+\tif err != nil {\n+\t\tc.Logger.Warn(\"failed to parse reply AT-URI\", \"uri\", post.Reply.Root.Uri)\n+\t\treturn false\n+\t}\n+\trootDID, err := rootURI.Authority().AsDID()\n+\tif err != nil {\n+\t\tc.Logger.Warn(\"reply AT-URI authority not a DID\", \"uri\", post.Reply.Root.Uri)\n+\t\treturn false\n+\t}\n+\n+\tif rootDID == parentDID {\n+\t\treturn false\n+\t}\n+\n+\trel = c.GetAccountRelationship(rootDID)\n+\tif rel.FollowedBy {\n+\t\treturn true\n+\t}\n+\treturn false\n+}\n---\nautomod/rules/interaction.go\n@@ -13,6 +13,7 @@ var _ automod.RecordRuleFunc = InteractionChurnRule\n \n // looks for accounts which do frequent interaction churn, such as follow-unfollow.\n func InteractionChurnRule(c *automod.RecordContext) error {\n+\n \tdid := c.Account.Identity.DID.String()\n \tswitch c.RecordOp.Collection {\n \tcase \"app.bsky.feed.like\":\n@@ -37,6 +38,14 @@ func InteractionChurnRule(c *automod.RecordContext) error {\n \t\t\tc.ReportAccount(automod.ReportReasonSpam, fmt.Sprintf(\"interaction churn: %d follows, %d unfollows today (so far)\", created, deleted))\n \t\t\tc.Notify(\"slack\")\n \t\t}\n+\t\t// just generic bulk following\n+\t\tfollowRatio := float64(c.Account.FollowersCount) / float64(c.Account.FollowsCount)\n+\t\tif created > interactionDailyThreshold && c.Account.FollowsCount > 2000 && followRatio < 0.1 {\n+\t\t\tc.Logger.Info(\"bulk-follower\", \"created-today\", created)\n+\t\t\tc.AddAccountFlag(\"bulk-follower\")\n+\t\t\t//c.ReportAccount(automod.ReportReasonSpam, fmt.Sprintf(\"many follows: %d follows today (so far)\", created))\n+\t\t\tc.Notify(\"slack\")\n+\t\t}\n \t}\n \treturn nil\n }\n---\nautomod/rules/mentions.go\n@@ -1,6 +1,7 @@\n package rules\n \n import (\n+\t\"fmt\"\n \t\"time\"\n \n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n@@ -42,7 +43,7 @@ func DistinctMentionsRule(c *automod.RecordContext, post *appbsky.FeedPost) erro\n \treturn nil\n }\n \n-var youngMentionAccountLimit = 6\n+var youngMentionAccountLimit = 12\n var _ automod.PostRuleFunc = YoungAccountDistinctMentionsRule\n \n func YoungAccountDistinctMentionsRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n@@ -90,7 +91,7 @@ func YoungAccountDistinctMentionsRule(c *automod.RecordContext, post *appbsky.Fe\n \tcount := c.GetCountDistinct(\"young-mention\", did, countstore.PeriodHour) + newMentions\n \tif count >= youngMentionAccountLimit {\n \t\tc.AddAccountFlag(\"young-distinct-account-mention\")\n-\t\t//c.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible spam (young account, mentioned %d distinct accounts in past hour)\", count))\n+\t\tc.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible spam (young account, mentioned %d distinct accounts in past hour)\", count))\n \t\tc.Notify(\"slack\")\n \t}\n \n---\nautomod/rules/promo.go\n@@ -4,6 +4,7 @@ import (\n \t\"net/url\"\n \t\"strings\"\n \t\"time\"\n+\t\"fmt\"\n \n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"github.com/bluesky-social/indigo/automod\"\n@@ -55,8 +56,9 @@ func AggressivePromotionRule(c *automod.RecordContext, post *appbsky.FeedPost) e\n \n \tdid := c.Account.Identity.DID.String()\n \tuniqueReplies := c.GetCountDistinct(\"reply-to\", did, countstore.PeriodDay)\n-\tif uniqueReplies >= 5 {\n+\tif uniqueReplies >= 10 {\n \t\tc.AddAccountFlag(\"promo-multi-reply\")\n+\t\tc.ReportAccount(automod.ReportReasonSpam, fmt.Sprintf(\"possible aggressive self-promotion\"))\n \t\tc.Notify(\"slack\")\n \t}\n \n---\nautomod/rules/replies.go\n@@ -3,6 +3,7 @@ package rules\n import (\n \t\"time\"\n \t\"unicode/utf8\"\n+\t\"fmt\"\n \n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n@@ -34,8 +35,8 @@ func ReplyCountPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error\n \treturn nil\n }\n \n-// triggers on the N+1 post, so 6th identical reply\n-var identicalReplyLimit = 5\n+// triggers on the N+1 post\n+var identicalReplyLimit = 6\n \n var _ automod.PostRuleFunc = IdenticalReplyPostRule\n \n@@ -58,6 +59,11 @@ func IdenticalReplyPostRule(c *automod.RecordContext, post *appbsky.FeedPost) er\n \t\t}\n \t}\n \n+\t// don't count if there is a follow-back relationship\n+\tif ParentOrRootIsFollower(c, post) {\n+\t\treturn nil\n+\t}\n+\n \t// increment before read. use a specific period (IncrementPeriod()) to reduce the number of counters (one per unique post text)\n \tperiod := countstore.PeriodDay\n \tbucket := c.Account.Identity.DID.String() + \"/\" + HashOfString(post.Text)\n@@ -66,7 +72,7 @@ func IdenticalReplyPostRule(c *automod.RecordContext, post *appbsky.FeedPost) er\n \tcount := c.GetCount(\"reply-text\", bucket, period)\n \tif count >= identicalReplyLimit {\n \t\tc.AddAccountFlag(\"multi-identical-reply\")\n-\t\t//c.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible spam (young account, %d identical reply-posts today)\", tag))\n+\t\tc.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible spam (young account, %d identical reply-posts today)\", count))\n \t\tc.Notify(\"slack\")\n \t}\n \n@@ -93,31 +99,30 @@ func YoungAccountDistinctRepliesRule(c *automod.RecordContext, post *appbsky.Fee\n \t\t}\n \t}\n \n-\tdid := c.Account.Identity.DID.String()\n+\t// don't count if there is a follow-back relationship\n+\tif ParentOrRootIsFollower(c, post) {\n+\t\treturn nil\n+\t}\n \n \tparentURI, err := syntax.ParseATURI(post.Reply.Parent.Uri)\n \tif err != nil {\n \t\tc.Logger.Warn(\"failed to parse reply AT-URI\", \"uri\", post.Reply.Parent.Uri)\n \t\treturn nil\n \t}\n-\totherDID, err := parentURI.Authority().AsDID()\n+\tparentDID, err := parentURI.Authority().AsDID()\n \tif err != nil {\n \t\tc.Logger.Warn(\"reply AT-URI authority not a DID\", \"uri\", post.Reply.Parent.Uri)\n \t\treturn nil\n \t}\n \n-\t// don't count if there is a follow-back relationship\n-\trel := c.GetAccountRelationship(otherDID)\n-\tif rel.FollowedBy {\n-\t\treturn nil\n-\t}\n+\tdid := c.Account.Identity.DID.String()\n \n-\tc.IncrementDistinct(\"young-reply-to\", did, otherDID.String())\n+\tc.IncrementDistinct(\"young-reply-to\", did, parentDID.String())\n \t// NOTE: won't include the increment from this event\n \tcount := c.GetCountDistinct(\"young-reply-to\", did, countstore.PeriodHour)\n \tif count >= youngReplyAccountLimit {\n \t\tc.AddAccountFlag(\"young-distinct-account-reply\")\n-\t\t//c.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible spam (young account, reply-posts to %d distinct accounts in past hour)\", count))\n+\t\tc.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible spam (young account, reply-posts to %d distinct accounts in past hour)\", count))\n \t\tc.Notify(\"slack\")\n \t}\n \n---\n"}], "ideal": "Title: automod interaction rule tweaks (anti-spam)\n\nBody: still very human-in-the-loop"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/hepa/consumer.go\n@@ -13,6 +13,7 @@ import (\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \t\"github.com/bluesky-social/indigo/automod\"\n \t\"github.com/bluesky-social/indigo/events/schedulers/autoscaling\"\n+\t\"github.com/bluesky-social/indigo/events/schedulers/parallel\"\n \tlexutil \"github.com/bluesky-social/indigo/lex/util\"\n \n \t\"github.com/bluesky-social/indigo/events\"\n@@ -79,17 +80,27 @@ func (s *Server) RunConsumer(ctx context.Context) error {\n \t\t// TODO: other event callbacks as needed\n \t}\n \n-\t// start at higher parallelism (somewhat arbitrary)\n-\tscaleSettings := autoscaling.DefaultAutoscaleSettings()\n-\tscaleSettings.Concurrency = 6\n-\tscaleSettings.MaxConcurrency = 240\n-\treturn events.HandleRepoStream(\n-\t\tctx, con, autoscaling.NewScheduler(\n-\t\t\tscaleSettings,\n+\tvar scheduler events.Scheduler\n+\tif s.firehoseParallelism > 0 {\n+\t\t// use a fixed-parallelism scheduler if configured\n+\t\tscheduler = parallel.NewScheduler(\n+\t\t\ts.firehoseParallelism,\n+\t\t\t1000,\n \t\t\ts.bgshost,\n \t\t\trsc.EventHandler,\n-\t\t),\n-\t)\n+\t\t)\n+\t\ts.logger.Info(\"hepa scheduler configured\", \"scheduler\", \"parallel\", \"initial\", s.firehoseParallelism)\n+\t} else {\n+\t\t// otherwise use auto-scaling scheduler\n+\t\tscaleSettings := autoscaling.DefaultAutoscaleSettings()\n+\t\t// start at higher parallelism (somewhat arbitrary)\n+\t\tscaleSettings.Concurrency = 4\n+\t\tscaleSettings.MaxConcurrency = 200\n+\t\tscheduler = autoscaling.NewScheduler(scaleSettings, s.bgshost, rsc.EventHandler)\n+\t\ts.logger.Info(\"hepa scheduler configured\", \"scheduler\", \"autoscaling\", \"initial\", scaleSettings.Concurrency, \"max\", scaleSettings.MaxConcurrency)\n+\t}\n+\n+\treturn events.HandleRepoStream(ctx, con, scheduler)\n }\n \n // TODO: move this to a \"ParsePath\" helper in syntax package?\n---\ncmd/hepa/main.go\n@@ -127,6 +127,11 @@ func run(args []string) error {\n \t\t\tUsage:   \"HTTP header to bypass ratelimits\",\n \t\t\tEnvVars: []string{\"HEPA_RATELIMIT_BYPASS\", \"RATELIMIT_BYPASS\"},\n \t\t},\n+\t\t&cli.IntFlag{\n+\t\t\tName:    \"firehose-parallelism\",\n+\t\t\tUsage:   \"force a fixed number of parallel firehose workers. default (or 0) for auto-scaling; 200 works for a large instance\",\n+\t\t\tEnvVars: []string{\"HEPA_FIREHOSE_PARALLELISM\"},\n+\t\t},\n \t}\n \n \tapp.Commands = []*cli.Command{\n@@ -214,21 +219,22 @@ var runCmd = &cli.Command{\n \t\tsrv, err := NewServer(\n \t\t\tdir,\n \t\t\tConfig{\n-\t\t\t\tBGSHost:         cctx.String(\"atp-bgs-host\"),\n-\t\t\t\tBskyHost:        cctx.String(\"atp-bsky-host\"),\n-\t\t\t\tLogger:          logger,\n-\t\t\t\tModHost:         cctx.String(\"atp-mod-host\"),\n-\t\t\t\tModAdminToken:   cctx.String(\"mod-admin-token\"),\n-\t\t\t\tModUsername:     cctx.String(\"mod-handle\"),\n-\t\t\t\tModPassword:     cctx.String(\"mod-password\"),\n-\t\t\t\tSetsFileJSON:    cctx.String(\"sets-json-path\"),\n-\t\t\t\tRedisURL:        cctx.String(\"redis-url\"),\n-\t\t\t\tSlackWebhookURL: cctx.String(\"slack-webhook-url\"),\n-\t\t\t\tHiveAPIToken:    cctx.String(\"hiveai-api-token\"),\n-\t\t\t\tAbyssHost:       cctx.String(\"abyss-host\"),\n-\t\t\t\tAbyssPassword:   cctx.String(\"abyss-password\"),\n-\t\t\t\tRatelimitBypass: cctx.String(\"ratelimit-bypass\"),\n-\t\t\t\tRulesetName:     cctx.String(\"ruleset\"),\n+\t\t\t\tBGSHost:             cctx.String(\"atp-bgs-host\"),\n+\t\t\t\tBskyHost:            cctx.String(\"atp-bsky-host\"),\n+\t\t\t\tLogger:              logger,\n+\t\t\t\tModHost:             cctx.String(\"atp-mod-host\"),\n+\t\t\t\tModAdminToken:       cctx.String(\"mod-admin-token\"),\n+\t\t\t\tModUsername:         cctx.String(\"mod-handle\"),\n+\t\t\t\tModPassword:         cctx.String(\"mod-password\"),\n+\t\t\t\tSetsFileJSON:        cctx.String(\"sets-json-path\"),\n+\t\t\t\tRedisURL:            cctx.String(\"redis-url\"),\n+\t\t\t\tSlackWebhookURL:     cctx.String(\"slack-webhook-url\"),\n+\t\t\t\tHiveAPIToken:        cctx.String(\"hiveai-api-token\"),\n+\t\t\t\tAbyssHost:           cctx.String(\"abyss-host\"),\n+\t\t\t\tAbyssPassword:       cctx.String(\"abyss-password\"),\n+\t\t\t\tRatelimitBypass:     cctx.String(\"ratelimit-bypass\"),\n+\t\t\t\tRulesetName:         cctx.String(\"ruleset\"),\n+\t\t\t\tFirehoseParallelism: cctx.Int(\"firehose-parallelism\"),\n \t\t\t},\n \t\t)\n \t\tif err != nil {\n@@ -280,20 +286,21 @@ func configEphemeralServer(cctx *cli.Context) (*Server, error) {\n \treturn NewServer(\n \t\tdir,\n \t\tConfig{\n-\t\t\tBGSHost:         cctx.String(\"atp-bgs-host\"),\n-\t\t\tBskyHost:        cctx.String(\"atp-bsky-host\"),\n-\t\t\tLogger:          logger,\n-\t\t\tModHost:         cctx.String(\"atp-mod-host\"),\n-\t\t\tModAdminToken:   cctx.String(\"mod-admin-token\"),\n-\t\t\tModUsername:     cctx.String(\"mod-handle\"),\n-\t\t\tModPassword:     cctx.String(\"mod-password\"),\n-\t\t\tSetsFileJSON:    cctx.String(\"sets-json-path\"),\n-\t\t\tRedisURL:        cctx.String(\"redis-url\"),\n-\t\t\tHiveAPIToken:    cctx.String(\"hiveai-api-token\"),\n-\t\t\tAbyssHost:       cctx.String(\"abyss-host\"),\n-\t\t\tAbyssPassword:   cctx.String(\"abyss-password\"),\n-\t\t\tRatelimitBypass: cctx.String(\"ratelimit-bypass\"),\n-\t\t\tRulesetName:     cctx.String(\"ruleset\"),\n+\t\t\tBGSHost:             cctx.String(\"atp-bgs-host\"),\n+\t\t\tBskyHost:            cctx.String(\"atp-bsky-host\"),\n+\t\t\tLogger:              logger,\n+\t\t\tModHost:             cctx.String(\"atp-mod-host\"),\n+\t\t\tModAdminToken:       cctx.String(\"mod-admin-token\"),\n+\t\t\tModUsername:         cctx.String(\"mod-handle\"),\n+\t\t\tModPassword:         cctx.String(\"mod-password\"),\n+\t\t\tSetsFileJSON:        cctx.String(\"sets-json-path\"),\n+\t\t\tRedisURL:            cctx.String(\"redis-url\"),\n+\t\t\tHiveAPIToken:        cctx.String(\"hiveai-api-token\"),\n+\t\t\tAbyssHost:           cctx.String(\"abyss-host\"),\n+\t\t\tAbyssPassword:       cctx.String(\"abyss-password\"),\n+\t\t\tRatelimitBypass:     cctx.String(\"ratelimit-bypass\"),\n+\t\t\tRulesetName:         cctx.String(\"ruleset\"),\n+\t\t\tFirehoseParallelism: cctx.Int(\"firehose-parallelism\"),\n \t\t},\n \t)\n }\n---\ncmd/hepa/server.go\n@@ -27,10 +27,11 @@ import (\n )\n \n type Server struct {\n-\tbgshost string\n-\tlogger  *slog.Logger\n-\tengine  *automod.Engine\n-\trdb     *redis.Client\n+\tbgshost             string\n+\tfirehoseParallelism int\n+\tlogger              *slog.Logger\n+\tengine              *automod.Engine\n+\trdb                 *redis.Client\n \n \t// lastSeq is the most recent event sequence number we've received and begun to handle.\n \t// This number is periodically persisted to redis, if redis is present.\n@@ -40,21 +41,22 @@ type Server struct {\n }\n \n type Config struct {\n-\tBGSHost         string\n-\tBskyHost        string\n-\tModHost         string\n-\tModAdminToken   string\n-\tModUsername     string\n-\tModPassword     string\n-\tSetsFileJSON    string\n-\tRedisURL        string\n-\tSlackWebhookURL string\n-\tHiveAPIToken    string\n-\tAbyssHost       string\n-\tAbyssPassword   string\n-\tRulesetName     string\n-\tRatelimitBypass string\n-\tLogger          *slog.Logger\n+\tBGSHost             string\n+\tBskyHost            string\n+\tModHost             string\n+\tModAdminToken       string\n+\tModUsername         string\n+\tModPassword         string\n+\tSetsFileJSON        string\n+\tRedisURL            string\n+\tSlackWebhookURL     string\n+\tHiveAPIToken        string\n+\tAbyssHost           string\n+\tAbyssPassword       string\n+\tRulesetName         string\n+\tRatelimitBypass     string\n+\tFirehoseParallelism int\n+\tLogger              *slog.Logger\n }\n \n func NewServer(dir identity.Directory, config Config) (*Server, error) {\n@@ -204,10 +206,11 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t}\n \n \ts := &Server{\n-\t\tbgshost: config.BGSHost,\n-\t\tlogger:  logger,\n-\t\tengine:  &engine,\n-\t\trdb:     rdb,\n+\t\tbgshost:             config.BGSHost,\n+\t\tfirehoseParallelism: config.FirehoseParallelism,\n+\t\tlogger:              logger,\n+\t\tengine:              &engine,\n+\t\trdb:                 rdb,\n \t}\n \n \treturn s, nil\n---\n"}], "ideal": "Title: hepa configurable parallelism\n\nBody: both the value, and whether to auto-scale"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/all.go\n@@ -40,6 +40,7 @@ func DefaultRules() automod.RuleSet {\n \t\t\tNewAccountRule,\n \t\t\tBadWordHandleRule,\n \t\t\tBadWordDIDRule,\n+\t\t\tBanEvasionHandleRule,\n \t\t},\n \t\tBlobRules: []automod.BlobRuleFunc{\n \t\t\t//BlobVerifyRule,\n---\nautomod/rules/banevasion.go\n@@ -0,0 +1,43 @@\n+package rules\n+\n+import (\n+\t\"fmt\"\n+\t\"strings\"\n+\n+\t\"github.com/bluesky-social/indigo/automod\"\n+)\n+\n+// example rule showing how to detect a pattern in handles\n+func BanEvasionHandleRule(c *automod.AccountContext) error {\n+\n+\t// TODO: move these to config\n+\tpatterns := []string{\n+\t\t\"rapeskids\",\n+\t\t\"isapedo\",\n+\t\t\"thegroomer\",\n+\t\t\"isarapist\",\n+\t}\n+\n+\thandle := c.Account.Identity.Handle.Normalize().String()\n+\temail := \"\"\n+\tif c.Account.Private != nil {\n+\t\temail = strings.ToLower(c.Account.Private.Email)\n+\t}\n+\tfor _, w := range patterns {\n+\t\tif strings.Contains(handle, w) {\n+\t\t\tc.AddAccountFlag(\"evasion-pattern-handle\")\n+\t\t\tc.ReportAccount(automod.ReportReasonViolation, fmt.Sprintf(\"possible ban evasion pattern (username): %s\", w))\n+\t\t\tc.Notify(\"slack\")\n+\t\t\tbreak\n+\t\t}\n+\t\tif email != \"\" && strings.Contains(email, w) {\n+\t\t\tc.AddAccountFlag(\"evasion-pattern-email\")\n+\t\t\tc.ReportAccount(automod.ReportReasonViolation, fmt.Sprintf(\"possible ban evasion pattern (email): %s\", w))\n+\t\t\tc.Notify(\"slack\")\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\treturn nil\n+}\n+\n+var _ automod.IdentityRuleFunc = BanEvasionHandleRule\n---\n"}], "ideal": "Title: example ban evasion rule\n\nBody: This isn't really going to work until we get identities on the event stream. And should get the strings in some config API, not hardcoded."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/parse_query.go\n@@ -8,20 +8,23 @@ import (\n \n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n-\n-\t\"github.com/google/shlex\"\n )\n \n // ParseQuery takes a query string and pulls out some facet patterns (\"from:handle.net\") as filters\n func ParseQuery(ctx context.Context, dir identity.Directory, raw string) (string, []map[string]interface{}) {\n \tvar filters []map[string]interface{}\n-\tparts, err := shlex.Split(raw)\n-\tif err != nil {\n-\t\t// pass-through if failed to parse\n-\t\treturn raw, filters\n-\t}\n+\tquoted := false\n+\tparts := strings.FieldsFunc(raw, func(r rune) bool {\n+\t\tif r == '\"' {\n+\t\t\tquoted = !quoted\n+\t\t}\n+\t\treturn r == ' ' && !quoted\n+\t})\n+\n \tkeep := make([]string, len(parts))\n \tfor _, p := range parts {\n+\t\tp = strings.Trim(p, \"\\\"\")\n+\n \t\tif !strings.ContainsRune(p, ':') || strings.ContainsRune(p, ' ') {\n \t\t\t// simple: quoted (whitespace), or just a token\n \t\t\tkeep = append(keep, p)\n---\n"}], "ideal": "Title: Parse queries better for search\n\nBody: Addresses https://github.com/bluesky-social/indigo/issues/578"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/cache_directory.go\n@@ -16,6 +16,7 @@ import (\n type CacheDirectory struct {\n \tInner             Directory\n \tErrTTL            time.Duration\n+\tInvalidHandleTTL  time.Duration\n \thandleCache       *expirable.LRU[syntax.Handle, HandleEntry]\n \tidentityCache     *expirable.LRU[syntax.DID, IdentityEntry]\n \tdidLookupChans    sync.Map\n@@ -67,12 +68,13 @@ var handleRequestsCoalesced = promauto.NewCounter(prometheus.CounterOpts{\n var _ Directory = (*CacheDirectory)(nil)\n \n // Capacity of zero means unlimited size. Similarly, ttl of zero means unlimited duration.\n-func NewCacheDirectory(inner Directory, capacity int, hitTTL, errTTL time.Duration) CacheDirectory {\n+func NewCacheDirectory(inner Directory, capacity int, hitTTL, errTTL time.Duration, invalidHandleTTL time.Duration) CacheDirectory {\n \treturn CacheDirectory{\n-\t\tErrTTL:        errTTL,\n-\t\tInner:         inner,\n-\t\thandleCache:   expirable.NewLRU[syntax.Handle, HandleEntry](capacity, nil, hitTTL),\n-\t\tidentityCache: expirable.NewLRU[syntax.DID, IdentityEntry](capacity, nil, hitTTL),\n+\t\tErrTTL:           errTTL,\n+\t\tInvalidHandleTTL: invalidHandleTTL,\n+\t\tInner:            inner,\n+\t\thandleCache:      expirable.NewLRU[syntax.Handle, HandleEntry](capacity, nil, hitTTL),\n+\t\tidentityCache:    expirable.NewLRU[syntax.DID, IdentityEntry](capacity, nil, hitTTL),\n \t}\n }\n \n@@ -87,6 +89,9 @@ func (d *CacheDirectory) IsIdentityStale(e *IdentityEntry) bool {\n \tif e.Err != nil && time.Since(e.Updated) > d.ErrTTL {\n \t\treturn true\n \t}\n+\tif e.Identity != nil && e.Identity.Handle.IsInvalidHandle() && time.Since(e.Updated) > d.InvalidHandleTTL {\n+\t\treturn true\n+\t}\n \treturn false\n }\n \n---\natproto/identity/identity.go\n@@ -76,7 +76,7 @@ func DefaultDirectory() Directory {\n \t\t// primary Bluesky PDS instance only supports HTTP resolution method\n \t\tSkipDNSDomainSuffixes: []string{\".bsky.social\"},\n \t}\n-\tcached := NewCacheDirectory(&base, 10000, time.Hour*24, time.Minute*2)\n+\tcached := NewCacheDirectory(&base, 250_000, time.Hour*24, time.Minute*2, time.Minute*5)\n \treturn &cached\n }\n \n---\natproto/identity/live_test.go\n@@ -64,7 +64,7 @@ func TestBaseDirectory(t *testing.T) {\n func TestCacheDirectory(t *testing.T) {\n \tt.Skip(\"TODO: skipping live network test\")\n \tinner := BaseDirectory{}\n-\td := NewCacheDirectory(&inner, 1000, time.Hour*1, time.Hour*1)\n+\td := NewCacheDirectory(&inner, 1000, time.Hour*1, time.Hour*1, time.Hour*1)\n \tfor i := 0; i < 3; i = i + 1 {\n \t\ttestDirectoryLive(t, &d)\n \t}\n@@ -87,7 +87,7 @@ func TestCacheCoalesce(t *testing.T) {\n \t\tTryAuthoritativeDNS:   true,\n \t\tSkipDNSDomainSuffixes: []string{\".bsky.social\"},\n \t}\n-\tdir := NewCacheDirectory(&base, 1000, time.Hour*1, time.Hour*1)\n+\tdir := NewCacheDirectory(&base, 1000, time.Hour*1, time.Hour*1, time.Hour*1)\n \t// All 60 routines launch at the same time, so they should all miss the cache initially\n \troutines := 60\n \twg := sync.WaitGroup{}\n---\ncmd/hepa/main.go\n@@ -157,7 +157,7 @@ func configDirectory(cctx *cli.Context) (identity.Directory, error) {\n \t\t}\n \t\tdir = rdir\n \t} else {\n-\t\tcdir := identity.NewCacheDirectory(&baseDir, 1_500_000, time.Hour*24, time.Minute*2)\n+\t\tcdir := identity.NewCacheDirectory(&baseDir, 1_500_000, time.Hour*24, time.Minute*2, time.Minute*5)\n \t\tdir = &cdir\n \t}\n \treturn dir, nil\n---\ncmd/palomar/main.go\n@@ -220,7 +220,7 @@ var runCmd = &cli.Command{\n \t\t\tTryAuthoritativeDNS:   true,\n \t\t\tSkipDNSDomainSuffixes: []string{\".bsky.social\"},\n \t\t}\n-\t\tdir := identity.NewCacheDirectory(&base, 1_500_000, time.Hour*24, time.Minute*2)\n+\t\tdir := identity.NewCacheDirectory(&base, 1_500_000, time.Hour*24, time.Minute*2, time.Minute*5)\n \n \t\tsrv, err := search.NewServer(\n \t\t\tdb,\n---\n"}], "ideal": "Title: Add a separate TTL for negative handle caching so we don't keep inval\u2026\n\nBody: \u2026id handles for hours"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "README.md\n@@ -53,12 +53,12 @@ The [HACKING](./HACKING.md) file has a list of commands and packages in this rep\n \n *not to be confused with the [AT command set](https://en.wikipedia.org/wiki/Hayes_command_set) or [Adenosine triphosphate](https://en.wikipedia.org/wiki/Adenosine_triphosphate)*\n \n-The Authenticated Transfer Protocol (\"ATP\" or \"atproto\") is a decentralized social media protocol, developed by [Bluesky PBC](https://blueskyweb.xyz). Learn more at:\n+The Authenticated Transfer Protocol (\"ATP\" or \"atproto\") is a decentralized social media protocol, developed by [Bluesky PBC](https://bsky.social). Learn more at:\n \n - [Overview and Guides](https://atproto.com/guides/overview) \ud83d\udc48 Best starting point\n - [Github Discussions](https://github.com/bluesky-social/atproto/discussions) \ud83d\udc48 Great place to ask questions\n - [Protocol Specifications](https://atproto.com/specs/atp)\n-- [Blogpost on self-authenticating data structures](https://blueskyweb.xyz/blog/3-6-2022-a-self-authenticating-social-protocol)\n+- [Blogpost on self-authenticating data structures](https://bsky.social/about/blog/3-6-2022-a-self-authenticating-social-protocol)\n \n The Bluesky Social application encompasses a set of schemas and APIs built in the overall AT Protocol framework. The namespace for these \"Lexicons\" is `app.bsky.*`.\n \n---\n"}], "ideal": "Title: Update `blueskyweb.xyz` links in README.md to `bsky.social`\n\nBody: This PR updates the two links in README.md that point to `blueskyweb.xyz` to the equivalent `bsky.social` URLs.\r\n\r\nAlso, I noticed that Line 13 still refers to 'Big Graph Service', should this be updated to 'Relay'?\r\n\r\nhttps://github.com/bluesky-social/indigo/blob/c72ce2340db3cc99fc886c2284daf19e438c7b91/README.md?plain=1#L13"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/did.go\n@@ -65,7 +65,6 @@ func (d *BaseDirectory) ResolveDIDWeb(ctx context.Context, did syntax.DID) (*DID\n \t\treturn nil, fmt.Errorf(\"did:web hostname has disallowed TLD: %s\", hostname)\n \t}\n \n-\t// TODO: use a more robust client\n \t// TODO: allow ctx to specify unsafe http:// resolution, for testing?\n \n \tif d.DIDWebLimitFunc != nil {\n@@ -74,7 +73,12 @@ func (d *BaseDirectory) ResolveDIDWeb(ctx context.Context, did syntax.DID) (*DID\n \t\t}\n \t}\n \n-\tresp, err := http.Get(\"https://\" + hostname + \"/.well-known/did.json\")\n+\treq, err := http.NewRequestWithContext(ctx, \"GET\", \"https://\"+hostname+\"/.well-known/did.json\", nil)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"constructing HTTP request for did:web resolution: %w\", err)\n+\t}\n+\tresp, err := d.HTTPClient.Do(req)\n+\n \t// look for NXDOMAIN\n \tvar dnsErr *net.DNSError\n \tif errors.As(err, &dnsErr) {\n@@ -85,6 +89,7 @@ func (d *BaseDirectory) ResolveDIDWeb(ctx context.Context, did syntax.DID) (*DID\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"%w: did:web HTTP well-known fetch: %w\", ErrDIDResolutionFailed, err)\n \t}\n+\tdefer resp.Body.Close()\n \tif resp.StatusCode == http.StatusNotFound {\n \t\treturn nil, fmt.Errorf(\"%w: did:web HTTP status 404\", ErrDIDNotFound)\n \t}\n@@ -115,10 +120,15 @@ func (d *BaseDirectory) ResolveDIDPLC(ctx context.Context, did syntax.DID) (*DID\n \t\t}\n \t}\n \n-\tresp, err := http.Get(plcURL + \"/\" + did.String())\n+\treq, err := http.NewRequestWithContext(ctx, \"GET\", plcURL+\"/\"+did.String(), nil)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"constructing HTTP request for did:plc resolution: %w\", err)\n+\t}\n+\tresp, err := d.HTTPClient.Do(req)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"%w: PLC directory lookup: %w\", ErrDIDResolutionFailed, err)\n \t}\n+\tdefer resp.Body.Close()\n \tif resp.StatusCode == http.StatusNotFound {\n \t\treturn nil, fmt.Errorf(\"%w: PLC directory 404\", ErrDIDNotFound)\n \t}\n---\natproto/identity/handle.go\n@@ -143,6 +143,7 @@ func (d *BaseDirectory) ResolveHandleWellKnown(ctx context.Context, handle synta\n \t\t}\n \t\treturn \"\", fmt.Errorf(\"%w: HTTP well-known request error: %w\", ErrHandleResolutionFailed, err)\n \t}\n+\tdefer resp.Body.Close()\n \tif resp.StatusCode == http.StatusNotFound {\n \t\treturn \"\", fmt.Errorf(\"%w: HTTP 404 for %s\", ErrHandleNotFound, handle)\n \t}\n---\n"}], "ideal": "Title: identity: use shared http.Client for lookups, and close resp bodies\n\nBody: I think these were embarrassing oversights?\r\n\r\nFor PLC in particular, want to keep HTTP/2 connections open for reuse. Less of a thing for the well-known lookups, though for the common case of `*.bsky.social` lookups, there are lots of hostnames, but all the same backing server, so hopefully still works.\r\n\r\n`did:web` we might actually want a separate connection every time."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/hepa/main.go\n@@ -7,7 +7,9 @@ import (\n \t\"io\"\n \t\"log/slog\"\n \t\"net/http\"\n+\t_ \"net/http/pprof\"\n \t\"os\"\n+\t\"runtime\"\n \t\"strings\"\n \t\"time\"\n \n@@ -235,6 +237,8 @@ var runCmd = &cli.Command{\n \n \t\t// prometheus HTTP endpoint: /metrics\n \t\tgo func() {\n+\t\t\truntime.SetBlockProfileRate(10)\n+\t\t\truntime.SetMutexProfileFraction(10)\n \t\t\tif err := srv.RunMetrics(cctx.String(\"metrics-listen\")); err != nil {\n \t\t\t\tslog.Error(\"failed to start metrics endpoint\", \"error\", err)\n \t\t\t\tpanic(fmt.Errorf(\"failed to start metrics endpoint: %w\", err))\n---\n"}], "ideal": "Title: hepa: add pprof endpoint, and enable block profiling.\n\nBody: Hepa already has an http service for prometh metrics, and it's the http package's default one, so this continues to just dogpile on that.\r\n\r\nWith the defaults, http://localhost:3989/debug/pprof/ is now informative.\r\n\r\nAlso added nudges to the runtime to enable block profiling and mutex profiling.  Without these nudges, those reports are empty.\r\n\r\nI picked the rate numbers here somewhat capriciously; they may need tuning to keep impact down in prod, or we may end up needing knobs for toggling this at runtime.  We'll see.\r\n\r\n(The goroutine profiles alone, requested periodically, provide a decent sampling of data that can be used to infer some things about blocking anyway, even if that pprof feature isn't enabled explicitly!  But more data is almost always better, so I propose turning it on for now.)"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/hepa/consumer.go\n@@ -7,6 +7,7 @@ import (\n \t\"net/http\"\n \t\"net/url\"\n \t\"strings\"\n+\t\"sync/atomic\"\n \n \tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n@@ -48,11 +49,11 @@ func (s *Server) RunConsumer(ctx context.Context) error {\n \n \trsc := &events.RepoStreamCallbacks{\n \t\tRepoCommit: func(evt *comatproto.SyncSubscribeRepos_Commit) error {\n-\t\t\ts.lastSeq = evt.Seq\n+\t\t\tatomic.StoreInt64(&s.lastSeq, evt.Seq)\n \t\t\treturn s.HandleRepoCommit(ctx, evt)\n \t\t},\n \t\tRepoHandle: func(evt *comatproto.SyncSubscribeRepos_Handle) error {\n-\t\t\ts.lastSeq = evt.Seq\n+\t\t\tatomic.StoreInt64(&s.lastSeq, evt.Seq)\n \t\t\tdid, err := syntax.ParseDID(evt.Did)\n \t\t\tif err != nil {\n \t\t\t\ts.logger.Error(\"bad DID in RepoHandle event\", \"did\", evt.Did, \"handle\", evt.Handle, \"seq\", evt.Seq, \"err\", err)\n@@ -64,7 +65,7 @@ func (s *Server) RunConsumer(ctx context.Context) error {\n \t\t\treturn nil\n \t\t},\n \t\tRepoMigrate: func(evt *comatproto.SyncSubscribeRepos_Migrate) error {\n-\t\t\ts.lastSeq = evt.Seq\n+\t\t\tatomic.StoreInt64(&s.lastSeq, evt.Seq)\n \t\t\tdid, err := syntax.ParseDID(evt.Did)\n \t\t\tif err != nil {\n \t\t\t\ts.logger.Error(\"bad DID in RepoMigrate event\", \"did\", evt.Did, \"seq\", evt.Seq, \"err\", err)\n---\ncmd/hepa/server.go\n@@ -7,6 +7,7 @@ import (\n \t\"net/http\"\n \t\"os\"\n \t\"strings\"\n+\t\"sync/atomic\"\n \t\"time\"\n \n \tcomatproto \"github.com/bluesky-social/indigo/api/atproto\"\n@@ -30,6 +31,11 @@ type Server struct {\n \tlogger  *slog.Logger\n \tengine  *automod.Engine\n \trdb     *redis.Client\n+\n+\t// lastSeq is the most recent event sequence number we've received and begun to handle.\n+\t// This number is periodically persisted to redis, if redis is present.\n+\t// The value is best-effort (the stream handling itself is concurrent, so event numbers may not be monotonic),\n+\t// but nonetheless, you must use atomics when updating or reading this (to avoid data races).\n \tlastSeq int64\n }\n \n@@ -222,10 +228,11 @@ func (s *Server) PersistCursor(ctx context.Context) error {\n \tif s.rdb == nil {\n \t\treturn nil\n \t}\n-\tif s.lastSeq <= 0 {\n+\tlastSeq := atomic.LoadInt64(&s.lastSeq)\n+\tif lastSeq <= 0 {\n \t\treturn nil\n \t}\n-\terr := s.rdb.Set(ctx, cursorKey, s.lastSeq, 14*24*time.Hour).Err()\n+\terr := s.rdb.Set(ctx, cursorKey, lastSeq, 14*24*time.Hour).Err()\n \treturn err\n }\n \n@@ -278,19 +285,21 @@ func (s *Server) RunPersistCursor(ctx context.Context) error {\n \tfor {\n \t\tselect {\n \t\tcase <-ctx.Done():\n-\t\t\tif s.lastSeq >= 1 {\n-\t\t\t\ts.logger.Info(\"persisting final cursor seq value\", \"seq\", s.lastSeq)\n+\t\t\tlastSeq := atomic.LoadInt64(&s.lastSeq)\n+\t\t\tif lastSeq >= 1 {\n+\t\t\t\ts.logger.Info(\"persisting final cursor seq value\", \"seq\", lastSeq)\n \t\t\t\terr := s.PersistCursor(ctx)\n \t\t\t\tif err != nil {\n-\t\t\t\t\ts.logger.Error(\"failed to persist cursor\", \"err\", err, \"seq\", s.lastSeq)\n+\t\t\t\t\ts.logger.Error(\"failed to persist cursor\", \"err\", err, \"seq\", lastSeq)\n \t\t\t\t}\n \t\t\t}\n \t\t\treturn nil\n \t\tcase <-ticker.C:\n-\t\t\tif s.lastSeq >= 1 {\n+\t\t\tlastSeq := atomic.LoadInt64(&s.lastSeq)\n+\t\t\tif lastSeq >= 1 {\n \t\t\t\terr := s.PersistCursor(ctx)\n \t\t\t\tif err != nil {\n-\t\t\t\t\ts.logger.Error(\"failed to persist cursor\", \"err\", err, \"seq\", s.lastSeq)\n+\t\t\t\t\ts.logger.Error(\"failed to persist cursor\", \"err\", err, \"seq\", lastSeq)\n \t\t\t\t}\n \t\t\t}\n \t\t}\n---\n"}], "ideal": "Title: hepa: use atomics for lastSeq.\n\nBody: Fixes data race.  Was probably harmless in practice, as these values are best-effort anyway, but keeping the race detector clean and happy when engaged is highly valuable for maintainability in the long run.\r\n\r\nSome comments attached about the field's concurrency."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "backfill/gormstore.go\n@@ -321,7 +321,7 @@ func (j *Gormjob) FlushBufferedOps(ctx context.Context, fn func(kind, rev, path\n \tdefer j.lk.Unlock()\n \n \tfor _, opset := range j.bufferedOps {\n-\t\tif opset.rev < j.rev {\n+\t\tif opset.rev <= j.rev {\n \t\t\t// stale events, skip\n \t\t\tcontinue\n \t\t}\n---\n"}], "ideal": "Title: Fixed backfill GormJob.FlushBufferedOps not skipping final stale event\n\nBody: The backfiller fails to flush operations when it doesn't identify an event as stale if its `rev` is equal to the last seen `rev`. This gets caught as a discontinuity, and it returns an error:\r\n```\r\n2024/02/05 18:25:18 ERROR failed to flush buffered ops source=backfiller_buffer_flush repo=[repo] error=\"event since did not match current rev (3kkpf3r7lx22m != 3kkpf53gjgs24): buffered event revs did not line up\"\r\n```\r\nwhich blocks the rest of the buffered events from being processed, and the job is eternally marked as enqueued."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/admin.go\n@@ -463,7 +463,17 @@ func (bgs *BGS) handleAdminCompactAllRepos(e echo.Context) error {\n \t\tlim = v\n \t}\n \n-\terr := bgs.compactor.EnqueueAllRepos(ctx, bgs, lim, 0, fast)\n+\tshardThresh := 20\n+\tif threshstr := e.QueryParam(\"threshold\"); threshstr != \"\" {\n+\t\tv, err := strconv.Atoi(threshstr)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\n+\t\tshardThresh = v\n+\t}\n+\n+\terr := bgs.compactor.EnqueueAllRepos(ctx, bgs, lim, shardThresh, fast)\n \tif err != nil {\n \t\treturn echo.NewHTTPError(http.StatusInternalServerError, fmt.Errorf(\"failed to enqueue all repos: %w\", err))\n \t}\n---\ncmd/gosky/bgs.go\n@@ -377,6 +377,9 @@ var bgsCompactAll = &cli.Command{\n \t\t&cli.IntFlag{\n \t\t\tName: \"limit\",\n \t\t},\n+\t\t&cli.IntFlag{\n+\t\t\tName: \"threshold\",\n+\t\t},\n \t\t&cli.BoolFlag{\n \t\t\tName: \"fast\",\n \t\t},\n@@ -399,6 +402,11 @@ var bgsCompactAll = &cli.Command{\n \t\tif cctx.IsSet(\"limit\") {\n \t\t\tq.Add(\"limit\", fmt.Sprint(cctx.Int(\"limit\")))\n \t\t}\n+\n+\t\tif cctx.IsSet(\"threshold\") {\n+\t\t\tq.Add(\"threshold\", fmt.Sprint(cctx.Int(\"threshold\")))\n+\t\t}\n+\n \t\tuu.RawQuery = q.Encode()\n \n \t\treq, err := http.NewRequest(\"POST\", uu.String(), nil)\n---\n"}], "ideal": "Title: make shard threshold parameter usable through admin api\n\nBody: currently this will always default to 20 when called (despite the comment saying 50), which is better for our purposes than the 50 that defaults in the background routine, but still should be something we can set"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/engine/effects.go\n@@ -9,9 +9,9 @@ var (\n \t// time period within which automod will not re-report an account for the same reasonType\n \tReportDupePeriod = 1 * 24 * time.Hour\n \t// number of reports automod can file per day, for all subjects and types combined (circuit breaker)\n-\tQuotaModReportDay = 50\n+\tQuotaModReportDay = 2000\n \t// number of takedowns automod can action per day, for all subjects combined (circuit breaker)\n-\tQuotaModTakedownDay = 10\n+\tQuotaModTakedownDay = 200\n )\n \n type CounterRef struct {\n@@ -115,7 +115,6 @@ func (e *Effects) ReportAccount(reason, comment string) {\n \tif comment == \"\" {\n \t\tcomment = \"(reporting without comment)\"\n \t}\n-\tcomment = \"[automod] \" + comment\n \tfor _, v := range e.AccountReports {\n \t\tif v.ReasonType == reason {\n \t\t\treturn\n---\nautomod/engine/engine.go\n@@ -16,7 +16,7 @@ import (\n )\n \n const (\n-\trecordEventTimeout       = 20 * time.Second\n+\trecordEventTimeout       = 30 * time.Second\n \tidentityEventTimeout     = 10 * time.Second\n \tnotificationEventTimeout = 5 * time.Second\n )\n---\nautomod/rules/hashtags.go\n@@ -1,6 +1,8 @@\n package rules\n \n import (\n+\t\"fmt\"\n+\n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"github.com/bluesky-social/indigo/automod\"\n \t\"github.com/bluesky-social/indigo/automod/keyword\"\n@@ -12,6 +14,7 @@ func BadHashtagsPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error\n \t\ttag = NormalizeHashtag(tag)\n \t\tif c.InSet(\"bad-hashtags\", tag) || c.InSet(\"bad-words\", tag) {\n \t\t\tc.AddRecordFlag(\"bad-hashtag\")\n+\t\t\tc.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"possible bad word in hashtags: %s\", tag))\n \t\t\tc.Notify(\"slack\")\n \t\t\tbreak\n \t\t}\n---\nautomod/rules/keyword.go\n@@ -16,15 +16,15 @@ func BadWordPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \t\tif word != \"\" && word != \"faggot\" && word != \"tranny\" {\n \t\t\tc.AddRecordFlag(\"bad-word-text\")\n \t\t\tc.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"possible bad word in post text or alttext: %s\", word))\n-\t\t\tc.Notify(\"slack\")\n+\t\t\t//c.Notify(\"slack\")\n \t\t\tbreak\n \t\t}\n \t\t// de-pluralize\n \t\ttok = strings.TrimSuffix(tok, \"s\")\n \t\tif c.InSet(\"worst-words\", tok) {\n \t\t\tc.AddRecordFlag(\"bad-word-text\")\n \t\t\tc.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"possible bad word in post text or alttext: %s\", tok))\n-\t\t\tc.Notify(\"slack\")\n+\t\t\t//c.Notify(\"slack\")\n \t\t\tbreak\n \t\t}\n \t}\n@@ -39,7 +39,7 @@ func BadWordProfileRule(c *automod.RecordContext, profile *appbsky.ActorProfile)\n \t\tif word != \"\" {\n \t\t\tc.AddRecordFlag(\"bad-word-name\")\n \t\t\tc.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"possible bad word in display name: %s\", word))\n-\t\t\tc.Notify(\"slack\")\n+\t\t\t//c.Notify(\"slack\")\n \t\t}\n \t}\n \tfor _, tok := range ExtractTextTokensProfile(profile) {\n@@ -48,7 +48,7 @@ func BadWordProfileRule(c *automod.RecordContext, profile *appbsky.ActorProfile)\n \t\tif c.InSet(\"worst-words\", tok) {\n \t\t\tc.AddRecordFlag(\"bad-word-text\")\n \t\t\tc.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"possible bad word in profile description: %s\", tok))\n-\t\t\tc.Notify(\"slack\")\n+\t\t\t//c.Notify(\"slack\")\n \t\t\tbreak\n \t\t}\n \t}\n@@ -68,7 +68,7 @@ func ReplySingleBadWordPostRule(c *automod.RecordContext, post *appbsky.FeedPost\n \t\tif c.InSet(\"bad-words\", tok) || keyword.SlugIsExplicitSlur(tok) != \"\" {\n \t\t\tc.AddRecordFlag(\"reply-single-bad-word\")\n \t\t\tc.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"bad single-word reply: %s\", tok))\n-\t\t\tc.Notify(\"slack\")\n+\t\t\t//c.Notify(\"slack\")\n \t\t}\n \t}\n \treturn nil\n@@ -175,7 +175,7 @@ func BadWordHandleRule(c *automod.AccountContext) error {\n \tif word != \"\" {\n \t\tc.AddAccountFlag(\"bad-word-handle\")\n \t\tc.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible bad word in handle (username): %s\", word))\n-\t\tc.Notify(\"slack\")\n+\t\t//c.Notify(\"slack\")\n \t\treturn nil\n \t}\n \n@@ -184,7 +184,7 @@ func BadWordHandleRule(c *automod.AccountContext) error {\n \t\tif c.InSet(\"bad-words\", tok) {\n \t\t\tc.AddAccountFlag(\"bad-word-handle\")\n \t\t\tc.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible bad word in handle (username): %s\", tok))\n-\t\t\tc.Notify(\"slack\")\n+\t\t\t//c.Notify(\"slack\")\n \t\t\tbreak\n \t\t}\n \t}\n---\nautomod/rules/replies.go\n@@ -47,11 +47,6 @@ func IdenticalReplyPostRule(c *automod.RecordContext, post *appbsky.FeedPost) er\n \t\treturn nil\n \t}\n \n-\t// increment first. use a specific period (IncrementPeriod()) to reduce the number of counters (one per unique post text)\n-\tperiod := countstore.PeriodDay\n-\tbucket := c.Account.Identity.DID.String() + \"/\" + HashOfString(post.Text)\n-\tc.IncrementPeriod(\"reply-text\", bucket, period)\n-\n \t// don't action short replies, or accounts more than two weeks old\n \tif utf8.RuneCountInString(post.Text) <= 10 {\n \t\treturn nil\n@@ -63,8 +58,15 @@ func IdenticalReplyPostRule(c *automod.RecordContext, post *appbsky.FeedPost) er\n \t\t}\n \t}\n \n-\tif c.GetCount(\"reply-text\", bucket, period) >= identicalReplyLimit {\n+\t// increment before read. use a specific period (IncrementPeriod()) to reduce the number of counters (one per unique post text)\n+\tperiod := countstore.PeriodDay\n+\tbucket := c.Account.Identity.DID.String() + \"/\" + HashOfString(post.Text)\n+\tc.IncrementPeriod(\"reply-text\", bucket, period)\n+\n+\tcount := c.GetCount(\"reply-text\", bucket, period)\n+\tif count >= identicalReplyLimit {\n \t\tc.AddAccountFlag(\"multi-identical-reply\")\n+\t\t//c.ReportAccount(automod.ReportReasonRude, fmt.Sprintf(\"possible spam (young account, %d identical reply-posts today)\", tag))\n \t\tc.Notify(\"slack\")\n \t}\n \n---\n"}], "ideal": "Title: automod polish\n\nBody: branch collecting tweaks that have been temporarily deployed in prod"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/hepa/server.go\n@@ -136,11 +136,13 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t}\n \n \textraBlobRules := []automod.BlobRuleFunc{}\n+\t/* XXX: disable hive temporarily\n \tif config.HiveAPIToken != \"\" {\n \t\tlogger.Info(\"configuring Hive AI image labeler\")\n \t\thc := visual.NewHiveAIClient(config.HiveAPIToken)\n \t\textraBlobRules = append(extraBlobRules, hc.HiveLabelBlobRule)\n \t}\n+\t*/\n \n \tif config.AbyssHost != \"\" && config.AbyssPassword != \"\" {\n \t\tlogger.Info(\"configuring abyss abusive image scanning\")\n---\n"}], "ideal": "Title: HACK to do abyss-only blob processing temporarily\n\nBody: DO NOT MERGE\r\n\r\nThis is to exercise automod more in prod with real rules."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/hepa/consumer.go\n@@ -140,7 +140,7 @@ func (s *Server) HandleRepoCommit(ctx context.Context, evt *comatproto.SyncSubsc\n \n \t\tek := repomgr.EventKind(op.Action)\n \t\tswitch ek {\n-\t\tcase repomgr.EvtKindCreateRecord:\n+\t\tcase repomgr.EvtKindCreateRecord, repomgr.EvtKindUpdateRecord:\n \t\t\t// read the record from blocks, and verify CID\n \t\t\trc, rec, err := rr.GetRecord(ctx, op.Path)\n \t\t\tif err != nil {\n@@ -151,9 +151,19 @@ func (s *Server) HandleRepoCommit(ctx context.Context, evt *comatproto.SyncSubsc\n \t\t\t\tlogger.Error(\"mismatch between commit op CID and record block\", \"recordCID\", rc, \"opCID\", op.Cid)\n \t\t\t\tbreak\n \t\t\t}\n+\t\t\tvar action string\n+\t\t\tswitch ek {\n+\t\t\tcase repomgr.EvtKindCreateRecord:\n+\t\t\t\taction = automod.CreateOp\n+\t\t\tcase repomgr.EvtKindUpdateRecord:\n+\t\t\t\taction = automod.UpdateOp\n+\t\t\tdefault:\n+\t\t\t\tlogger.Error(\"impossible event kind\", \"kind\", ek)\n+\t\t\t\tbreak\n+\t\t\t}\n \t\t\trecCID := syntax.CID(op.Cid.String())\n \t\t\terr = s.engine.ProcessRecordOp(ctx, automod.RecordOp{\n-\t\t\t\tAction:     automod.CreateOp,\n+\t\t\t\tAction:     action,\n \t\t\t\tDID:        did,\n \t\t\t\tCollection: collection,\n \t\t\t\tRecordKey:  rkey,\n---\ncmd/hepa/main.go\n@@ -4,9 +4,11 @@ import (\n \t\"context\"\n \t\"encoding/json\"\n \t\"fmt\"\n+\t\"io\"\n \t\"log/slog\"\n \t\"net/http\"\n \t\"os\"\n+\t\"strings\"\n \t\"time\"\n \n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n@@ -113,6 +115,11 @@ func run(args []string) error {\n \t\t\tUsage:   \"which ruleset config to use: default, no-blobs, only-blobs\",\n \t\t\tEnvVars: []string{\"HEPA_RULESET\"},\n \t\t},\n+\t\t&cli.StringFlag{\n+\t\t\tName:    \"log-level\",\n+\t\t\tUsage:   \"\",\n+\t\t\tEnvVars: []string{\"HEPA_LOG_LEVEL\", \"LOG_LEVEL\"},\n+\t\t},\n \t}\n \n \tapp.Commands = []*cli.Command{\n@@ -149,6 +156,27 @@ func configDirectory(cctx *cli.Context) (identity.Directory, error) {\n \treturn dir, nil\n }\n \n+func configLogger(cctx *cli.Context, writer io.Writer) *slog.Logger {\n+\tvar level slog.Level\n+\tswitch strings.ToLower(cctx.String(\"log-level\")) {\n+\tcase \"error\":\n+\t\tlevel = slog.LevelError\n+\tcase \"warn\":\n+\t\tlevel = slog.LevelWarn\n+\tcase \"info\":\n+\t\tlevel = slog.LevelInfo\n+\tcase \"debug\":\n+\t\tlevel = slog.LevelDebug\n+\tdefault:\n+\t\tlevel = slog.LevelInfo\n+\t}\n+\tlogger := slog.New(slog.NewJSONHandler(writer, &slog.HandlerOptions{\n+\t\tLevel: level,\n+\t}))\n+\tslog.SetDefault(logger)\n+\treturn logger\n+}\n+\n var runCmd = &cli.Command{\n \tName:  \"run\",\n \tUsage: \"run the hepa daemon\",\n@@ -168,11 +196,7 @@ var runCmd = &cli.Command{\n \t},\n \tAction: func(cctx *cli.Context) error {\n \t\tctx := context.Background()\n-\t\tlogger := slog.New(slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{\n-\t\t\tLevel: slog.LevelInfo,\n-\t\t}))\n-\t\tslog.SetDefault(logger)\n-\n+\t\tlogger := configLogger(cctx, os.Stdout)\n \t\tconfigOTEL(\"hepa\")\n \n \t\tdir, err := configDirectory(cctx)\n@@ -236,10 +260,7 @@ var runCmd = &cli.Command{\n // for simple commands, not long-running daemons\n func configEphemeralServer(cctx *cli.Context) (*Server, error) {\n \t// NOTE: using stderr not stdout because some commands print to stdout\n-\tlogger := slog.New(slog.NewJSONHandler(os.Stderr, &slog.HandlerOptions{\n-\t\tLevel: slog.LevelInfo,\n-\t}))\n-\tslog.SetDefault(logger)\n+\tlogger := configLogger(cctx, os.Stderr)\n \n \tdir, err := configDirectory(cctx)\n \tif err != nil {\n---\n"}], "ideal": "Title: hepa: small improvements\n\nBody: process record updates (in addition to creates), eg for profile records.\r\n\r\nalso make log level configurable via an env var (or CLI arg)."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/engine/engine.go\n@@ -4,7 +4,6 @@ import (\n \t\"context\"\n \t\"fmt\"\n \t\"log/slog\"\n-\t\"strings\"\n \t\"time\"\n \n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n@@ -217,11 +216,3 @@ func (e *Engine) CanonicalLogLineNotification(c *NotificationContext) {\n \t\t\"reject\", c.effects.RejectEvent,\n \t)\n }\n-\n-func splitRepoPath(path string) (string, string, error) {\n-\tparts := strings.SplitN(path, \"/\", 3)\n-\tif len(parts) != 2 {\n-\t\treturn \"\", \"\", fmt.Errorf(\"invalid record path: %s\", path)\n-\t}\n-\treturn parts[0], parts[1], nil\n-}\n---\nbgs/admin.go\n@@ -17,10 +17,6 @@ import (\n \t\"gorm.io/gorm\"\n )\n \n-func (bgs *BGS) handleAdminBlockRepoStream(e echo.Context) error {\n-\tpanic(\"TODO\")\n-}\n-\n func (bgs *BGS) handleAdminSetSubsEnabled(e echo.Context) error {\n \tenabled, err := strconv.ParseBool(e.QueryParam(\"enabled\"))\n \tif err != nil {\n---\nlex/gen.go\n@@ -7,7 +7,6 @@ import (\n \t\"bytes\"\n \t\"encoding/json\"\n \t\"fmt\"\n-\t\"html/template\"\n \t\"io\"\n \t\"os\"\n \t\"path/filepath\"\n@@ -585,17 +584,6 @@ func (s *TypeSchema) WriteRPC(w io.Writer, typename string) error {\n \treturn nil\n }\n \n-func doTemplate(w io.Writer, info interface{}, templ string) error {\n-\tt := template.Must(template.New(\"\").\n-\t\tFuncs(template.FuncMap{\n-\t\t\t\"TODO\": func(thing string) string {\n-\t\t\t\treturn \"//TODO: \" + thing\n-\t\t\t},\n-\t\t}).Parse(templ))\n-\n-\treturn t.Execute(w, info)\n-}\n-\n func CreateHandlerStub(pkg string, impmap map[string]string, dir string, schemas []*Schema, handlers bool) error {\n \tbuf := new(bytes.Buffer)\n \n@@ -1352,24 +1340,6 @@ func (ts *TypeSchema) writeTypeMethods(name string, w io.Writer) error {\n \t}\n }\n \n-func forEachProp(t TypeSchema, cb func(k string, ts TypeSchema) error) error {\n-\tvar keys []string\n-\tfor k := range t.Properties {\n-\t\tkeys = append(keys, k)\n-\t}\n-\n-\tsort.Strings(keys)\n-\n-\tfor _, k := range keys {\n-\t\tsubv := t.Properties[k]\n-\n-\t\tif err := cb(k, *subv); err != nil {\n-\t\t\treturn err\n-\t\t}\n-\t}\n-\treturn nil\n-}\n-\n func (ts *TypeSchema) writeJsonMarshalerObject(name string, w io.Writer) error {\n \treturn nil // no need for a special json marshaler right now\n }\n@@ -1399,20 +1369,6 @@ func (s *TypeSchema) writeJsonUnmarshalerObject(name string, w io.Writer) error\n \t//pf(\"func (t *%s) UnmarshalJSON(b []byte) (error) {\\n\", name)\n }\n \n-func (ts *TypeSchema) getTypeConstValueForType(ref string) (any, error) {\n-\trr, err := ts.lookupRef(ref)\n-\tif err != nil {\n-\t\treturn nil, err\n-\t}\n-\n-\treft, ok := rr.Properties[\"type\"]\n-\tif !ok {\n-\t\treturn nil, nil\n-\t}\n-\n-\treturn reft.Const, nil\n-}\n-\n func (ts *TypeSchema) writeJsonUnmarshalerEnum(name string, w io.Writer) error {\n \tpf := printerf(w)\n \tpf(\"func (t *%s) UnmarshalJSON(b []byte) (error) {\\n\", name)\n---\npds/server.go\n@@ -3,7 +3,6 @@ package pds\n import (\n \t\"context\"\n \t\"database/sql\"\n-\t\"encoding/json\"\n \t\"errors\"\n \t\"fmt\"\n \t\"net\"\n@@ -536,15 +535,6 @@ func (s *Server) userCheckMiddleware(next echo.HandlerFunc) echo.HandlerFunc {\n \t}\n }\n \n-func (s *Server) handleAuth(next echo.HandlerFunc) echo.HandlerFunc {\n-\treturn func(c echo.Context) error {\n-\t\tauthstr := c.Request().Header.Get(\"Authorization\")\n-\t\t_ = authstr\n-\n-\t\treturn nil\n-\t}\n-}\n-\n func (s *Server) getUser(ctx context.Context) (*User, error) {\n \tu, ok := ctx.Value(\"user\").(*User)\n \tif !ok {\n@@ -556,15 +546,6 @@ func (s *Server) getUser(ctx context.Context) (*User, error) {\n \treturn u, nil\n }\n \n-func convertRecordTo(from any, to any) error {\n-\tb, err := json.Marshal(from)\n-\tif err != nil {\n-\t\treturn err\n-\t}\n-\n-\treturn json.Unmarshal(b, to)\n-}\n-\n func validateEmail(email string) error {\n \t_, err := mail.ParseAddress(email)\n \tif err != nil {\n---\npds/type_helpers.go\n@@ -1,22 +0,0 @@\n-package pds\n-\n-import (\n-\t\"context\"\n-\n-\tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n-)\n-\n-// TODO: this is a quick helper to transform bsky.ActorDefs_ProfileViewBasic to\n-// bsky.ActorDefs_ProfileView, written during the lexicon refactor (March\n-// 2023). It probably needs to be updated to actually populate all the\n-// additional fields (eg, via additional database queries)\n-func (s *Server) actorBasicToView(ctx context.Context, basic *appbsky.ActorDefs_ProfileViewBasic) *appbsky.ActorDefs_ProfileView {\n-\tview := &appbsky.ActorDefs_ProfileView{\n-\t\tAvatar:      basic.Avatar,\n-\t\tDid:         basic.Did,\n-\t\tDisplayName: basic.DisplayName,\n-\t\tHandle:      basic.Handle,\n-\t\tViewer:      basic.Viewer,\n-\t}\n-\treturn view\n-}\n---\nutil/normalize.go\n@@ -1,26 +0,0 @@\n-package util\n-\n-import (\n-\t\"fmt\"\n-\t\"strings\"\n-)\n-\n-func NormalizeHostname(hostname string) (string, error) {\n-\tif len(hostname) > 255 {\n-\t\treturn \"\", fmt.Errorf(\"hostname cannot be longer than 255 characters\")\n-\t}\n-\n-\thostname = strings.TrimSpace(hostname)\n-\thostname = strings.Trim(hostname, \".\")\n-\n-\tif len(hostname) == 0 {\n-\t\treturn \"\", fmt.Errorf(\"hostname cannot be empty\")\n-\t}\n-\n-\t// Lowercase the hostname, as domain names are case-insensitive\n-\thostname = strings.ToLower(hostname)\n-\n-\t// TODO: other normalizations\n-\n-\treturn hostname, nil\n-}\n---\n"}], "ideal": "Title: remove deadcode\n\nBody: ran `deadcode -test ./...` and deleted stuff which looked actively confusing or misplaced, as opposed to just filling out API completeness or work-in-progress."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/capture/capture_test.go\n@@ -1,6 +1,7 @@\n package capture\n \n import (\n+\t\"context\"\n \t\"testing\"\n \n \t\"github.com/bluesky-social/indigo/automod/countstore\"\n@@ -9,15 +10,16 @@ import (\n )\n \n func TestNoOpCaptureReplyRule(t *testing.T) {\n+\tctx := context.Background()\n \tassert := assert.New(t)\n \n \teng := engine.EngineTestFixture()\n \tcapture := MustLoadCapture(\"testdata/capture_atprotocom.json\")\n \tassert.NoError(ProcessCaptureRules(&eng, capture))\n-\tc, err := eng.GetCount(\"automod-quota\", \"report\", countstore.PeriodDay)\n+\tc, err := eng.Counters.GetCount(ctx, \"automod-quota\", \"report\", countstore.PeriodDay)\n \tassert.NoError(err)\n \tassert.Equal(0, c)\n-\tc, err = eng.GetCount(\"automod-quota\", \"takedown\", countstore.PeriodDay)\n+\tc, err = eng.Counters.GetCount(ctx, \"automod-quota\", \"takedown\", countstore.PeriodDay)\n \tassert.NoError(err)\n \tassert.Equal(0, c)\n }\n---\nautomod/engine/action_dedupe_test.go\n@@ -48,7 +48,7 @@ func TestAccountReportDedupe(t *testing.T) {\n \t\tassert.NoError(eng.ProcessRecordOp(ctx, op))\n \t}\n \n-\treports, err := eng.GetCount(\"automod-quota\", \"report\", countstore.PeriodDay)\n+\treports, err := eng.Counters.GetCount(ctx, \"automod-quota\", \"report\", countstore.PeriodDay)\n \tassert.NoError(err)\n \tassert.Equal(1, reports)\n }\n---\nautomod/engine/circuit_breaker_test.go\n@@ -57,11 +57,11 @@ func TestTakedownCircuitBreaker(t *testing.T) {\n \t\tassert.NoError(eng.ProcessRecordOp(ctx, op))\n \t}\n \n-\ttakedowns, err := eng.GetCount(\"automod-quota\", \"takedown\", countstore.PeriodDay)\n+\ttakedowns, err := eng.Counters.GetCount(ctx, \"automod-quota\", \"takedown\", countstore.PeriodDay)\n \tassert.NoError(err)\n \tassert.Equal(QuotaModTakedownDay, takedowns)\n \n-\treports, err := eng.GetCount(\"automod-quota\", \"report\", countstore.PeriodDay)\n+\treports, err := eng.Counters.GetCount(ctx, \"automod-quota\", \"report\", countstore.PeriodDay)\n \tassert.NoError(err)\n \tassert.Equal(0, reports)\n }\n@@ -99,11 +99,11 @@ func TestReportCircuitBreaker(t *testing.T) {\n \t\tassert.NoError(eng.ProcessRecordOp(ctx, op))\n \t}\n \n-\ttakedowns, err := eng.GetCount(\"automod-quota\", \"takedown\", countstore.PeriodDay)\n+\ttakedowns, err := eng.Counters.GetCount(ctx, \"automod-quota\", \"takedown\", countstore.PeriodDay)\n \tassert.NoError(err)\n \tassert.Equal(0, takedowns)\n \n-\treports, err := eng.GetCount(\"automod-quota\", \"report\", countstore.PeriodDay)\n+\treports, err := eng.Counters.GetCount(ctx, \"automod-quota\", \"report\", countstore.PeriodDay)\n \tassert.NoError(err)\n \tassert.Equal(QuotaModReportDay, reports)\n }\n---\nautomod/engine/engine.go\n@@ -39,6 +39,9 @@ type Engine struct {\n \tSlackWebhookURL string\n }\n \n+// Entrypoint for external code pushing arbitrary identity events in to the engine.\n+//\n+// This method can be called concurrently, though cached state may end up inconsistent if multiple events for the same account (DID) are processed in parallel.\n func (eng *Engine) ProcessIdentityEvent(ctx context.Context, typ string, did syntax.DID) error {\n \t// similar to an HTTP server, we want to recover any panics from rule execution\n \tdefer func() {\n@@ -76,6 +79,9 @@ func (eng *Engine) ProcessIdentityEvent(ctx context.Context, typ string, did syn\n \treturn nil\n }\n \n+// Entrypoint for external code pushing repository updates. A simple repo commit results in multiple calls.\n+//\n+// This method can be called concurrently, though cached state may end up inconsistent if multiple events for the same account (DID) are processed in parallel.\n func (eng *Engine) ProcessRecordOp(ctx context.Context, op RecordOp) error {\n \t// similar to an HTTP server, we want to recover any panics from rule execution\n \tdefer func() {\n@@ -129,20 +135,7 @@ func (eng *Engine) ProcessRecordOp(ctx context.Context, op RecordOp) error {\n \treturn nil\n }\n \n-func (e *Engine) GetCount(name, val, period string) (int, error) {\n-\treturn e.Counters.GetCount(context.TODO(), name, val, period)\n-}\n-\n-func (e *Engine) GetCountDistinct(name, bucket, period string) (int, error) {\n-\treturn e.Counters.GetCountDistinct(context.TODO(), name, bucket, period)\n-}\n-\n-// checks if `val` is an element of set `name`\n-func (e *Engine) InSet(name, val string) (bool, error) {\n-\treturn e.Sets.InSet(context.TODO(), name, val)\n-}\n-\n-// purge caches of any exiting metadata\n+// Purge metadata caches for a specific account.\n func (e *Engine) PurgeAccountCaches(ctx context.Context, did syntax.DID) error {\n \te.Directory.Purge(ctx, did.AtIdentifier())\n \treturn e.Cache.Purge(ctx, \"acct\", did.String())\n---\nautomod/engine/persisthelpers.go\n@@ -56,7 +56,7 @@ func (eng *Engine) dedupeReportActions(ctx context.Context, did syntax.DID, repo\n \tnewReports := []ModReport{}\n \tfor _, r := range reports {\n \t\tcounterName := \"automod-account-report-\" + ReasonShortName(r.ReasonType)\n-\t\texisting, err := eng.GetCount(counterName, did.String(), countstore.PeriodDay)\n+\t\texisting, err := eng.Counters.GetCount(ctx, counterName, did.String(), countstore.PeriodDay)\n \t\tif err != nil {\n \t\t\treturn nil, fmt.Errorf(\"checking report de-dupe counts: %w\", err)\n \t\t}\n@@ -77,7 +77,7 @@ func (eng *Engine) circuitBreakReports(ctx context.Context, reports []ModReport)\n \tif len(reports) == 0 {\n \t\treturn []ModReport{}, nil\n \t}\n-\tc, err := eng.GetCount(\"automod-quota\", \"report\", countstore.PeriodDay)\n+\tc, err := eng.Counters.GetCount(ctx, \"automod-quota\", \"report\", countstore.PeriodDay)\n \tif err != nil {\n \t\treturn nil, fmt.Errorf(\"checking report action quota: %w\", err)\n \t}\n@@ -96,7 +96,7 @@ func (eng *Engine) circuitBreakTakedown(ctx context.Context, takedown bool) (boo\n \tif !takedown {\n \t\treturn false, nil\n \t}\n-\tc, err := eng.GetCount(\"automod-quota\", \"takedown\", countstore.PeriodDay)\n+\tc, err := eng.Counters.GetCount(ctx, \"automod-quota\", \"takedown\", countstore.PeriodDay)\n \tif err != nil {\n \t\treturn false, fmt.Errorf(\"checking takedown action quota: %w\", err)\n \t}\n---\n"}], "ideal": "Title: engine: remove wrapper counter and set methods\n\nBody: These were from earlier API design, and are just confusing now."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/README.md\n@@ -1,7 +1,7 @@\n-`indigo/automod`\n-================\n+`indigo/automod`: rules engine for anti-spam and other moderation tasks\n+=======================================================================\n \n-This package (`github.com/bluesky-social/indigo/automod`) contains a \"rules engine\" to augment human moderators in the atproto network. Batches of rules are processed for novel \"events\" such as a new post or update of an account handle. Counters and other statistics are collected, which can drive subsequent rule invocations. The outcome of rules can be moderation events like \"report account for human review\" or \"label post\". A lot of what this package does is collect and maintain caches of relevant metadata about accounts and pieces of content, so that rules have efficient access to this information.\n+automod is a \"rules engine\" framework, used to augment human moderators in the atproto network by proactively identifying patterns of behavior and content. Batches of rules are processed for novel \"events\" such as a new post or update of an account handle. Counters and other statistics are collected, which can drive subsequent rule invocations. The outcome of rules can be moderation events like \"report account for human review\" or \"label post\". Much of what this framework does is simply aggregating and maintaining caches of relevant metadata about accounts and pieces of content, so that rules have efficient access to this information.\n \n A primary design goal is to have a flexible framework to allow new rules to be written and deployed rapidly in response to new patterns of spam and abuse.\n \n---\nautomod/cachestore/doc.go\n@@ -0,0 +1,6 @@\n+// Automod component for caching arbitrary data (as JSON strings) with a fixed TTL and purging.\n+//\n+// Includes an interface and implementations using redis and in-process memory.\n+//\n+// This is used by the rules engine to cache things like account metadata, improving latency and reducing load on authoritative backend systems.\n+package cachestore\n---\nautomod/capture/doc.go\n@@ -0,0 +1,4 @@\n+// Automod development helpers for fetching and saving snapshots of real-world content and metadata.\n+//\n+// NOTE: real-world content is sensitive, even if it is abusive.\n+package capture\n---\nautomod/countstore/doc.go\n@@ -0,0 +1,2 @@\n+// Interface for fast atomic counters, and separate implementations using redis and in-process memory.\n+package countstore\n---\nautomod/doc.go\n@@ -1,6 +1,6 @@\n // Auto-Moderation rules engine for anti-spam and other moderation tasks.\n //\n-// This package (`github.com/bluesky-social/indigo/automod`) contains a \"rules engine\" to augment human moderators in the atproto network. Batches of rules are processed for novel \"events\", such as a new post or update of an account handle. Counters and other statistics are collected, which can drive subsequent rule invocations. The outcome of rules can be moderation events like \"report account for human review\" or \"label post\". A lot of what this package does is collect and maintain caches of relevant metadata about accounts and pieces of content, so that rules have efficient access to this information.\n+// This package (`github.com/bluesky-social/indigo/automod`) contains a \"rules engine\" to augment human moderators in the atproto network. Batches of rules are processed for novel \"events\" such as a new post or update of an account handle. Counters and other statistics are collected, which can drive subsequent rule invocations. The outcome of rules can be moderation events like \"report account for human review\" or \"label post\". A lot of what this package does is collect and maintain caches of relevant metadata about accounts and pieces of content, so that rules have efficient access to this information.\n //\n // See `automod/README.md` for more background, and `cmd/hepa` for a daemon built on this package.\n package automod\n---\nautomod/engine/doc.go\n@@ -0,0 +1,2 @@\n+// Core automod rules engine implementation and related types\n+package engine\n---\nautomod/engine/fetchaccountmeta.go\n@@ -11,6 +11,7 @@ import (\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n )\n \n+// Helper to hydrate metadata about an account from several sources: PDS (if access), mod service (if access), public identity resolution\n func (e *Engine) GetAccountMeta(ctx context.Context, ident *identity.Identity) (*AccountMeta, error) {\n \n \t// wipe parsed public key; it's a waste of space and can't serialize\n---\nautomod/engine/ruleset.go\n@@ -8,6 +8,7 @@ import (\n \tlexutil \"github.com/bluesky-social/indigo/lex/util\"\n )\n \n+// Holds configuration of which rules of various types should be run, and helps dispatch events to those rules.\n type RuleSet struct {\n \tPostRules         []PostRuleFunc\n \tProfileRules      []ProfileRuleFunc\n@@ -17,6 +18,7 @@ type RuleSet struct {\n \tBlobRules         []BlobRuleFunc\n }\n \n+// Executes all the various record-related rules. Only dispatches execution, does no other de-dupe or pre/post processing.\n func (r *RuleSet) CallRecordRules(c *RecordContext) error {\n \t// first the generic rules\n \tfor _, f := range r.RecordRules {\n@@ -62,6 +64,7 @@ func (r *RuleSet) CallRecordRules(c *RecordContext) error {\n \treturn nil\n }\n \n+// NOTE: this will probably be removed and merged in to `CallRecordRules`\n func (r *RuleSet) CallRecordDeleteRules(c *RecordContext) error {\n \tfor _, f := range r.RecordDeleteRules {\n \t\terr := f(c)\n@@ -72,6 +75,7 @@ func (r *RuleSet) CallRecordDeleteRules(c *RecordContext) error {\n \treturn nil\n }\n \n+// Executes rules for identity update events.\n func (r *RuleSet) CallIdentityRules(c *AccountContext) error {\n \tfor _, f := range r.IdentityRules {\n \t\terr := f(c)\n---\nautomod/flagstore/doc.go\n@@ -0,0 +1,2 @@\n+// Interface for storing \"flags\", a form of private automod metadata.\n+package flagstore\n---\nautomod/rules/doc.go\n@@ -0,0 +1,2 @@\n+// Example automod rules and helpers.\n+package rules\n---\nautomod/setstore/doc.go\n@@ -0,0 +1,2 @@\n+// Interface for simple sets of strings, with fast inclusion checks.\n+package setstore\n---\n"}], "ideal": "Title: automod: a bit more docs/comments\n\nBody: Mostly old commits, re-based."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "api/extra.go\n@@ -5,6 +5,7 @@ import (\n \t\"errors\"\n \t\"fmt\"\n \t\"io\"\n+\t\"log/slog\"\n \t\"net\"\n \t\"net/http\"\n \t\"net/url\"\n@@ -14,13 +15,10 @@ import (\n \n \t\"github.com/bluesky-social/indigo/did\"\n \tarc \"github.com/hashicorp/golang-lru/arc/v2\"\n-\tlogging \"github.com/ipfs/go-log\"\n \t\"go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\"\n \totel \"go.opentelemetry.io/otel\"\n )\n \n-var log = logging.Logger(\"api\")\n-\n func ResolveDidToHandle(ctx context.Context, res did.Resolver, hr HandleResolver, udid string) (string, string, error) {\n \tctx, span := otel.Tracer(\"gosky\").Start(ctx, \"resolveDidToHandle\")\n \tdefer span.End()\n@@ -248,12 +246,12 @@ func (tr *TestHandleResolver) ResolveHandleToDid(ctx context.Context, handle str\n \n \t\tresp, err := c.Do(req)\n \t\tif err != nil {\n-\t\t\tlog.Warnf(\"failed to get did: %s\", err)\n+\t\t\tslog.Warn(\"failed to resolve handle to DID\", \"handle\", handle, \"err\", err)\n \t\t\tcontinue\n \t\t}\n \n \t\tif resp.StatusCode != 200 {\n-\t\t\tlog.Warnf(\"got non-200 status code while fetching did: %d\", resp.StatusCode)\n+\t\t\tslog.Warn(\"got non-200 status code while resolving handle\", \"handle\", handle, \"statusCode\", resp.StatusCode)\n \t\t\tcontinue\n \t\t}\n \n---\nutil/http.go\n@@ -2,34 +2,32 @@ package util\n \n import (\n \t\"context\"\n+\t\"log/slog\"\n \t\"net/http\"\n \t\"time\"\n \n \t\"github.com/hashicorp/go-retryablehttp\"\n-\tlogging \"github.com/ipfs/go-log\"\n )\n \n-var log = logging.Logger(\"http\")\n-\n-type LeveledZap struct {\n-\tinner *logging.ZapEventLogger\n+type LeveledSlog struct {\n+\tinner *slog.Logger\n }\n \n // re-writes HTTP client ERROR to WARN level (because of retries)\n-func (l LeveledZap) Error(msg string, keysAndValues ...interface{}) {\n-\tl.inner.Warnw(msg, keysAndValues...)\n+func (l LeveledSlog) Error(msg string, keysAndValues ...interface{}) {\n+\tl.inner.Warn(msg, keysAndValues...)\n }\n \n-func (l LeveledZap) Warn(msg string, keysAndValues ...interface{}) {\n-\tl.inner.Warnw(msg, keysAndValues...)\n+func (l LeveledSlog) Warn(msg string, keysAndValues ...interface{}) {\n+\tl.inner.Warn(msg, keysAndValues...)\n }\n \n-func (l LeveledZap) Info(msg string, keysAndValues ...interface{}) {\n-\tl.inner.Infow(msg, keysAndValues...)\n+func (l LeveledSlog) Info(msg string, keysAndValues ...interface{}) {\n+\tl.inner.Info(msg, keysAndValues...)\n }\n \n-func (l LeveledZap) Debug(msg string, keysAndValues ...interface{}) {\n-\tl.inner.Debugw(msg, keysAndValues...)\n+func (l LeveledSlog) Debug(msg string, keysAndValues ...interface{}) {\n+\tl.inner.Debug(msg, keysAndValues...)\n }\n \n // Generates an HTTP client with decent general-purpose defaults around\n@@ -45,11 +43,12 @@ func (l LeveledZap) Debug(msg string, keysAndValues ...interface{}) {\n // default.\n func RobustHTTPClient() *http.Client {\n \n+\tlogger := LeveledSlog{inner: slog.Default().With(\"subsystem\", \"RobustHTTPClient\")}\n \tretryClient := retryablehttp.NewClient()\n \tretryClient.RetryMax = 3\n \tretryClient.RetryWaitMin = 1 * time.Second\n \tretryClient.RetryWaitMax = 10 * time.Second\n-\tretryClient.Logger = retryablehttp.LeveledLogger(LeveledZap{log})\n+\tretryClient.Logger = retryablehttp.LeveledLogger(logger)\n \tretryClient.CheckRetry = XRPCRetryPolicy\n \tclient := retryClient.StandardClient()\n \tclient.Timeout = 30 * time.Second\n---\n"}], "ideal": "Title: library package go-log to slog update\n\nBody: These packages emit log lines from all kinds of services, even those not using go-log, and they end up formatted inconsistently (lines not JSON)."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/engine/effects.go\n@@ -6,7 +6,7 @@ import (\n \n var (\n \t// time period within which automod will not re-report an account for the same reasonType\n-\tReportDupePeriod = 7 * 24 * time.Hour\n+\tReportDupePeriod = 1 * 24 * time.Hour\n \t// number of reports automod can file per day, for all subjects and types combined (circuit breaker)\n \tQuotaModReportDay = 50\n \t// number of takedowns automod can action per day, for all subjects combined (circuit breaker)\n---\n"}], "ideal": "Title: automod: change report fresh/limit period to one day\n\nBody: After discussion with mod team.\r\n\r\ncc: @warpfork for visibility, but i'm going to self-merge this as it is mostly a policy/process tweak, not a code thing"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/syntax/cid.go\n@@ -13,14 +13,16 @@ import (\n // Always use [ParseCID] instead of wrapping strings directly, especially when working with network input.\n type CID string\n \n+var cidRegex = regexp.MustCompile(`^[a-zA-Z0-9+=]{8,256}$`)\n+\n func ParseCID(raw string) (CID, error) {\n \tif len(raw) > 256 {\n \t\treturn \"\", fmt.Errorf(\"CID is too long (256 chars max)\")\n \t}\n \tif len(raw) < 8 {\n \t\treturn \"\", fmt.Errorf(\"CID is too short (8 chars min)\")\n \t}\n-\tvar cidRegex = regexp.MustCompile(`^[a-zA-Z0-9+=]{8,256}$`)\n+\n \tif !cidRegex.MatchString(raw) {\n \t\treturn \"\", fmt.Errorf(\"CID syntax didn't validate via regex\")\n \t}\n---\natproto/syntax/datetime.go\n@@ -21,11 +21,13 @@ const (\n // Syntax is specified at: https://atproto.com/specs/lexicon#datetime\n type Datetime string\n \n+var datetimeRegex = regexp.MustCompile(`^[0-9]{4}-[01][0-9]-[0-3][0-9]T[0-2][0-9]:[0-6][0-9]:[0-6][0-9](.[0-9]{1,20})?(Z|([+-][0-2][0-9]:[0-5][0-9]))$`)\n+\n func ParseDatetime(raw string) (Datetime, error) {\n \tif len(raw) > 64 {\n \t\treturn \"\", fmt.Errorf(\"Datetime too long (max 64 chars)\")\n \t}\n-\tvar datetimeRegex = regexp.MustCompile(`^[0-9]{4}-[01][0-9]-[0-3][0-9]T[0-2][0-9]:[0-6][0-9]:[0-6][0-9](.[0-9]{1,20})?(Z|([+-][0-2][0-9]:[0-5][0-9]))$`)\n+\n \tif !datetimeRegex.MatchString(raw) {\n \t\treturn \"\", fmt.Errorf(\"Datetime syntax didn't validate via regex\")\n \t}\n@@ -53,6 +55,8 @@ func ParseDatetimeTime(raw string) (time.Time, error) {\n // Similar to ParseDatetime, but more flexible about some parsing.\n //\n // Note that this may mutate the internal string, so a round-trip will fail. This is intended for working with legacy/broken records, not to be used in an ongoing way.\n+var hasTimezoneRegex = regexp.MustCompile(`^.*(([+-]\\d\\d:?\\d\\d)|[a-zA-Z])$`)\n+\n func ParseDatetimeLenient(raw string) (Datetime, error) {\n \t// fast path: it is a valid overall datetime\n \tvalid, err := ParseDatetime(raw)\n@@ -71,7 +75,6 @@ func ParseDatetimeLenient(raw string) (Datetime, error) {\n \t}\n \n \t// try adding timezone if it is missing\n-\tvar hasTimezoneRegex = regexp.MustCompile(`^.*(([+-]\\d\\d:?\\d\\d)|[a-zA-Z])$`)\n \tif !hasTimezoneRegex.MatchString(raw) {\n \t\twithTZ, err := ParseDatetime(raw + \"Z\")\n \t\tif nil == err {\n---\natproto/syntax/did.go\n@@ -13,11 +13,12 @@ import (\n // Syntax specification: https://atproto.com/specs/did\n type DID string\n \n+var didRegex = regexp.MustCompile(`^did:[a-z]+:[a-zA-Z0-9._:%-]*[a-zA-Z0-9._-]$`)\n+\n func ParseDID(raw string) (DID, error) {\n \tif len(raw) > 2*1024 {\n \t\treturn \"\", fmt.Errorf(\"DID is too long (2048 chars max)\")\n \t}\n-\tvar didRegex = regexp.MustCompile(`^did:[a-z]+:[a-zA-Z0-9._:%-]*[a-zA-Z0-9._-]$`)\n \tif !didRegex.MatchString(raw) {\n \t\treturn \"\", fmt.Errorf(\"DID syntax didn't validate via regex\")\n \t}\n---\natproto/syntax/language.go\n@@ -12,11 +12,12 @@ import (\n // The syntax is BCP-47. This is a partial/naive parsing implementation, designed for fast validation and exact-string passthrough with no normaliztion. For actually working with BCP-47 language specifiers in atproto code bases, we recommend the golang.org/x/text/language package.\n type Language string\n \n+var langRegex = regexp.MustCompile(`^(i|[a-z]{2,3})(-[a-zA-Z0-9]+)*$`)\n+\n func ParseLanguage(raw string) (Language, error) {\n \tif len(raw) > 128 {\n \t\treturn \"\", fmt.Errorf(\"Language is too long (128 chars max)\")\n \t}\n-\tvar langRegex = regexp.MustCompile(`^(i|[a-z]{2,3})(-[a-zA-Z0-9]+)*$`)\n \tif !langRegex.MatchString(raw) {\n \t\treturn \"\", fmt.Errorf(\"Language syntax didn't validate via regex\")\n \t}\n---\natproto/syntax/tid.go\n@@ -24,11 +24,12 @@ func Base32Sort() *base32.Encoding {\n // Syntax specification: https://atproto.com/specs/record-key\n type TID string\n \n+var tidRegex = regexp.MustCompile(`^[234567abcdefghij][234567abcdefghijklmnopqrstuvwxyz]{12}$`)\n+\n func ParseTID(raw string) (TID, error) {\n \tif len(raw) != 13 {\n \t\treturn \"\", fmt.Errorf(\"TID is wrong length (expected 13 chars)\")\n \t}\n-\tvar tidRegex = regexp.MustCompile(`^[234567abcdefghij][234567abcdefghijklmnopqrstuvwxyz]{12}$`)\n \tif !tidRegex.MatchString(raw) {\n \t\treturn \"\", fmt.Errorf(\"TID syntax didn't validate via regex\")\n \t}\n---\nsearch/indexing.go\n@@ -48,6 +48,8 @@ func (s *Server) deletePost(ctx context.Context, ident *identity.Identity, rkey\n \treturn nil\n }\n \n+var tidRegex = regexp.MustCompile(`^[234567abcdefghijklmnopqrstuvwxyz]{13}$`)\n+\n func (s *Server) indexPost(ctx context.Context, ident *identity.Identity, rec *appbsky.FeedPost, path string, rcid cid.Cid) error {\n \tctx, span := tracer.Start(ctx, \"indexPost\")\n \tdefer span.End()\n@@ -56,7 +58,6 @@ func (s *Server) indexPost(ctx context.Context, ident *identity.Identity, rec *a\n \tlog := s.logger.With(\"repo\", ident.DID, \"path\", path, \"op\", \"indexPost\")\n \tparts := strings.SplitN(path, \"/\", 3)\n \t// TODO: replace with an atproto/syntax package type for TID\n-\tvar tidRegex = regexp.MustCompile(`^[234567abcdefghijklmnopqrstuvwxyz]{13}$`)\n \tif len(parts) != 2 || !tidRegex.MatchString(parts[1]) {\n \t\tlog.Warn(\"skipping index post record with weird path/TID\", \"did\", ident.DID, \"path\", path)\n \t\treturn nil\n---\n"}], "ideal": "Title: Move all regexp MustCompiles outside\n\nBody: Lots of CPU time spent compiling reused regexps in CPU profiles"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/gtube.go\n@@ -10,13 +10,17 @@ import (\n // https://en.wikipedia.org/wiki/GTUBE\n var gtubeString = \"XJS*C4JDBQADN1.NSBN3*2IDNEN*GTUBE-STANDARD-ANTI-UBE-TEST-EMAIL*C.34X\"\n \n+var _ automod.PostRuleFunc = GtubePostRule\n+\n func GtubePostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \tif strings.Contains(post.Text, gtubeString) {\n \t\tc.AddRecordLabel(\"spam\")\n \t}\n \treturn nil\n }\n \n+var _ automod.ProfileRuleFunc = GtubeProfileRule\n+\n func GtubeProfileRule(c *automod.RecordContext, profile *appbsky.ActorProfile) error {\n \tif profile.Description != nil && strings.Contains(*profile.Description, gtubeString) {\n \t\tc.AddRecordLabel(\"spam\")\n---\nautomod/rules/hashtags.go\n@@ -5,6 +5,8 @@ import (\n \t\"github.com/bluesky-social/indigo/automod\"\n )\n \n+var _ automod.PostRuleFunc = BadHashtagsPostRule\n+\n // looks for specific hashtags from known lists\n func BadHashtagsPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \tfor _, tag := range ExtractHashtags(post) {\n@@ -17,6 +19,8 @@ func BadHashtagsPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error\n \treturn nil\n }\n \n+var _ automod.PostRuleFunc = TooManyHashtagsPostRule\n+\n // if a post is \"almost all\" hashtags, it might be a form of search spam\n func TooManyHashtagsPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \ttags := ExtractHashtags(post)\n---\nautomod/rules/identity.go\n@@ -9,6 +9,8 @@ import (\n \t\"github.com/bluesky-social/indigo/automod/countstore\"\n )\n \n+var _ automod.IdentityRuleFunc = NewAccountRule\n+\n // triggers on first identity event for an account (DID)\n func NewAccountRule(c *automod.AccountContext) error {\n \t// need access to IndexedAt for this rule\n---\nautomod/rules/interaction.go\n@@ -9,6 +9,8 @@ import (\n \n var interactionDailyThreshold = 800\n \n+var _ automod.RecordRuleFunc = InteractionChurnRule\n+\n // looks for accounts which do frequent interaction churn, such as follow-unfollow.\n func InteractionChurnRule(c *automod.RecordContext) error {\n \tdid := c.Account.Identity.DID.String()\n@@ -37,6 +39,8 @@ func InteractionChurnRule(c *automod.RecordContext) error {\n \treturn nil\n }\n \n+var _ automod.RecordRuleFunc = DeleteInteractionRule\n+\n func DeleteInteractionRule(c *automod.RecordContext) error {\n \tdid := c.Account.Identity.DID.String()\n \tswitch c.RecordOp.Collection {\n---\nautomod/rules/keyword.go\n@@ -7,6 +7,8 @@ import (\n \t\"github.com/bluesky-social/indigo/automod\"\n )\n \n+var _ automod.PostRuleFunc = KeywordPostRule\n+\n func KeywordPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \tfor _, tok := range ExtractTextTokensPost(post) {\n \t\tif c.InSet(\"bad-words\", tok) {\n@@ -18,6 +20,8 @@ func KeywordPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \treturn nil\n }\n \n+var _ automod.ProfileRuleFunc = KeywordProfileRule\n+\n func KeywordProfileRule(c *automod.RecordContext, profile *appbsky.ActorProfile) error {\n \tfor _, tok := range ExtractTextTokensProfile(profile) {\n \t\tif c.InSet(\"bad-words\", tok) {\n@@ -29,6 +33,8 @@ func KeywordProfileRule(c *automod.RecordContext, profile *appbsky.ActorProfile)\n \treturn nil\n }\n \n+var _ automod.PostRuleFunc = ReplySingleKeywordPostRule\n+\n func ReplySingleKeywordPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \tif post.Reply != nil && !IsSelfThread(c, post) {\n \t\ttokens := ExtractTextTokensPost(post)\n---\nautomod/rules/misleading.go\n@@ -78,6 +78,8 @@ func isMisleadingURLFacet(facet PostFacet, logger *slog.Logger) bool {\n \treturn false\n }\n \n+var _ automod.PostRuleFunc = MisleadingURLPostRule\n+\n func MisleadingURLPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \t// TODO: make this an InSet() config?\n \tif c.Account.Identity.Handle == \"nowbreezing.ntw.app\" {\n@@ -100,6 +102,8 @@ func MisleadingURLPostRule(c *automod.RecordContext, post *appbsky.FeedPost) err\n \treturn nil\n }\n \n+var _ automod.PostRuleFunc = MisleadingMentionPostRule\n+\n func MisleadingMentionPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \t// TODO: do we really need to route context around? probably\n \tctx := context.TODO()\n---\nautomod/rules/private.go\n@@ -7,6 +7,8 @@ import (\n \t\"github.com/bluesky-social/indigo/automod\"\n )\n \n+var _ automod.PostRuleFunc = AccountPrivateDemoPostRule\n+\n // dummy rule. this leaks PII (account email) in logs and should never be used in real life\n func AccountPrivateDemoPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \tif c.Account.Private != nil {\n---\nautomod/rules/profile.go\n@@ -5,6 +5,8 @@ import (\n \t\"github.com/bluesky-social/indigo/automod\"\n )\n \n+var _ automod.PostRuleFunc = AccountDemoPostRule\n+\n // this is a dummy rule to demonstrate accessing account metadata (eg, profile) from within post handler\n func AccountDemoPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \tif c.Account.Profile.Description != nil && len(post.Text) > 5 && *c.Account.Profile.Description == post.Text {\n---\nautomod/rules/promo.go\n@@ -10,6 +10,8 @@ import (\n \t\"github.com/bluesky-social/indigo/automod/countstore\"\n )\n \n+var _ automod.PostRuleFunc = AggressivePromotionRule\n+\n // looks for new accounts, with a commercial or donation link in profile, which directly reply to several accounts\n //\n // this rule depends on ReplyCountPostRule() to set counts\n---\nautomod/rules/replies.go\n@@ -10,6 +10,8 @@ import (\n \t\"github.com/bluesky-social/indigo/automod/countstore\"\n )\n \n+var _ automod.PostRuleFunc = ReplyCountPostRule\n+\n // does not count \"self-replies\" (direct to self, or in own post thread)\n func ReplyCountPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error {\n \tif post.Reply == nil || IsSelfThread(c, post) {\n@@ -35,6 +37,8 @@ func ReplyCountPostRule(c *automod.RecordContext, post *appbsky.FeedPost) error\n // triggers on the N+1 post, so 6th identical reply\n var identicalReplyLimit = 5\n \n+var _ automod.PostRuleFunc = IdenticalReplyPostRule\n+\n // Looks for accounts posting the exact same text multiple times. Does not currently count the number of distinct accounts replied to, just counts replies at all.\n //\n // There can be legitimate situations that trigger this rule, so in most situations should be a \"report\" not \"label\" action.\n---\n"}], "ideal": "Title: automod: annotate rules with function types\n\nBody: As discussed; pretty straight-forward"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "go.mod\n@@ -56,7 +56,7 @@ require (\n \tgithub.com/whyrusleeping/cbor-gen v0.0.0-20230923211252-36a87e1ba72f\n \tgithub.com/whyrusleeping/go-did v0.0.0-20230824162731-404d1707d5d6\n \tgitlab.com/yawning/secp256k1-voi v0.0.0-20230925100816-f2616030848b\n-\tgo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.42.0\n+\tgo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.46.1\n \tgo.opentelemetry.io/otel v1.21.0\n \tgo.opentelemetry.io/otel/exporters/jaeger v1.14.0\n \tgo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.21.0\n@@ -65,7 +65,7 @@ require (\n \tgo.opentelemetry.io/otel/trace v1.21.0\n \tgo.uber.org/automaxprocs v1.5.3\n \tgo.uber.org/zap v1.26.0\n-\tgolang.org/x/crypto v0.15.0\n+\tgolang.org/x/crypto v0.17.0\n \tgolang.org/x/sync v0.5.0\n \tgolang.org/x/text v0.14.0\n \tgolang.org/x/time v0.3.0\n@@ -103,7 +103,7 @@ require (\n \tgithub.com/felixge/httpsnoop v1.0.4 // indirect\n \tgithub.com/go-kit/log v0.2.1 // indirect\n \tgithub.com/go-logfmt/logfmt v0.6.0 // indirect\n-\tgithub.com/go-logr/logr v1.3.0 // indirect\n+\tgithub.com/go-logr/logr v1.4.1 // indirect\n \tgithub.com/go-logr/stdr v1.2.2 // indirect\n \tgithub.com/gogo/protobuf v1.3.2 // indirect\n \tgithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da // indirect\n@@ -165,7 +165,7 @@ require (\n \tgo.uber.org/multierr v1.11.0 // indirect\n \tgolang.org/x/mod v0.14.0 // indirect\n \tgolang.org/x/net v0.18.0 // indirect\n-\tgolang.org/x/sys v0.14.0 // indirect\n+\tgolang.org/x/sys v0.15.0 // indirect\n \tgoogle.golang.org/genproto/googleapis/api v0.0.0-20231120223509-83a465c0220f // indirect\n \tgoogle.golang.org/genproto/googleapis/rpc v0.0.0-20231120223509-83a465c0220f // indirect\n \tgoogle.golang.org/grpc v1.59.0 // indirect\n---\ngo.sum\n@@ -137,8 +137,8 @@ github.com/go-logfmt/logfmt v0.6.0 h1:wGYYu3uicYdqXVgoYbvnkrPVXkuLM1p1ifugDMEdRi\n github.com/go-logfmt/logfmt v0.6.0/go.mod h1:WYhtIu8zTZfxdn5+rREduYbwxfcBr/Vr6KEVveWlfTs=\n github.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\n github.com/go-logr/logr v1.2.3/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\n-github.com/go-logr/logr v1.3.0 h1:2y3SDp0ZXuc6/cjLSZ+Q3ir+QB9T/iG5yYRXqsagWSY=\n-github.com/go-logr/logr v1.3.0/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=\n+github.com/go-logr/logr v1.4.1 h1:pKouT5E8xu9zeFC39JXRDukb6JFQPXM5p5I91188VAQ=\n+github.com/go-logr/logr v1.4.1/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=\n github.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=\n github.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=\n github.com/go-redis/cache/v9 v9.0.0 h1:0thdtFo0xJi0/WXbRVu8B066z8OvVymXTJGaXrVWnN0=\n@@ -663,8 +663,8 @@ go.opencensus.io v0.24.0 h1:y73uSU6J157QMP2kn2r30vwW1A2W2WFwSCGnAVxeaD0=\n go.opencensus.io v0.24.0/go.mod h1:vNK8G9p7aAivkbmorf4v+7Hgx+Zs0yY+0fOtgBfjQKo=\n go.opentelemetry.io/contrib/instrumentation/github.com/labstack/echo/otelecho v0.45.0 h1:JJCIHAxGCB5HM3NxeIwFjHc087Xwk96TG9kaZU6TAec=\n go.opentelemetry.io/contrib/instrumentation/github.com/labstack/echo/otelecho v0.45.0/go.mod h1:Px9kH7SJ+NhsgWRtD/eMcs15Tyt4uL3rM7X54qv6pfA=\n-go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.42.0 h1:pginetY7+onl4qN1vl0xW/V/v6OBZ0vVdH+esuJgvmM=\n-go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.42.0/go.mod h1:XiYsayHc36K3EByOO6nbAXnAWbrUxdjUROCEeeROOH8=\n+go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.46.1 h1:aFJWCqJMNjENlcleuuOkGAPH82y0yULBScfXcIEdS24=\n+go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.46.1/go.mod h1:sEGXWArGqc3tVa+ekntsN65DmVbVeW+7lTKTjZF3/Fo=\n go.opentelemetry.io/contrib/propagators/b3 v1.20.0 h1:Yty9Vs4F3D6/liF1o6FNt0PvN85h/BJJ6DQKJ3nrcM0=\n go.opentelemetry.io/contrib/propagators/b3 v1.20.0/go.mod h1:On4VgbkqYL18kbJlWsa18+cMNe6rYpBnPi1ARI/BrsU=\n go.opentelemetry.io/otel v1.21.0 h1:hzLeKBZEL7Okw2mGzZ0cc4k/A7Fta0uoPgaJCr8fsFc=\n@@ -715,8 +715,8 @@ golang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5y\n golang.org/x/crypto v0.1.0/go.mod h1:RecgLatLF4+eUMCP1PoPZQb+cVrJcOPbHkTkbkB9sbw=\n golang.org/x/crypto v0.6.0/go.mod h1:OFC/31mSvZgRz0V1QTNCzfAI1aIRzbiufJtkMIlEp58=\n golang.org/x/crypto v0.12.0/go.mod h1:NF0Gs7EO5K4qLn+Ylc+fih8BSTeIjAP05siRnAh98yw=\n-golang.org/x/crypto v0.15.0 h1:frVn1TEaCEaZcn3Tmd7Y2b5KKPaZ+I32Q2OA3kYp5TA=\n-golang.org/x/crypto v0.15.0/go.mod h1:4ChreQoLWfG3xLDer1WdlH5NdlQ3+mwnQq1YTKY+72g=\n+golang.org/x/crypto v0.17.0 h1:r8bRNjWL3GshPW3gkd+RpvzWrZAwPS49OmTGZ/uhM4k=\n+golang.org/x/crypto v0.17.0/go.mod h1:gCAAfMLgwOJRpTjQ2zCCt2OcSfYMTeZVSRtQlPC7Nq4=\n golang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\n golang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\n golang.org/x/exp v0.0.0-20190510132918-efd6b22b2522/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=\n@@ -893,8 +893,8 @@ golang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n golang.org/x/sys v0.8.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n golang.org/x/sys v0.11.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\n-golang.org/x/sys v0.14.0 h1:Vz7Qs629MkJkGyHxUlRHizWJRG2j8fbQKjELVSNhy7Q=\n-golang.org/x/sys v0.14.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\n+golang.org/x/sys v0.15.0 h1:h48lPFYpsTvQJZF4EKyI4aLHaev3CxivZmv7yZig9pc=\n+golang.org/x/sys v0.15.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\n golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\n golang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\n golang.org/x/term v0.1.0/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\n---\n"}], "ideal": "Title: bump some deps (appease dependabot)\n\nBody: Nothing major, just some minor bumps."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/hepa/main.go\n@@ -192,6 +192,14 @@ var runCmd = &cli.Command{\n \t\t\t}\n \t\t}()\n \n+\t\tif srv.engine.AdminClient != nil {\n+\t\t\tgo func() {\n+\t\t\t\tif err := srv.RunRefreshAdminClient(ctx); err != nil {\n+\t\t\t\t\tslog.Error(\"session refresh failed\", \"err\", err)\n+\t\t\t\t}\n+\t\t\t}()\n+\t\t}\n+\n \t\t// the main service loop\n \t\tif err := srv.RunConsumer(ctx); err != nil {\n \t\t\treturn fmt.Errorf(\"failure consuming and processing firehose: %w\", err)\n---\ncmd/hepa/server.go\n@@ -191,6 +191,44 @@ func (s *Server) PersistCursor(ctx context.Context) error {\n \treturn err\n }\n \n+// Periodically refreshes the engine's admin XRPC client JWT auth token.\n+//\n+// Expects to be run in a goroutine, and to be the only running code which touches the auth fields (aka, there is no locking).\n+// TODO: this is a hack until we have an XRPC client which handles these details automatically.\n+func (s *Server) RunRefreshAdminClient(ctx context.Context) error {\n+\tif s.engine.AdminClient == nil {\n+\t\treturn nil\n+\t}\n+\tac := s.engine.AdminClient\n+\tticker := time.NewTicker(1 * time.Hour)\n+\tfor {\n+\t\tselect {\n+\t\tcase <-ticker.C:\n+\t\t\t// uses a temporary xrpc client instead of the existing one because we need to put refreshJwt in the position of accessJwt, and that would cause an error for any concurrent requests\n+\t\t\ttmpClient := xrpc.Client{\n+\t\t\t\tHost: ac.Host,\n+\t\t\t\tAuth: &xrpc.AuthInfo{\n+\t\t\t\t\tDid:        ac.Auth.Did,\n+\t\t\t\t\tHandle:     ac.Auth.Handle,\n+\t\t\t\t\tAccessJwt:  ac.Auth.RefreshJwt,\n+\t\t\t\t\tRefreshJwt: ac.Auth.RefreshJwt,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t\trefresh, err := comatproto.ServerRefreshSession(ctx, &tmpClient)\n+\t\t\tif err != nil {\n+\t\t\t\t// don't return an error, just log, and attempt again on the next tick\n+\t\t\t\ts.logger.Error(\"failed to refresh admin client session\", \"err\", err, \"host\", ac.Host)\n+\t\t\t} else {\n+\t\t\t\ts.engine.AdminClient.Auth.RefreshJwt = refresh.RefreshJwt\n+\t\t\t\ts.engine.AdminClient.Auth.AccessJwt = refresh.AccessJwt\n+\t\t\t\ts.logger.Info(\"refreshed admin client session\")\n+\t\t\t}\n+\t\tcase <-ctx.Done():\n+\t\t\treturn nil\n+\t\t}\n+\t}\n+}\n+\n // this method runs in a loop, persisting the current cursor state every 5 seconds\n func (s *Server) RunPersistCursor(ctx context.Context) error {\n \n---\n"}], "ideal": "Title: hepa: periodically refresh auth session\n\nBody: This works around a current issue in prod where actions are failing to persist because the session expires.\r\n\r\nThe real fix for the underlying issue (IMHO) is to re-implement `xrpc.Client` to handle this in a more elegant and robust way. That is sort-of tracked in https://github.com/bluesky-social/indigo/issues/378\r\n\r\nI was initially confused why this was only coming up when taking actions, because the client is used for a number of reads (GET) as well. Those GETs mostly use *admin* auth (a token in the HTTP Authorization header), not login/session auth (which requires refresh), which explains why it mostly works, then fails for actions."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/engine.go\n@@ -28,6 +28,7 @@ type Engine struct {\n \t// used to persist moderation actions in mod service (optional)\n \tAdminClient     *xrpc.Client\n \tSlackWebhookURL string\n+\tLogQuieter      bool\n }\n \n func (e *Engine) ProcessIdentityEvent(ctx context.Context, t string, did syntax.DID) error {\n---\nautomod/event.go\n@@ -414,8 +414,22 @@ func (e *RepoEvent) PersistCounters(ctx context.Context) error {\n \treturn nil\n }\n \n+func (e *RepoEvent) AnyActions() bool {\n+\tif len(e.AccountLabels) > 0 || len(e.AccountFlags) > 0 || e.AccountTakedown || len(e.AccountReports) > 0 {\n+\t\treturn true\n+\t}\n+\treturn false\n+}\n+\n func (e *RepoEvent) CanonicalLogLine() {\n-\te.Logger.Info(\"canonical-event-line\",\n+\tlevel := slog.LevelInfo\n+\tif e.Engine.LogQuieter && !e.AnyActions() {\n+\t\tlevel = slog.LevelDebug\n+\t}\n+\te.Logger.Log(\n+\t\tcontext.Background(),\n+\t\tlevel,\n+\t\t\"canonical-event-line\",\n \t\t\"accountLabels\", e.AccountLabels,\n \t\t\"accountFlags\", e.AccountFlags,\n \t\t\"accountTakedown\", e.AccountTakedown,\n@@ -574,8 +588,25 @@ func (e *RecordEvent) PersistActions(ctx context.Context) error {\n \treturn e.PersistRecordActions(ctx)\n }\n \n+func (e *RecordEvent) AnyActions() bool {\n+\tif e.RepoEvent.AnyActions() {\n+\t\treturn true\n+\t}\n+\tif len(e.RecordLabels) > 0 || len(e.RecordFlags) > 0 || e.RecordTakedown || len(e.RecordReports) > 0 {\n+\t\treturn true\n+\t}\n+\treturn false\n+}\n+\n func (e *RecordEvent) CanonicalLogLine() {\n-\te.Logger.Info(\"canonical-event-line\",\n+\tlevel := slog.LevelInfo\n+\tif e.Engine.LogQuieter && !e.AnyActions() {\n+\t\tlevel = slog.LevelDebug\n+\t}\n+\te.Logger.Log(\n+\t\tcontext.Background(),\n+\t\tlevel,\n+\t\t\"canonical-event-line\",\n \t\t\"accountLabels\", e.AccountLabels,\n \t\t\"accountFlags\", e.AccountFlags,\n \t\t\"accountTakedown\", e.AccountTakedown,\n---\ncmd/hepa/main.go\n@@ -144,6 +144,11 @@ var runCmd = &cli.Command{\n \t\t\tUsage:   \"full URL of slack webhook\",\n \t\t\tEnvVars: []string{\"SLACK_WEBHOOK_URL\"},\n \t\t},\n+\t\t&cli.StringFlag{\n+\t\t\tName:    \"quieter\",\n+\t\t\tUsage:   \"log events to lower-level unless there is an action\",\n+\t\t\tEnvVars: []string{\"HEPA_QUIETER\"},\n+\t\t},\n \t},\n \tAction: func(cctx *cli.Context) error {\n \t\tctx := context.Background()\n@@ -172,6 +177,7 @@ var runCmd = &cli.Command{\n \t\t\t\tSetsFileJSON:    cctx.String(\"sets-json-path\"),\n \t\t\t\tRedisURL:        cctx.String(\"redis-url\"),\n \t\t\t\tSlackWebhookURL: cctx.String(\"slack-webhook-url\"),\n+\t\t\t\tLogQuieter:      cctx.Bool(\"quieter\"),\n \t\t\t},\n \t\t)\n \t\tif err != nil {\n---\ncmd/hepa/server.go\n@@ -40,6 +40,7 @@ type Config struct {\n \tRedisURL        string\n \tSlackWebhookURL string\n \tLogger          *slog.Logger\n+\tLogQuieter      bool\n }\n \n func NewServer(dir identity.Directory, config Config) (*Server, error) {\n@@ -141,6 +142,7 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\t\tHost:   config.BskyHost,\n \t\t},\n \t\tSlackWebhookURL: config.SlackWebhookURL,\n+\t\tLogQuieter:      config.LogQuieter,\n \t}\n \n \ts := &Server{\n---\n"}], "ideal": "Title: automod: ability to surpress canonical-log-line verbosity when developing\n\nBody: The behavior with this CLI flag set is that most log lines end up being \"DEBUG\" not \"INFO\", and won't print by default. This is more useful for development when actually inspecting logs visually.\r\n\r\n----\r\n\r\nI'm not actually sure this is the right way forward. Maybe instead the canonical log line should have a fixed verbosity and we do something closer to the slack webhook for at a higher log level?"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/event.go\n@@ -281,6 +281,9 @@ func createReportIfFresh(ctx context.Context, xrpcc *xrpc.Client, evt RepoEvent,\n \t\t\t},\n \t\t},\n \t})\n+\tif err != nil {\n+\t\treturn false, err\n+\t}\n \treturn true, nil\n }\n \n---\n"}], "ideal": "Title: automod: actually return error (bugfix)\n\nBody: This is pretty trivial, i'll probably just self-merge."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/keyword.go\n@@ -1,6 +1,8 @@\n package rules\n \n import (\n+\t\"fmt\"\n+\n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"github.com/bluesky-social/indigo/automod\"\n )\n@@ -9,6 +11,7 @@ func KeywordPostRule(evt *automod.RecordEvent, post *appbsky.FeedPost) error {\n \tfor _, tok := range ExtractTextTokensPost(post) {\n \t\tif evt.InSet(\"bad-words\", tok) {\n \t\t\tevt.AddRecordFlag(\"bad-word\")\n+\t\t\tevt.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"bad-word: %s\", tok))\n \t\t\tbreak\n \t\t}\n \t}\n@@ -19,6 +22,7 @@ func KeywordProfileRule(evt *automod.RecordEvent, profile *appbsky.ActorProfile)\n \tfor _, tok := range ExtractTextTokensProfile(profile) {\n \t\tif evt.InSet(\"bad-words\", tok) {\n \t\t\tevt.AddRecordFlag(\"bad-word\")\n+\t\t\tevt.ReportRecord(automod.ReportReasonRude, fmt.Sprintf(\"bad-word: %s\", tok))\n \t\t\tbreak\n \t\t}\n \t}\n---\nautomod/rules/replies.go\n@@ -1,6 +1,8 @@\n package rules\n \n import (\n+\t\"unicode/utf8\"\n+\n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \t\"github.com/bluesky-social/indigo/automod\"\n@@ -39,6 +41,11 @@ func IdenticalReplyPostRule(evt *automod.RecordEvent, post *appbsky.FeedPost) er\n \t\treturn nil\n \t}\n \n+\t// short reply? ignore it\n+\tif utf8.RuneCountInString(post.Text) <= 10 {\n+\t\treturn nil\n+\t}\n+\n \t// use a specific period (IncrementPeriod()) to reduce the number of counters (one per unique post text)\n \tperiod := automod.PeriodDay\n \tbucket := evt.Account.Identity.DID.String() + \"/\" + HashOfString(post.Text)\n---\n"}], "ideal": "Title: quick tweaks to rules at scale\n\nBody: - skip short post text for identical replies\r\n- start reporting bad word records for review\r\n\r\nThe \"short post text\" instead of skipping just empty also handles a common case of \"handful of emoji\"."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "api/atproto/servercreateSession.go\n@@ -7,7 +7,6 @@ package atproto\n import (\n \t\"context\"\n \n-\t\"github.com/bluesky-social/indigo/lex/util\"\n \t\"github.com/bluesky-social/indigo/xrpc\"\n )\n \n@@ -20,13 +19,13 @@ type ServerCreateSession_Input struct {\n \n // ServerCreateSession_Output is the output of a com.atproto.server.createSession call.\n type ServerCreateSession_Output struct {\n-\tAccessJwt      string                   `json:\"accessJwt\" cborgen:\"accessJwt\"`\n-\tDid            string                   `json:\"did\" cborgen:\"did\"`\n-\tDidDoc         *util.LexiconTypeDecoder `json:\"didDoc,omitempty\" cborgen:\"didDoc,omitempty\"`\n-\tEmail          *string                  `json:\"email,omitempty\" cborgen:\"email,omitempty\"`\n-\tEmailConfirmed *bool                    `json:\"emailConfirmed,omitempty\" cborgen:\"emailConfirmed,omitempty\"`\n-\tHandle         string                   `json:\"handle\" cborgen:\"handle\"`\n-\tRefreshJwt     string                   `json:\"refreshJwt\" cborgen:\"refreshJwt\"`\n+\tAccessJwt string `json:\"accessJwt\" cborgen:\"accessJwt\"`\n+\tDid       string `json:\"did\" cborgen:\"did\"`\n+\t//DidDoc         *util.LexiconTypeDecoder `json:\"didDoc,omitempty\" cborgen:\"didDoc,omitempty\"`\n+\tEmail          *string `json:\"email,omitempty\" cborgen:\"email,omitempty\"`\n+\tEmailConfirmed *bool   `json:\"emailConfirmed,omitempty\" cborgen:\"emailConfirmed,omitempty\"`\n+\tHandle         string  `json:\"handle\" cborgen:\"handle\"`\n+\tRefreshJwt     string  `json:\"refreshJwt\" cborgen:\"refreshJwt\"`\n }\n \n // ServerCreateSession calls the XRPC method \"com.atproto.server.createSession\".\n---\n"}], "ideal": "Title: dont include did doc in create session for now\n\nBody: The did doc is defined as an `any` type in the lexicon right now, which in all other cases implies a record (with a $type field). For now, lets just ignore this in the go code (its not necessary for anything) until we figure out a better way forward."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/query.go\n@@ -9,9 +9,10 @@ import (\n \t\"log/slog\"\n \n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n-\t\"go.opentelemetry.io/otel/attribute\"\n+\t\"github.com/bluesky-social/indigo/atproto/syntax\"\n \n \tes \"github.com/opensearch-project/opensearch-go/v2\"\n+\t\"go.opentelemetry.io/otel/attribute\"\n )\n \n type EsSearchHit struct {\n@@ -73,7 +74,15 @@ func DoSearchPosts(ctx context.Context, dir identity.Directory, escli *es.Client\n \t\t\t\"analyze_wildcard\": false,\n \t\t},\n \t}\n-\n+\t// filter out future posts (TODO: temporary hack)\n+\tnow := syntax.DatetimeNow()\n+\tfilters = append(filters, map[string]interface{}{\n+\t\t\"range\": map[string]interface{}{\n+\t\t\t\"created_at\": map[string]interface{}{\n+\t\t\t\t\"lte\": now,\n+\t\t\t},\n+\t\t},\n+\t})\n \tquery := map[string]interface{}{\n \t\t\"query\": map[string]interface{}{\n \t\t\t\"bool\": map[string]interface{}{\n---\nsearch/transform.go\n@@ -1,7 +1,9 @@\n package search\n \n import (\n+\t\"log/slog\"\n \t\"strings\"\n+\t\"time\"\n \n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n@@ -180,8 +182,15 @@ func TransformPost(post *appbsky.FeedPost, ident *identity.Identity, rkey, cid s\n \t\t// there are some old bad timestamps out there!\n \t\tdt, err := syntax.ParseDatetimeLenient(post.CreatedAt)\n \t\tif nil == err { // *not* an error\n-\t\t\ts := dt.String()\n-\t\t\tdoc.CreatedAt = &s\n+\t\t\t// not more than a few minutes in the future\n+\t\t\tif time.Since(dt.Time()) >= -1*5*time.Minute {\n+\t\t\t\ts := dt.String()\n+\t\t\t\tdoc.CreatedAt = &s\n+\t\t\t} else {\n+\t\t\t\tslog.Warn(\"rejecting future post CreatedAt\", \"datetime\", dt.String(), \"did\", ident.DID.String(), \"rkey\", rkey)\n+\t\t\t\ts := syntax.DatetimeNow().String()\n+\t\t\t\tdoc.CreatedAt = &s\n+\t\t\t}\n \t\t}\n \t}\n \n---\n"}], "ideal": "Title: palomar: handle bogus future createdAt better\n\nBody: This tries to mitigate issues with bogus createdAt timestamps in post records. In particular this might (?) be causing a bunch of network traffic in-app when you search posts for \"hello\".\r\n\r\nWe have a batch of these in the current index which mess up ranking, so there is a query-time filter. A better mitigation would be to run a cleanup \"update by query\" which might look like this (untested):\r\n\r\n```\r\nPOST palomar_post/_update_by_query\r\n{\r\n  \"script\": {\r\n    \"source\": \"ctx._source.created_at = null\",\r\n    \"lang\": \"painless\"\r\n  },\r\n  \"query\": {\r\n    \"range\": {\r\n      \"created_at\": {\r\n        \"gte\": \"2024-01-01\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nOur PDS currently enforces a reasonable createdAt, but it might stop this Lexicon-specific behavior some day (speculative), or third-party PDS implementations might not take this step. So this PR adds checks at index-time.\r\n\r\nThere is no test coverage here, and haven't checked against an actual index, but wanted to share partial work if helpful."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/all.go\n@@ -19,6 +19,7 @@ func DefaultRules() automod.RuleSet {\n \t\t\tReplySingleKeywordPostRule,\n \t\t\tAggressivePromotionRule,\n \t\t\tIdenticalReplyPostRule,\n+\t\t\tDistinctMentionsRule,\n \t\t},\n \t\tProfileRules: []automod.ProfileRuleFunc{\n \t\t\tGtubeProfileRule,\n---\nautomod/rules/mentions.go\n@@ -0,0 +1,38 @@\n+package rules\n+\n+import (\n+\tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n+\t\"github.com/bluesky-social/indigo/automod\"\n+)\n+\n+var _ automod.PostRuleFunc = DistinctMentionsRule\n+\n+var mentionHourlyThreshold = 20\n+\n+// DistinctMentionsRule looks for accounts which mention an unusually large number of distinct accounts per period.\n+func DistinctMentionsRule(evt *automod.RecordEvent, post *appbsky.FeedPost) error {\n+\tdid := evt.Account.Identity.DID.String()\n+\n+\t// Increment counters for all new mentions in this post.\n+\tvar newMentions bool\n+\tfor _, facet := range post.Facets {\n+\t\tfor _, feature := range facet.Features {\n+\t\t\tmention := feature.RichtextFacet_Mention\n+\t\t\tif mention == nil {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tevt.IncrementDistinct(\"mentions\", did, mention.Did)\n+\t\t\tnewMentions = true\n+\t\t}\n+\t}\n+\n+\t// If there were any new mentions, check if it's gotten spammy.\n+\tif !newMentions {\n+\t\treturn nil\n+\t}\n+\tif mentionHourlyThreshold <= evt.GetCountDistinct(\"mentions\", did, automod.PeriodHour) {\n+\t\tevt.AddAccountFlag(\"high-distinct-mentions\")\n+\t}\n+\n+\treturn nil\n+}\n---\n"}], "ideal": "Title: automod: mentions spike rule\n\nBody: Introduce a simple new rule for detecting and flagging spikes of mentions within a period."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "search/indexing.go\n@@ -6,7 +6,6 @@ import (\n \t\"encoding/json\"\n \t\"fmt\"\n \t\"io\"\n-\t\"regexp\"\n \t\"strings\"\n \n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n@@ -18,14 +17,26 @@ import (\n \tesapi \"github.com/opensearch-project/opensearch-go/v2/opensearchapi\"\n )\n \n-func (s *Server) deletePost(ctx context.Context, ident *identity.Identity, rkey string) error {\n+func (s *Server) deletePost(ctx context.Context, ident *identity.Identity, recordPath string) error {\n \tctx, span := tracer.Start(ctx, \"deletePost\")\n \tdefer span.End()\n-\tspan.SetAttributes(attribute.String(\"repo\", ident.DID.String()), attribute.String(\"rkey\", rkey))\n+\tspan.SetAttributes(attribute.String(\"repo\", ident.DID.String()), attribute.String(\"path\", recordPath))\n+\n+\tlogger := s.logger.With(\"repo\", ident.DID, \"path\", recordPath, \"op\", \"deletePost\")\n+\n+\tparts := strings.SplitN(recordPath, \"/\", 3)\n+\tif len(parts) < 2 {\n+\t\tlogger.Warn(\"skipping post record with malformed path\")\n+\t\treturn nil\n+\t}\n+\trkey, err := syntax.ParseTID(parts[1])\n+\tif err != nil {\n+\t\tlogger.Warn(\"skipping post record with non-TID rkey\")\n+\t\treturn nil\n+\t}\n \n-\tlog := s.logger.With(\"repo\", ident.DID, \"rkey\", rkey, \"op\", \"deletePost\")\n-\tlog.Info(\"deleting post from index\")\n \tdocID := fmt.Sprintf(\"%s_%s\", ident.DID.String(), rkey)\n+\tlogger.Info(\"deleting post from index\", \"docID\", docID)\n \treq := esapi.DeleteRequest{\n \t\tIndex:      s.postIndex,\n \t\tDocumentID: docID,\n@@ -42,37 +53,32 @@ func (s *Server) deletePost(ctx context.Context, ident *identity.Identity, rkey\n \t\treturn fmt.Errorf(\"failed to read indexing response: %w\", err)\n \t}\n \tif res.IsError() {\n-\t\tlog.Warn(\"opensearch indexing error\", \"status_code\", res.StatusCode, \"response\", res, \"body\", string(body))\n+\t\tlogger.Warn(\"opensearch indexing error\", \"status_code\", res.StatusCode, \"response\", res, \"body\", string(body))\n \t\treturn fmt.Errorf(\"indexing error, code=%d\", res.StatusCode)\n \t}\n \treturn nil\n }\n \n-var tidRegex = regexp.MustCompile(`^[234567abcdefghijklmnopqrstuvwxyz]{13}$`)\n-\n func (s *Server) indexPost(ctx context.Context, ident *identity.Identity, rec *appbsky.FeedPost, path string, rcid cid.Cid) error {\n \tctx, span := tracer.Start(ctx, \"indexPost\")\n \tdefer span.End()\n \tspan.SetAttributes(attribute.String(\"repo\", ident.DID.String()), attribute.String(\"path\", path))\n \n \tlog := s.logger.With(\"repo\", ident.DID, \"path\", path, \"op\", \"indexPost\")\n \tparts := strings.SplitN(path, \"/\", 3)\n-\t// TODO: replace with an atproto/syntax package type for TID\n-\tif len(parts) != 2 || !tidRegex.MatchString(parts[1]) {\n-\t\tlog.Warn(\"skipping index post record with weird path/TID\", \"did\", ident.DID, \"path\", path)\n+\tif len(parts) < 2 {\n+\t\tlog.Warn(\"skipping post record with malformed path\")\n \t\treturn nil\n \t}\n-\trkey := parts[1]\n-\n-\tlog = log.With(\"rkey\", rkey)\n-\n-\t_, err := syntax.ParseDatetimeLenient(rec.CreatedAt)\n+\trkey, err := syntax.ParseTID(parts[1])\n \tif err != nil {\n-\t\tlog.Warn(\"post had invalid timestamp\", \"createdAt\", rec.CreatedAt, \"parseErr\", err)\n-\t\trec.CreatedAt = \"\"\n+\t\tlog.Warn(\"skipping post record with non-TID rkey\")\n+\t\treturn nil\n \t}\n \n-\tdoc := TransformPost(rec, ident, rkey, rcid.String())\n+\tlog = log.With(\"rkey\", rkey)\n+\n+\tdoc := TransformPost(rec, ident, rkey.String(), rcid.String())\n \tb, err := json.Marshal(doc)\n \tif err != nil {\n \t\treturn err\n---\nsearch/server.go\n@@ -168,6 +168,7 @@ func (s *Server) EnsureIndices(ctx context.Context) error {\n }\n \n type HealthStatus struct {\n+\tService string `json:\"service,const=palomar\"`\n \tStatus  string `json:\"status\"`\n \tVersion string `json:\"version\"`\n \tMessage string `json:\"msg,omitempty\"`\n@@ -202,6 +203,7 @@ func (s *Server) RunAPI(listen string) error {\n \t}\n \n \te.Use(middleware.CORS())\n+\te.GET(\"/\", s.handleHealthCheck)\n \te.GET(\"/_health\", s.handleHealthCheck)\n \te.GET(\"/metrics\", echo.WrapHandler(promhttp.Handler()))\n \te.GET(\"/xrpc/app.bsky.unspecced.searchPostsSkeleton\", s.handleSearchPostsSkeleton)\n---\nsearch/transform.go\n@@ -2,11 +2,11 @@ package search\n \n import (\n \t\"strings\"\n-\t\"time\"\n \n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n-\t\"github.com/bluesky-social/indigo/util\"\n+\t\"github.com/bluesky-social/indigo/atproto/syntax\"\n+\n \t\"github.com/rivo/uniseg\"\n )\n \n@@ -80,7 +80,7 @@ func TransformProfile(profile *appbsky.ActorProfile, ident *identity.Identity, c\n \t\thandle = ident.Handle.String()\n \t}\n \treturn ProfileDoc{\n-\t\tDocIndexTs:  time.Now().UTC().Format(util.ISO8601),\n+\t\tDocIndexTs:  syntax.DatetimeNow().String(),\n \t\tDID:         ident.DID.String(),\n \t\tRecordCID:   cid,\n \t\tHandle:      handle,\n@@ -157,7 +157,7 @@ func TransformPost(post *appbsky.FeedPost, ident *identity.Identity, rkey, cid s\n \t}\n \n \tdoc := PostDoc{\n-\t\tDocIndexTs:      time.Now().UTC().Format(util.ISO8601),\n+\t\tDocIndexTs:      syntax.DatetimeNow().String(),\n \t\tDID:             ident.DID.String(),\n \t\tRecordRkey:      rkey,\n \t\tRecordCID:       cid,\n@@ -177,7 +177,12 @@ func TransformPost(post *appbsky.FeedPost, ident *identity.Identity, rkey, cid s\n \t}\n \n \tif post.CreatedAt != \"\" {\n-\t\tdoc.CreatedAt = &post.CreatedAt\n+\t\t// there are some old bad timestamps out there!\n+\t\tdt, err := syntax.ParseDatetimeLenient(post.CreatedAt)\n+\t\tif nil == err { // *not* an error\n+\t\t\ts := dt.String()\n+\t\t\tdoc.CreatedAt = &s\n+\t\t}\n \t}\n \n \treturn doc\n---\n"}], "ideal": "Title: palomar: prod errors burndown\n\nBody: I took a peek at prod error logs and found some issues:\r\n\r\n- deleting search documents is failing, because the \"document ID\" (docID) was formatted wrong, because the `rkey` parameter is actually a full path, not just the record key part\r\n- many actually-valid datetimes were not getting parsed correctly, resulting in posts not having correct createdAt, likely resulting in them not appearing with expected ranking in search results\r\n- many HTTP 404 errors on fetches of base path; not really a big deal but might as well return healthcheck\r\n\r\nI haven't tested these much yet, we should probably deploy to staging (which consumes the prod firehose, IIRC) and observe that for a bit."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/gosky/main.go\n@@ -747,11 +747,11 @@ var listLabelsCmd = &cli.Command{\n \n \t\t\tif len(out.Labels) > 0 {\n \t\t\t\tlast := out.Labels[len(out.Labels)-1]\n-\t\t\t\tts, err := util.ParseTimestamp(last.Cts)\n+\t\t\t\tdt, err := syntax.ParseDatetime(last.Cts)\n \t\t\t\tif err != nil {\n \t\t\t\t\treturn fmt.Errorf(\"invalid cts: %w\", err)\n \t\t\t\t}\n-\t\t\t\tsince = ts.UnixMilli()\n+\t\t\t\tsince = dt.Time().UnixMilli()\n \t\t\t} else {\n \t\t\t\tbreak\n \t\t\t}\n---\nsearch/indexing.go\n@@ -12,7 +12,6 @@ import (\n \tappbsky \"github.com/bluesky-social/indigo/api/bsky\"\n \t\"github.com/bluesky-social/indigo/atproto/identity\"\n \t\"github.com/bluesky-social/indigo/atproto/syntax\"\n-\t\"github.com/bluesky-social/indigo/util\"\n \t\"github.com/ipfs/go-cid\"\n \t\"go.opentelemetry.io/otel/attribute\"\n \n@@ -66,7 +65,7 @@ func (s *Server) indexPost(ctx context.Context, ident *identity.Identity, rec *a\n \n \tlog = log.With(\"rkey\", rkey)\n \n-\t_, err := util.ParseTimestamp(rec.CreatedAt)\n+\t_, err := syntax.ParseDatetimeLenient(rec.CreatedAt)\n \tif err != nil {\n \t\tlog.Warn(\"post had invalid timestamp\", \"createdAt\", rec.CreatedAt, \"parseErr\", err)\n \t\trec.CreatedAt = \"\"\n---\nutil/time.go\n@@ -1,52 +1,3 @@\n package util\n \n-import (\n-\t\"fmt\"\n-\t\"time\"\n-)\n-\n const ISO8601 = \"2006-01-02T15:04:05.000Z\"\n-\n-const ISO8601_milli = \"2006-01-02T15:04:05.000000Z\"\n-\n-const ISO8601_numtz = \"2006-01-02T15:04:05.000-07:00\"\n-\n-const ISO8601_numtz_milli = \"2006-01-02T15:04:05.000000-07:00\"\n-\n-const ISO8601_sec = \"2006-01-02T15:04:05Z\"\n-\n-const ISO8601_numtz_sec = \"2006-01-02T15:04:05-07:00\"\n-\n-func ParseTimestamp(s string) (time.Time, error) {\n-\tt, err := time.Parse(ISO8601, s)\n-\tif err == nil {\n-\t\treturn t, nil\n-\t}\n-\n-\tt, err = time.Parse(ISO8601_milli, s)\n-\tif err == nil {\n-\t\treturn t, nil\n-\t}\n-\n-\tt, err = time.Parse(ISO8601_numtz, s)\n-\tif err == nil {\n-\t\treturn t, nil\n-\t}\n-\n-\tt, err = time.Parse(ISO8601_numtz_milli, s)\n-\tif err == nil {\n-\t\treturn t, nil\n-\t}\n-\n-\tt, err = time.Parse(ISO8601_sec, s)\n-\tif err == nil {\n-\t\treturn t, nil\n-\t}\n-\n-\tt, err = time.Parse(ISO8601_numtz_sec, s)\n-\tif err == nil {\n-\t\treturn t, nil\n-\t}\n-\n-\treturn time.Time{}, fmt.Errorf(\"failed to parse %q as timestamp\", s)\n-}\n---\nutil/time_test.go\n@@ -1,20 +0,0 @@\n-package util\n-\n-import \"testing\"\n-\n-func TestTimeParsing(t *testing.T) {\n-\tgood := []string{\n-\t\t\"2023-07-19T21:54:14.165300Z\",\n-\t\t\"2023-07-19T21:54:14.163Z\",\n-\t\t\"2023-07-19T21:52:02.000+00:00\",\n-\t\t\"2023-07-19T21:52:02.123456+00:00\",\n-\t\t\"2023-09-13T11:23:33+09:00\",\n-\t}\n-\n-\tfor _, g := range good {\n-\t\t_, err := ParseTimestamp(g)\n-\t\tif err != nil {\n-\t\t\tt.Fatal(err)\n-\t\t}\n-\t}\n-}\n---\n"}], "ideal": "Title: util: remove ParseTimestamp\n\nBody: In particular from search/palomar codebase where it is causing issues, but also in general the `syntax.ParseDatetime` method is more tested and compliant with the spec."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/cache_directory.go\n@@ -90,7 +90,7 @@ func (d *CacheDirectory) IsIdentityStale(e *IdentityEntry) bool {\n \treturn false\n }\n \n-func (d *CacheDirectory) updateHandle(ctx context.Context, h syntax.Handle) (*HandleEntry, error) {\n+func (d *CacheDirectory) updateHandle(ctx context.Context, h syntax.Handle) HandleEntry {\n \tident, err := d.Inner.LookupHandle(ctx, h)\n \tif err != nil {\n \t\the := HandleEntry{\n@@ -99,7 +99,7 @@ func (d *CacheDirectory) updateHandle(ctx context.Context, h syntax.Handle) (*Ha\n \t\t\tErr:     err,\n \t\t}\n \t\td.handleCache.Add(h, he)\n-\t\treturn &he, nil\n+\t\treturn he\n \t}\n \n \tentry := IdentityEntry{\n@@ -115,7 +115,7 @@ func (d *CacheDirectory) updateHandle(ctx context.Context, h syntax.Handle) (*Ha\n \n \td.identityCache.Add(ident.DID, entry)\n \td.handleCache.Add(ident.Handle, he)\n-\treturn &he, nil\n+\treturn he\n }\n \n func (d *CacheDirectory) ResolveHandle(ctx context.Context, h syntax.Handle) (syntax.DID, error) {\n@@ -145,21 +145,24 @@ func (d *CacheDirectory) ResolveHandle(ctx context.Context, h syntax.Handle) (sy\n \t\t}\n \t}\n \n-\tvar did syntax.DID\n \t// Update the Handle Entry from PLC and cache the result\n-\tnewEntry, err := d.updateHandle(ctx, h)\n-\tif err == nil && newEntry != nil {\n-\t\tdid = newEntry.DID\n-\t}\n+\tnewEntry := d.updateHandle(ctx, h)\n+\n \t// Cleanup the coalesce map and close the results channel\n \td.handleLookupChans.Delete(h.String())\n \t// Callers waiting will now get the result from the cache\n \tclose(res)\n \n-\treturn did, err\n+\tif newEntry.Err != nil {\n+\t\treturn \"\", newEntry.Err\n+\t}\n+\tif newEntry.DID != \"\" {\n+\t\treturn newEntry.DID, nil\n+\t}\n+\treturn \"\", fmt.Errorf(\"unexpected control-flow error\")\n }\n \n-func (d *CacheDirectory) updateDID(ctx context.Context, did syntax.DID) (*IdentityEntry, error) {\n+func (d *CacheDirectory) updateDID(ctx context.Context, did syntax.DID) IdentityEntry {\n \tident, err := d.Inner.LookupDID(ctx, did)\n \t// persist the identity lookup error, instead of processing it immediately\n \tentry := IdentityEntry{\n@@ -181,7 +184,7 @@ func (d *CacheDirectory) updateDID(ctx context.Context, did syntax.DID) (*Identi\n \tif he != nil {\n \t\td.handleCache.Add(ident.Handle, *he)\n \t}\n-\treturn &entry, err\n+\treturn entry\n }\n \n func (d *CacheDirectory) LookupDID(ctx context.Context, did syntax.DID) (*Identity, error) {\n@@ -211,18 +214,21 @@ func (d *CacheDirectory) LookupDID(ctx context.Context, did syntax.DID) (*Identi\n \t\t}\n \t}\n \n-\tvar doc *Identity\n \t// Update the Identity Entry from PLC and cache the result\n-\tnewEntry, err := d.updateDID(ctx, did)\n-\tif err == nil && newEntry != nil {\n-\t\tdoc = newEntry.Identity\n-\t}\n+\tnewEntry := d.updateDID(ctx, did)\n+\n \t// Cleanup the coalesce map and close the results channel\n \td.didLookupChans.Delete(did.String())\n \t// Callers waiting will now get the result from the cache\n \tclose(res)\n \n-\treturn doc, err\n+\tif newEntry.Err != nil {\n+\t\treturn nil, newEntry.Err\n+\t}\n+\tif newEntry.Identity != nil {\n+\t\treturn newEntry.Identity, nil\n+\t}\n+\treturn nil, fmt.Errorf(\"unexpected control-flow error\")\n }\n \n func (d *CacheDirectory) LookupHandle(ctx context.Context, h syntax.Handle) (*Identity, error) {\n---\n"}], "ideal": "Title: identity: refactor cache directory to prevent nil/nil condition\n\nBody: This is closely related to https://github.com/bluesky-social/indigo/pull/458, which tried to resolve an issue with DIDs. I was seeing very confusing behavior with handles; was able to confirm `\"\", nil` getting returned internally on real-world lookups.\r\n\r\nI took a more aggressive approach and changed the return signatures of both update helper methods to just return an \"Entry\", not as a pointer, and no err. This makes the code flow much simpler.\r\n\r\nI tacked on a special control-flow error message as defensive programming after getting bit twice on this (darn self!). Probably isn't necessary and smells a bit but :shrug:."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "cmd/hepa/main.go\n@@ -154,7 +154,7 @@ var runCmd = &cli.Command{\n \n \t\tdir, err := configDirectory(cctx)\n \t\tif err != nil {\n-\t\t\treturn err\n+\t\t\treturn fmt.Errorf(\"failed to configure identity directory: %v\", err)\n \t\t}\n \n \t\tsrv, err := NewServer(\n@@ -173,7 +173,7 @@ var runCmd = &cli.Command{\n \t\t\t},\n \t\t)\n \t\tif err != nil {\n-\t\t\treturn err\n+\t\t\treturn fmt.Errorf(\"failed to construct server: %v\", err)\n \t\t}\n \n \t\t// prometheus HTTP endpoint: /metrics\n---\ncmd/hepa/server.go\n@@ -70,7 +70,7 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\t\tPassword:   config.ModPassword,\n \t\t})\n \t\tif err != nil {\n-\t\t\treturn nil, err\n+\t\t\treturn nil, fmt.Errorf(\"connecting to mod service: %v\", err)\n \t\t}\n \t\txrpcc.Auth.AccessJwt = auth.AccessJwt\n \t\txrpcc.Auth.RefreshJwt = auth.RefreshJwt\n@@ -81,7 +81,7 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \tsets := automod.NewMemSetStore()\n \tif config.SetsFileJSON != \"\" {\n \t\tif err := sets.LoadFromFileJSON(config.SetsFileJSON); err != nil {\n-\t\t\treturn nil, err\n+\t\t\treturn nil, fmt.Errorf(\"initializing in-process setstore: %v\", err)\n \t\t} else {\n \t\t\tlogger.Info(\"loaded set config from JSON\", \"path\", config.SetsFileJSON)\n \t\t}\n@@ -95,30 +95,30 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\t// generic client, for cursor state\n \t\topt, err := redis.ParseURL(config.RedisURL)\n \t\tif err != nil {\n-\t\t\treturn nil, err\n+\t\t\treturn nil, fmt.Errorf(\"parsing redis URL: %v\", err)\n \t\t}\n \t\trdb = redis.NewClient(opt)\n \t\t// check redis connection\n \t\t_, err = rdb.Ping(context.TODO()).Result()\n \t\tif err != nil {\n-\t\t\treturn nil, err\n+\t\t\treturn nil, fmt.Errorf(\"redis ping failed: %v\", err)\n \t\t}\n \n \t\tcnt, err := countstore.NewRedisCountStore(config.RedisURL)\n \t\tif err != nil {\n-\t\t\treturn nil, err\n+\t\t\treturn nil, fmt.Errorf(\"initializing redis countstore: %v\", err)\n \t\t}\n \t\tcounters = cnt\n \n \t\tcsh, err := automod.NewRedisCacheStore(config.RedisURL, 30*time.Minute)\n \t\tif err != nil {\n-\t\t\treturn nil, err\n+\t\t\treturn nil, fmt.Errorf(\"initializing redis cachestore: %v\", err)\n \t\t}\n \t\tcache = csh\n \n \t\tflg, err := automod.NewRedisFlagStore(config.RedisURL)\n \t\tif err != nil {\n-\t\t\treturn nil, err\n+\t\t\treturn nil, fmt.Errorf(\"initializing redis flagstore: %v\", err)\n \t\t}\n \t\tflags = flg\n \t} else {\n---\n"}], "ideal": "Title: hepa: more descriptive process startup error messages\n\nBody: Was debugging an un-related issue and the current messages are unhelpful, so added a bunch."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "lex/gen.go\n@@ -1290,7 +1290,7 @@ func (ts *TypeSchema) writeTypeDefinition(name string, w io.Writer) error {\n \t\t\tpf(\"}\\n\\n\")\n \t\t}\n \tdefault:\n-\t\treturn fmt.Errorf(\"%s has unrecognized type type %s\", name, ts.Type)\n+\t\treturn fmt.Errorf(\"%s has unrecognized type: %s\", name, ts.Type)\n \t}\n \n \treturn nil\n@@ -1344,7 +1344,7 @@ func (ts *TypeSchema) writeTypeMethods(name string, w io.Writer) error {\n \n \t\treturn fmt.Errorf(\"%q unsupported for marshaling\", name)\n \tdefault:\n-\t\treturn fmt.Errorf(\"%q has unrecognized type type %s\", name, ts.Type)\n+\t\treturn fmt.Errorf(\"%q has unrecognized type: %s\", name, ts.Type)\n \t}\n }\n \n---\nlex/util/decoder.go\n@@ -34,7 +34,7 @@ func RegisterType(id string, val cbg.CBORMarshaler) {\n func NewFromType(typ string) (interface{}, error) {\n \tt, ok := lexTypesMap[typ]\n \tif !ok {\n-\t\treturn nil, fmt.Errorf(\"unknown type: %q\", typ)\n+\t\treturn nil, fmt.Errorf(\"%w: %q\", ErrUnrecognizedType, typ)\n \t}\n \tv := reflect.New(t)\n \treturn v.Interface(), nil\n@@ -48,7 +48,7 @@ func JsonDecodeValue(b []byte) (any, error) {\n \n \tt, ok := lexTypesMap[tstr]\n \tif !ok {\n-\t\treturn nil, fmt.Errorf(\"unrecognized type: %q\", tstr)\n+\t\treturn nil, fmt.Errorf(\"%w: %q\", ErrUnrecognizedType, tstr)\n \t}\n \n \tval := reflect.New(t)\n@@ -66,7 +66,7 @@ type CBOR interface {\n \tcbg.CBORMarshaler\n }\n \n-var ErrUnrecognizedType = fmt.Errorf(\"unrecognized type\")\n+var ErrUnrecognizedType = fmt.Errorf(\"unrecognized lexicon type\")\n \n func CborDecodeValue(b []byte) (CBOR, error) {\n \ttstr, err := CborTypeExtract(b)\n@@ -76,7 +76,7 @@ func CborDecodeValue(b []byte) (CBOR, error) {\n \n \tt, ok := lexTypesMap[tstr]\n \tif !ok {\n-\t\treturn nil, fmt.Errorf(\"handling %q: %w\", tstr, ErrUnrecognizedType)\n+\t\treturn nil, fmt.Errorf(\"%w: %q\", ErrUnrecognizedType, tstr)\n \t}\n \n \tval := reflect.New(t)\n---\n"}], "ideal": "Title: lexgen error handling tweaks\n\nBody: Working on a separate patch to explicitly handle `ErrUnrecognizedType` in automod firehose consumer, and reviewed this file."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/interaction.go\n@@ -5,7 +5,7 @@ import (\n \t\"github.com/bluesky-social/indigo/automod/countstore\"\n )\n \n-var interactionDailyThreshold = 500\n+var interactionDailyThreshold = 800\n \n // looks for accounts which do frequent interaction churn, such as follow-unfollow.\n func InteractionChurnRule(evt *automod.RecordEvent) error {\n---\n"}], "ideal": "Title: autmod: bump interaction churn quota to 800\n\nBody: A number of folks seem to end up doing manual follow/unfollow interaction pairs at around 550/day. The most obvious/suspicious automated actors do around 1000/day.\r\n\r\nThis is a trivial one-liner so intend to self-merge."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "bgs/handlers.go\n@@ -202,6 +202,10 @@ func (s *BGS) handleComAtprotoSyncListRepos(ctx context.Context, cursor string,\n \t\t}\n \t}\n \n+\tresp := &comatprototypes.SyncListRepos_Output{\n+\t\tRepos: []*comatprototypes.SyncListRepos_Repo{},\n+\t}\n+\n \tusers := []User{}\n \tif err := s.db.Model(&User{}).Where(\"id > ? AND NOT tombstoned AND NOT taken_down\", c).Order(\"id\").Limit(limit).Find(&users).Error; err != nil {\n \t\tif err == gorm.ErrRecordNotFound {\n@@ -212,11 +216,8 @@ func (s *BGS) handleComAtprotoSyncListRepos(ctx context.Context, cursor string,\n \t}\n \n \tif len(users) == 0 {\n-\t\treturn &comatprototypes.SyncListRepos_Output{}, nil\n-\t}\n-\n-\tresp := &comatprototypes.SyncListRepos_Output{\n-\t\tRepos: []*comatprototypes.SyncListRepos_Repo{},\n+\t\t// resp.Repos is an explicit empty array, not just 'nil'\n+\t\treturn resp, nil\n \t}\n \n \tfor i := range users {\n---\n"}], "ideal": "Title: relay: return explicit empty array, not nil, for sync.listRepos\n\nBody: This is a work-around for the specific situation in: https://github.com/bluesky-social/atproto/issues/1949\r\n\r\nWe may need to have lexgen stubs ensure that any required array types in Output types are set to an explicit empty array, instead of nil? I haven't dug in to the details of JSON marshaling and CBOR marshaling to understand the scope of this issue yet, but the root of the issue is that the typescript code is being more strict about \"empty\" types than golang is. The typescript strictness seems both correct and reasonable to me, FWIW."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/slack.go\n@@ -18,7 +18,10 @@ type SlackWebhookBody struct {\n func (e *Engine) SendSlackMsg(ctx context.Context, msg string) error {\n \t// loosely based on: https://golangcode.com/send-slack-messages-without-a-library/\n \n-\tbody, _ := json.Marshal(SlackWebhookBody{Text: msg})\n+\tbody, err := json.Marshal(SlackWebhookBody{Text: msg})\n+\tif err != nil {\n+\t\treturn err\n+\t}\n \treq, err := http.NewRequestWithContext(ctx, http.MethodPost, e.SlackWebhookURL, bytes.NewBuffer(body))\n \tif err != nil {\n \t\treturn err\n@@ -35,7 +38,6 @@ func (e *Engine) SendSlackMsg(ctx context.Context, msg string) error {\n \tbuf := new(bytes.Buffer)\n \tbuf.ReadFrom(resp.Body)\n \tif resp.StatusCode != 200 || buf.String() != \"ok\" {\n-\t\t// TODO: in some cases print body? eg, if short and text\n \t\treturn fmt.Errorf(\"failed slack webhook POST request. status=%d\", resp.StatusCode)\n \t}\n \treturn nil\n---\ncmd/hepa/server.go\n@@ -54,7 +54,7 @@ func NewServer(dir identity.Directory, config Config) (*Server, error) {\n \t\treturn nil, fmt.Errorf(\"specified bgs host must include 'ws://' or 'wss://'\")\n \t}\n \n-\t// TODO: this isn't a very robust way to handle a peristent client\n+\t// TODO: this isn't a very robust way to handle a persistent client\n \tvar xrpcc *xrpc.Client\n \tif config.ModAdminToken != \"\" {\n \t\txrpcc = &xrpc.Client{\n---\n"}], "ideal": "Title: automod: small fixes\n\nBody: didn't want to clutter other PRs with these"}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "automod/rules/all.go\n@@ -7,8 +7,8 @@ import (\n func DefaultRules() automod.RuleSet {\n \trules := automod.RuleSet{\n \t\tPostRules: []automod.PostRuleFunc{\n-\t\t\tMisleadingURLPostRule,\n-\t\t\tMisleadingMentionPostRule,\n+\t\t\t//MisleadingURLPostRule,\n+\t\t\t//MisleadingMentionPostRule,\n \t\t\tReplyCountPostRule,\n \t\t\tBadHashtagsPostRule,\n \t\t\t//TooManyHashtagsPostRule,\n---\n"}], "ideal": "Title: automod: remove mistleading url+mention rules from default list\n\nBody: These are just too noisy right now, turning up client bugs much more often than intentionally misleading content.\r\n\r\nMay come back to these later; definitely leaving code (and tests) in place."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "atproto/identity/base_directory.go\n@@ -33,6 +33,7 @@ type BaseDirectory struct {\n var _ Directory = (*BaseDirectory)(nil)\n \n func (d *BaseDirectory) LookupHandle(ctx context.Context, h syntax.Handle) (*Identity, error) {\n+\th = h.Normalize()\n \tdid, err := d.ResolveHandle(ctx, h)\n \tif err != nil {\n \t\treturn nil, err\n---\natproto/identity/cache_directory.go\n@@ -181,7 +181,7 @@ func (d *CacheDirectory) updateDID(ctx context.Context, did syntax.DID) (*Identi\n \tif he != nil {\n \t\td.handleCache.Add(ident.Handle, *he)\n \t}\n-\treturn &entry, nil\n+\treturn &entry, err\n }\n \n func (d *CacheDirectory) LookupDID(ctx context.Context, did syntax.DID) (*Identity, error) {\n@@ -226,6 +226,7 @@ func (d *CacheDirectory) LookupDID(ctx context.Context, did syntax.DID) (*Identi\n }\n \n func (d *CacheDirectory) LookupHandle(ctx context.Context, h syntax.Handle) (*Identity, error) {\n+\th = h.Normalize()\n \tdid, err := d.ResolveHandle(ctx, h)\n \tif err != nil {\n \t\treturn nil, err\n@@ -260,6 +261,7 @@ func (d *CacheDirectory) Lookup(ctx context.Context, a syntax.AtIdentifier) (*Id\n func (d *CacheDirectory) Purge(ctx context.Context, a syntax.AtIdentifier) error {\n \thandle, err := a.AsHandle()\n \tif nil == err { // if not an error, is a handle\n+\t\thandle = handle.Normalize()\n \t\td.handleCache.Remove(handle)\n \t\treturn nil\n \t}\n---\natproto/identity/mock_directory.go\n@@ -30,6 +30,7 @@ func (d *MockDirectory) Insert(ident Identity) {\n }\n \n func (d *MockDirectory) LookupHandle(ctx context.Context, h syntax.Handle) (*Identity, error) {\n+\th = h.Normalize()\n \tdid, ok := d.Handles[h]\n \tif !ok {\n \t\treturn nil, ErrHandleNotFound\n---\n"}], "ideal": "Title: identity: small improvements\n\nBody: I'm not sure why the error wasn't getting returned; might have been a typo? Probably worth re-reading that function again in review. I hit a nil de-reference pointer in automod caused by that function returning `nil, nil`."}
{"input": [{"role": "system", "content": "Given the following code diff, generate a title and a description of a GitHub pull request that best represents this code diff.\n\nWrite your answer in the following format:\n\nTitle: [[Title of the GitHub Pull Request]]\n\nBody:  [[Description of the GitHub Pull Request]]"}, {"role": "user", "content": "repo/tid.go\n@@ -30,8 +30,8 @@ func NextTID() string {\n \tt := uint64(time.Now().UnixMicro())\n \n \tltLock.Lock()\n-\tif lastTime == t {\n-\t\tt++\n+\tif lastTime >= t {\n+\t\tt = lastTime + 1\n \t}\n \n \tlastTime = t\n---\n"}], "ideal": "Title: Fix TID generator to avoid duplicates\n\nBody: Third call on the same microsecond would not match the `if` condition and would return the same value as the first call."}
